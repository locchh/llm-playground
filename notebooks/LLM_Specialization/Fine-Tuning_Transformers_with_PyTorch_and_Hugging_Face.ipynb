{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415b6156-f8cb-4867-ad71-4f8e1c0877fd",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "# **Fine-Tuning Transformers with PyTorch and Hugging Face**\n",
    "\n",
    "Estimated time needed: **45** minutes\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This project aims to introduce you to the process of loading and fine-tuning pretrained large language models (LLMs) \n",
    "\n",
    "You will learn how to implement the training loop of a model using pytorch to tune a model on task-specific data, as well as fine-tuning a model on task-specific data using the SFTTrainer module from Hugging Face. Finally, you will learn how to evaluate the performance of the fine-tuned models.\n",
    "\n",
    "By the end of this project, you will have a solid understanding of how to leverage pretrained LLMs and fine-tune them for your specific use cases, empowering you to create powerful and customized natural language processing solutions.\n",
    "\n",
    "# __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-required-libraries\">Installing required libraries</a></li>\n",
    "            <li><a href=\"#Importing-required-libraries\">Importing required libraries</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Supervised-Fine-tuning-with-PyTorch)\">Supervised Fine-tuning with Pytorch</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Dataset-preparations\">Dataset preparations</a></li>\n",
    "            <li><a href=\"#Train-the-model\">Train the model</a></li>\n",
    "            <li><a href=\"#Evaluate\">Evaluate</a></li>\n",
    "            <li><a href=\"#Loading-the-saved-model\">Loading the saved model</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"#Exercise:-Training-a-conversational-model-using-SFTTrainer\">Exercise: Training a conversational model using SFTTrainer</a></li>\n",
    "</ol>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9cf7f1-9eb3-49cb-901c-b288165107dd",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    " - Load pretrained LLMs from Hugging Face and make inferences\n",
    " - Fine-tune a model on task-specific data using the SFTTrainer module from Hugging Face\n",
    " - Load a SFTTrainer pretrained model and make comparisons\n",
    " - Evaluate the model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997addec-1db2-4c63-9dc0-61954e4c7ecd",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "### Installing required libraries\n",
    "\n",
    "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda), you will need to install these libraries by removing the `#` sign before `!pip` in the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603e52ae-a6ad-42b9-8d67-7991623485d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "# !pip install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 torch=2.1.0+cu118\n",
    "# - Update a specific package\n",
    "# !pip install pmdarima -U\n",
    "# - Update a package to specific version\n",
    "# !pip install --upgrade pmdarima==2.0.2\n",
    "# Note: If your environment doesn't support \"!pip install\", use \"!mamba install\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83381d93-fa81-4157-b0be-b4a9f4ebe9be",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n",
    "\n",
    "```bash\n",
    "!pip install transformers==4.42.1\n",
    "!pip install datasets # 2.20.0\n",
    "!pip install portalocker>=2.0.0\n",
    "!pip install torch==2.3.1\n",
    "!pip install torchmetrics==1.4.0.post0\n",
    "#!pip install numpy==1.26.4\n",
    "#!pip install peft==0.11.1\n",
    "#!pip install evaluate==0.4.2\n",
    "#!pip install -q bitsandbytes==0.43.1\n",
    "!pip install accelerate==0.31.0\n",
    "!pip install torchvision==0.18.1\n",
    "\n",
    "\n",
    "!pip install trl==0.9.4\n",
    "!pip install protobuf==3.20.*\n",
    "!pip install matplotlib\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ba1bcc-3a6b-43c3-8330-9c8789cc8787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P40\n",
      "Import Successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# Set the environment variable TOKENIZERS_PARALLELISM to 'false'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import AutoConfig,AutoModelForCausalLM,AutoModelForSequenceClassification,BertConfig,BertForMaskedLM,TrainingArguments, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer,BertTokenizerFast,TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import SFTConfig,SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Import Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4649ed11-4fff-40e6-a842-559f559dd694",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708eed2-7c2c-46e9-a272-eab92ea58770",
   "metadata": {},
   "source": [
    "# Supervised Fine-tuning with Pytorch\n",
    "\n",
    "Fine-tuning Transformers, specifically BERT (Bidirectional Encoder Representations from Transformers), refers to the process of training a pretrained BERT model on a specific downstream task. BERT is an encoder-only language model that has been pretrained on a large corpus of text to learn contextual representations of words.\n",
    "\n",
    "Fine-tuning BERT involves taking the pretrained model and further training it on a task-specific dataset, such as sentiment analysis or question answering. During fine-tuning, the parameters of the pretrained BERT model are updated and adapted to the specifics of the target task.\n",
    "\n",
    "This process is important because it allows you to leverage the knowledge and language understanding captured by BERT and apply it to different tasks. By fine-tuning BERT, you can benefit from its contextual understanding of language and transfer that knowledge to specific domain-specific or task-specific problems. Fine-tuning enables BERT to learn from a smaller labeled dataset and generalize well to unseen examples, making it a powerful tool for various natural language processing tasks. It helps to bridge the gap between pretraining on a large corpus and the specific requirements of downstream applications, ultimately improving the performance and effectiveness of models in various real-world scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab114e17-3e60-45d4-b2e0-d89f0dc332e5",
   "metadata": {},
   "source": [
    "## Dataset preparations\n",
    "\n",
    "The Yelp review dataset is a widely used dataset in natural language processing (NLP) and sentiment analysis research. It consists of user reviews and accompanying metadata from the Yelp platform, which is a popular online platform for reviewing and rating local businesses such as restaurants, hotels, and shops.\n",
    "\n",
    "The dataset includes 6,990,280 reviews written by Yelp users, covering a wide range of businesses and locations. Each review typically contains the text of the review itself alongwith the star rating given by the user (ranging from 1 to 5).\n",
    "\n",
    "Our aim in this lab, is to fine-tune a pretrained BERT model to predict the ratings from reviews.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53197366-786a-4140-a763-94a457f7c57a",
   "metadata": {},
   "source": [
    "Let's start by loading the yelp_review data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b10bc58e-6a01-42fd-bb5b-603bdab488df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe80ca5-a106-4019-a5ce-59c357678c99",
   "metadata": {},
   "source": [
    "Let's check a sample record of the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3914b89c-df32-4e72-b9d6-f0ba66ac7359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c912868-a4bb-4b1f-8076-0488c1fa6f57",
   "metadata": {},
   "source": [
    "the label is the key of the class label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849db4bb-acb4-404a-820f-5369adee3015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d1d31a-d756-4575-8a8d-b37ef415f1d9",
   "metadata": {},
   "source": [
    "there is also the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317777cb-add1-4393-869c-399eb6f5a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][100]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61034a3c-a4f4-488a-8e2c-892b0a48a33d",
   "metadata": {},
   "source": [
    "You can select a portion of data to decrease the training time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe4f577-e873-416b-966d-4ef7aba6e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].select([i for i in range(1000)])\n",
    "dataset[\"test\"] = dataset[\"test\"].select([i for i in range(200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a7edc-6812-4843-8749-44ea1fcc5320",
   "metadata": {},
   "source": [
    "There are two data fields:\n",
    "- label: the label for the review\n",
    "- text: a string containing the body of the user review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8151bfc-0304-4045-9319-b28bbf0c38bf",
   "metadata": {},
   "source": [
    "### Tokenizing data\n",
    "\n",
    "The next step is to load a BERT tokenizer to tokenize, pad and truncate reviews to handle variable-length sequences:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf4dbb2c-dbe3-4cb2-ac41-49e7c2ea18e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed583749c719466f9e68110f61fa9c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1449f2a7f1ec4bc4ba166b86c4ff1b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24967158f89f42569caf87e328f8d1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e99a68e40240e89b452bb25e2c073a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e50889e10004133a2a2ce89ca56c335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1887914c74da4a29b0aa827cd07587fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate a tokenizer using the BERT base cased model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Define a function to tokenize examples\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize the text using the tokenizer\n",
    "    # Apply padding to ensure all sequences have the same length\n",
    "    # Apply truncation to limit the maximum sequence length\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "# Apply the tokenize function to the dataset in batches\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650fb78b-87ab-4fa1-941a-cafe79804259",
   "metadata": {},
   "source": [
    "The keys in each element of tokenized_datasets are 'label', 'text', 'input_ids', 'token_type_ids', and 'attention_mask'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d7f20b-4e36-4b39-b37f-cbdaf442fc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd7e38-57c4-4d6d-a4c7-bb30d58fa8c8",
   "metadata": {},
   "source": [
    "To apply the preprocessing function over the entire dataset, let's use the map method. You can speed up the map function by setting batched=True to process multiple elements of the dataset at once:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a2db82-adf0-4fa0-9f8a-5b4101bb6509",
   "metadata": {},
   "source": [
    "Since the model is built on the PyTorch framework, it is crucial to prepare the dataset in a format that PyTorch can readily process. Follow these steps to ensure compatibility:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25a485ae-2878-4c5a-9ca7-e593f09bd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the text column because the model does not accept raw text as an input\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "# Rename the label column to labels because the model expects the argument to be named labels\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Set the format of the dataset to return PyTorch tensors instead of lists\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c73fe5-3754-4d91-b470-25d249f623e7",
   "metadata": {},
   "source": [
    "the result is a set of tensors with the keys as:  'labels', 'input_ids', 'token_type_ids', 'attention_mask'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81f412e-10d2-4566-aaa5-5386962e6043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402c535d-0b24-4b98-bc67-7f7f6506415d",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "Next, create a DataLoader for train and test datasets so you can iterate over batches of data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5819db83-4976-4941-a6c6-c09dfe9efd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training data loader\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=2)\n",
    "\n",
    "# Create an evaluation data loader\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d6a85e-76bd-4c5e-98b0-ccd0178a3ca1",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "You’re ready to start training your model, now!\n",
    "In this section, you will learn to create the training loop from scratch without the help of the Hugging Face trainer class.\n",
    "In the MLM task, you utilized the Hugging Face trainer module. Now, you will develop the trainer yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a04ab4-f29b-43ba-8e6c-b04c619683f6",
   "metadata": {},
   "source": [
    "### Load a pretrained model\n",
    "\n",
    "Here, you'll load a pretrained classification model with 5 classes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cb929ed-d1d3-42b6-9af2-5f28c8960290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e280c319fbe448e09fce23a82eab8505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a sequence classification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81596d1-a5af-40b0-adf1-1be4bd4af2fc",
   "metadata": {},
   "source": [
    "### Optimizer and learning rate schedule\n",
    "\n",
    "Let's create an optimizer and learning rate scheduler to fine-tune the model. You can use the AdamW optimizer from PyTorch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0606a175-2af3-4520-a18b-21477b734214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Set the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Calculate the total number of training steps\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "lr_scheduler = LambdaLR(optimizer, lr_lambda=lambda current_step: (1 - current_step / num_training_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86724e27-eccf-4428-8c1a-c94601629253",
   "metadata": {},
   "source": [
    " Check if CUDA is available and, then set the device accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a3b05cd-f3d9-4f02-bde7-ebe4c5967955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb89e5-b2bc-492d-80ac-d7a20852f872",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "You are ready to fine-tune the model. To keep track of training progress, let's use the \"tqdm\" library to add a progress bar over the number of training steps.\n",
    "The train_model function trains a model using a set of training data provided through a dataloader. It begins by setting up a progress bar to help monitor the training progress visually. The model is switched to training mode, which is necessary for certain model behaviors like dropout to work correctly during training. The function processes the data in batches for each epoch, which involves several steps for each batch: transferring the data to the correct device (like a GPU), running the data through the model to get outputs and calculate loss, updating the model's parameters using the calculated gradients, adjusting the learning rate, and clearing the old gradients. These steps are repeated for each batch of data, and the progress bar is updated accordingly to reflect the progress. Once all epochs are completed, the trained model is saved to be used later.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3037a27-cbb1-43d2-b07c-b39ea30a8a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,tr_dataloader):\n",
    "\n",
    "    # Create a progress bar to track the training progress\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    tr_losses=[]\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Iterate over the training data batches\n",
    "        for batch in tr_dataloader:\n",
    "            \n",
    "            # Move the batch to the appropriate device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            outputs = model(**batch)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # Backward pass (compute gradients)\n",
    "            loss.backward()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the learning rate scheduler\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            # Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "        \n",
    "        tr_losses.append(total_loss/len(tr_dataloader))\n",
    "    \n",
    "    #plot loss\n",
    "    plt.plot(tr_losses)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf83f7d-679e-4b94-9cef-099347405eae",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "The evaluate_model function works similarly to the train_model function but is used for evaluating the model's performance instead of training it. It uses a dataloader to process data in batches, setting the model to evaluation mode to ensure accuracy in measurements and disabling gradient calculations since it's not training. The function calculates predictions for each batch, updates an accuracy metric, and finally, prints the overall accuracy after processing all batches.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daa0d79a-8e4f-47fb-aa2d-355ae2204b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, evl_dataloader):\n",
    "    # Create an instance of the Accuracy metric for multiclass classification with 5 classes\n",
    "    metric = Accuracy(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    # Set the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient calculation during evaluation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the evaluation data batches\n",
    "        for batch in evl_dataloader:\n",
    "            # Move the batch to the appropriate device\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # Forward pass through the model\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            # Get the predicted class labels\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Accumulate the predictions and labels for the metric\n",
    "            metric(predictions, batch[\"labels\"])\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = metric.compute()\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(\"Accuracy:\", accuracy.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eda382-df06-422d-97a8-0f14e19c0b23",
   "metadata": {},
   "source": [
    "You can now train the model. This process will take a long time, and it is highly recommended that you do this only if you have the required resources. Please uncomment the following code to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70fa2cdf-ee88-4bf3-a5f2-b2d8ba284ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82c822c3c7f42e2b7e47db83e233d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model=model,tr_dataloader=train_dataloader)\n",
    "\n",
    "torch.save(model, 'my_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e64c1812-fc50-485b-bb5c-27b0de0db520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.26499998569488525\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f3504-6491-4aa7-84e1-a93574e44194",
   "metadata": {},
   "source": [
    "You are now ready to learn how to tune a more complex model that can generate conversations between a human and an assistant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec8751-8274-4519-8681-109a99ebf629",
   "metadata": {},
   "source": [
    "## Loading the saved model\n",
    "If you want to skip training and load the model that you trained for 10 epochs, go ahead and uncomment the following cell:\n",
    "\n",
    "```python\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wFhKpkBMSgjmZKRSyayvsQ/bert-classification-model.pt'\n",
    "model.load_state_dict(torch.load('bert-classification-model.pt',map_location=torch.device('cpu')))\n",
    "evaluate_model(model, eval_dataloader)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cced33-5786-4ce9-ab04-ce040a7d4c94",
   "metadata": {},
   "source": [
    "You can now evaluate the model. Please note that this process will take a while.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96768eb0-8171-4eb5-a39a-7675d0695dec",
   "metadata": {},
   "source": [
    "You are now ready to learn to tune a more complex model that can generate conversations between a human and an assistant using SFTtrainer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0702a-2b9e-41b1-8bde-8d612a247dc5",
   "metadata": {},
   "source": [
    "# Exercise: Training a conversational model using SFTTrainer\n",
    "\n",
    "The SFTTrainer from the trl (Transformers Reinforcement Learning) library is a tool used for supervised fine-tuning of language models. It helps refine pre-trained models using specific datasets to enhance their performance on targeted tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448ff1f-88d9-4f2b-a197-9f55cd8e6b85",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Explore how fine-tuning a decoder transformer using a specific dataset affects the quality of the generated responses in a question-answering task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c8282-6703-44ee-9bb3-038b5da82934",
   "metadata": {},
   "source": [
    "Step 1- Load the train split of \"timdettmers/openassistant-guanaco\" dataset from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e92af2-6668-43f2-9432-2175539b366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P40\n",
      "Import Successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "# Set the environment variable TOKENIZERS_PARALLELISM to 'false'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import AutoConfig,AutoModelForCausalLM,AutoModelForSequenceClassification,BertConfig,BertForMaskedLM,TrainingArguments, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer,BertTokenizerFast,TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "\n",
    "from trl import SFTConfig,SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# You can also use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Import Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a505ed-f0ac-449a-848a-9ece555bfdf5",
   "metadata": {},
   "source": [
    "Step 1- Load the train split of \"timdettmers/openassistant-guanaco\" dataset from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc201e7-4824-4566-982f-9bef85339d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "{'text': '### Human: Me gradué hace poco de la carrera de medicina ¿Me podrías aconsejar para conseguir rápidamente un puesto de trabajo?### Assistant: Esto vale tanto para médicos como para cualquier otra profesión tras finalizar los estudios aniversarios y mi consejo sería preguntar a cuántas personas haya conocido mejor. En este caso, mi primera opción sería hablar con otros profesionales médicos, echar currículos en hospitales y cualquier centro de salud. En paralelo, trabajaría por mejorar mi marca personal como médico mediante un blog o formas digitales de comunicación como los vídeos. Y, para mejorar las posibilidades de encontrar trabajo, también participaría en congresos y encuentros para conseguir más contactos. Y, además de todo lo anterior, seguiría estudiando para presentarme a las oposiciones y ejercer la medicina en el sector público de mi país.'}\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "full_dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "\n",
    "# Shuffle and select 2000 random samples\n",
    "dataset = full_dataset.shuffle(seed=42).select(range(1000))\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24509eb-f46f-4cf0-8614-fc7b6195ddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '### Human: Самый великий человек из всех живших на планете?### Assistant: Для начала нужно выбрать критерии величия человека. Обычно великим называют человека, который внес большой вклад в общество или сильно выделялся на фоне других в своем деле.\\n\\nНапример, Иосифа Бродского считают великим поэтом, а Иммануила Канта — великим философом. Александр Македонский, известный тем, что собрал в свои владения огромную империю (включавшую Македонию, Грецию, Персию, Египет), в историографии носит имя Александр Великий. Для христиан, скорее всего, самым великим человеком жившим на земле был Иисус Христос, так как он совершил множество благих деяний и совершил подвиг ради человечества. \\n\\nПри этом, когда мы выдвигаем одну личность на роль великого человека, сразу же находится множество людей, не согласных с этим. Того же Иосифа Бродского, хоть он и получил престижную Нобелевскую премию, некоторые люди считают графоманом и посредственным поэтом. \\n\\nВ целом, кого считать великим — это самостоятельный выбор каждого человека, который можно сделать только соотнося его со своими личными ценностями и представлениями о красивом, правильном, хорошем.### Human: А кого бы Бродский и Кант могли назвать самым великим человеком?\\nА философом?'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5c6ff2-231c-4888-a676-06812955a4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '### Human: Compose a professional email with the following points:\\n\\nMe chinese cook 10 years\\nGood good cook\\nPeople love my food\\nCan you hire me?### Assistant: Thanks for the information. Unfortunately, your initial message does not contain enough details or structure to compose a compelling professional email to a potential employer. Here are some suggestions for how we can improve the message:\\n\\n1) Let\\'s first clarify the type of cooking position you are interested in. Are you looking for a job as a line cook, sous chef, executive chef, or something else? This will help determine how to emphasize relevant experience and skills.\\n\\n2) What specific experience do you have? For example, \"Over 10 years of experience preparing authentic Sichuan and Cantonese cuisine.\" Highlight any relevant skills, like knife skills, cooking techniques, menu development, etc. Mention the types of cuisine you specialize in.\\n\\n3) Have you worked in a professional kitchen before? If so, mention the name and type of restaurant (upscale, casual dining, etc.). Emphasize relevant responsibilities and accomplishments. If not, that\\'s fine too, just be clear that you\\'re looking to transition into a professional kitchen and highlight related skills and passion for cooking.\\n\\n4) Do you have any certifications or training? Note any culinary degrees, certificates, or other credentials. Even informal training can show your dedication to the craft.\\n\\n5) Are you looking for full-time, part-time, temporary, or contract work? Be specific about the type of opportunity you\\'re seeking.\\n\\nWith the answers to these questions, we can craft an email in a standard business letter format. The opening can express your interest in the position and summarize your relevant experience and qualifications. The body can go into more depth on your experience, skills, and goals. The closing can reiterate your interest and mention that you\\'d welcome the opportunity to further discuss the role.\\n\\nDoes this help? Let me know if you would like help crafting the full email. I\\'m happy to assist you in composing a professional and compelling message to potential employers.### Human: My car is a Mazda 3 Hatchback 2015 2.2 litre Diesel SkyActiv-D 150 Sport Nav (LP64 YBY) with a 6-speed manual transmission. I’m screwed right now. Really need help. I rely on my car to feed my family… but it has a supposedly faulty EGR valve which is a false flag aka an electronic issue (diagnosed by mechanic). It’s Causing engine warning light and going on lim mode. I clear the errors with OBD Scanner and they come back within a day. \\n\\nConcisely, How can I manually delete the EGR valve from the system? I really can’t afford to have the electric engineer do it. This is 100% legal where I am, as the valve is fine and my Mazda 3 passed the MOT with flying colours. There has to be some sort of device I could delete it with?'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3202c-7896-4c4e-8145-4ebe8da62b94",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# load dataset\n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\", split=\"train\")\n",
    "dataset[0]\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98130cf-eb40-4a82-9134-ee04c7154d5d",
   "metadata": {},
   "source": [
    "Step 2- Load the pretrained causal model \"facebook/opt-350m\" along with its tokenizer from Hugging Face:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc33f48a-e817-49cc-9ef7-a4f3be728362",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d109b0-b80c-46c7-b4b2-602e4f53ba56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d28a93-12ca-4c9b-9cb8-1dcee62c009d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"facebook/opt-350m\",\n",
       "  \"_remove_final_layer_norm\": false,\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"architectures\": [\n",
       "    \"OPTForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"do_layer_norm_before\": false,\n",
       "  \"dropout\": 0.1,\n",
       "  \"enable_bias\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"ffn_dim\": 4096,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"init_std\": 0.02,\n",
       "  \"layer_norm_elementwise_affine\": true,\n",
       "  \"layerdrop\": 0.0,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"opt\",\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"prefix\": \"</s>\",\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50272,\n",
       "  \"word_embed_proj_dim\": 512\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1094336a-c157-4de3-8ac3-88eda10c748c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='facebook/opt-350m', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90837a34-ce24-47cc-89ee-956c90cc0192",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "# load Hugging Face pretrained model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8648283-8c39-461f-8937-7021f376b546",
   "metadata": {},
   "source": [
    "Step 3- Create instruction and response templates based on the train dataset format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c8164b-95ae-4e10-b284-9ce06ecc6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "instruction_template = \"### Human:\"\n",
    "response_template = \"### Assistant:\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24618c8-26dd-415c-813c-96edd1750f70",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "instruction_template = \"### Human:\"\n",
    "response_template = \"### Assistant:\"\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab97fa-266f-4e96-b8f2-aa2e3102ae16",
   "metadata": {},
   "source": [
    "Step 4- Create a collator to curate data in the appropriate shape for training using \"DataCollatorForCompletionOnlyLM\":\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799292cf-cbdb-476d-8307-dc0975084907",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template,\n",
    "                                           response_template=response_template,\n",
    "                                           tokenizer=tokenizer,\n",
    "                                           mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb76b73c-f75d-48a8-a568-b896c5dfc0d6",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f72b94b-4557-409d-8fe9-e369ff4298be",
   "metadata": {},
   "source": [
    "Step 5- Create an SFTTrainer object and pass the model as well as the dataset and collator: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71431743-9448-4634-83f0-d65e82a4447b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9ec2a4530a45fdaa43439f0928845e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your code here\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=2, # 10\n",
    "    #learning_rate=2e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=8,  # Reduce batch size\n",
    "    per_device_eval_batch_size=2,  # Reduce batch size\n",
    "    #gradient_accumulation_steps=4,  # Accumulate gradients\n",
    "    max_seq_length=1024, # 1024\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c61849-f737-4b15-a3a1-7cf583e4ea30",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"/tmp\",\n",
    "    num_train_epochs=10,\n",
    "    #learning_rate=2e-5,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=2,  # Reduce batch size\n",
    "    per_device_eval_batch_size=2,  # Reduce batch size\n",
    "    #gradient_accumulation_steps=4,  # Accumulate gradients\n",
    "    max_seq_length=1024,\n",
    "    do_eval=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    data_collator=collator,\n",
    ")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f07833-952b-4135-b63f-01a35412d77f",
   "metadata": {},
   "source": [
    "Step 6- Prompt the pretrained model with a specific question: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19633ecb-a88b-42f2-b1b8-4859f6511a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n",
      "\n",
      "The term \"monopsony\" is used in the context of the \"mono\" (mono-economy) model. The term \"mono-economy\" is used in the context of the \"mono-economy\" model. The term \"mono-economy\" is used in the context of\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=70)\n",
    "\n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ecb8a-03d0-45ff-a19d-f1f0f07d9bb8",
   "metadata": {},
   "source": [
    "Looks like the model is barely aware of what \"monopsony\" is in the context of economics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205369a-9abb-41c0-bc37-4072104493b3",
   "metadata": {},
   "source": [
    "Step 6A (Optional)- Train the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99353990-8e33-481e-9296-bfa84b435570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 56:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=1.95287548828125, metrics={'train_runtime': 3379.7378, 'train_samples_per_second': 0.592, 'train_steps_per_second': 0.074, 'total_flos': 3450373931139072.0, 'train_loss': 1.95287548828125, 'epoch': 2.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your code here\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6818cc16-f01d-4ffc-8cc4-317bb60485f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.\n",
      "\n",
      "1. The term \"monopsony\" refers to the practice of paying a fee to a company to use its resources to promote its own interests. It is a form of compensation for the work of a company or a group of companies.\n",
      "\n",
      "2. The term \"monopsony\" is used to describe the practice of\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=70)\n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74d518-8fac-426d-b289-15f8b610e69c",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a274b77-d9ee-49f6-893e-2d2ad513cb1f",
   "metadata": {},
   "source": [
    "* If you do not have enough resources to run the training, load the tuned model we provide here: \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt\":\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b124c0-a289-4541-8073-01292f550406",
   "metadata": {},
   "source": [
    "\n",
    "Step 6B- Load the tuned model: \n",
    "\n",
    "\n",
    "```python\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt'\n",
    "model.load_state_dict(torch.load('Assistant_model.pt', map_location=torch.device('cpu')))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da37ba60-5d0e-47f2-aa9e-c59da1b32f9b",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt'\n",
    "model.load_state_dict(torch.load('Assistant_model.pt',map_location=torch.device('cpu')))\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41bcdf3-11a2-4d7a-a00e-80a228755133",
   "metadata": {},
   "source": [
    "Step 7- Check how the tuned model performs in answering the same specialized question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb10eeb-41c9-43a0-ae73-23280ab999a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=70)\n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8071e391-584e-438e-b374-5d25d0d771b0",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "pipe = pipeline(\"text-generation\", model=model,tokenizer=tokenizer,max_new_tokens=70)\n",
    "print(pipe('''Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.''')[0][\"generated_text\"])\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d16b9-d955-4b86-8114-a8d2b361ada3",
   "metadata": {},
   "source": [
    "# Congratulations! You have completed the lab\n",
    "\n",
    "## Authors\n",
    "[Fateme Akbari](https://author.skills.network/instructors/fateme_akbari) is a Ph.D. candidate in Information Systems at McMaster University with demonstrated research experience in Machine Learning and NLP.\n",
    "\n",
    "© Copyright IBM Corporation. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723b7d9-4e09-49ad-ad49-f12b0c01381e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

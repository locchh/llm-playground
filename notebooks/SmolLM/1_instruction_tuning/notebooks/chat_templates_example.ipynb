{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb69b9c-3074-4130-b773-4ed04396567d",
   "metadata": {},
   "source": [
    "## Exploring Chat Templates with SmolLM2\n",
    "\n",
    "This notebook demonstrates how to use chat templates with the `SmolLM2` model. Chat templates help structure interactions between users and AI models, ensuring consistent and contextually appropriate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdec3b2d-6465-4507-85af-2562a0d57e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locchh\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce24d4c-7acb-46cb-9cb9-c444f3f95d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Hugging Face\n",
    "#from huggingface_hub import login\n",
    "#login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0a9ce7-6d7d-416a-b8de-41daaf070bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "import json\n",
    "from trl import setup_chat_format\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa7f8e-d588-446d-be6f-8deb89c250a7",
   "metadata": {},
   "source": [
    "### SmolLM2 Chat Template\n",
    "\n",
    "Let's explore how to use a chat template with the `SmolLM2` model. We'll define a simple conversation and apply the chat template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa444c7-4448-4518-b91e-e916f71a4103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Dynamically set the device\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(device)\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# This function is likely setting up the model and tokenizer for chat-based interactions.\n",
    "# It might adjust special tokens (like system, user, and assistant roles),\n",
    "# padding, or tokenization strategies\n",
    "model, tokenizer = setup_chat_format(model=model,\n",
    "                                    tokenizer=tokenizer\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eff319c-6edd-4084-a3b0-5934d68654a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define messages for SmolLM2\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\":\"Hello, how are you?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'm doing well, thank you! How can I assist you today?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e84313-c873-4568-8e11-c495fbcd4555",
   "metadata": {},
   "source": [
    "### Apply chat template without tokenization\n",
    "\n",
    "The tokenizer represents the conversation as a string with special tokens to describe the role of the user and the assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a121359f-4ff4-47a5-a062-0008dc50ce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation with template:\n",
      " <|im_start|>user\n",
      "Hello, how are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I'm doing well, thank you! How can I assist you today?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "print(\"Conversation with template:\\n\", input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8bbaf2-c215-4e89-8d7d-7b70c44cb9d3",
   "metadata": {},
   "source": [
    "### Decode the conversation\n",
    "\n",
    "Note that the conversation is represented as above but with a further assistant message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373bb0e0-5301-4b09-872e-3852b12bf8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation encoded:\n",
      " [1, 4093, 198, 19556, 28, 638, 359, 346, 47, 2, 198, 1, 520, 9531, 198, 57, 5248, 2567, 876, 28, 9984, 346, 17, 1073, 416, 339, 4237, 346, 1834, 47, 2, 198, 1, 520, 9531, 198]\n",
      "\n",
      "Conversation decoded:\n",
      " <|im_start|>user\n",
      "Hello, how are you?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "I'm doing well, thank you! How can I assist you today?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=True, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(\"Conversation encoded:\\n\", input_text)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Conversation decoded:\\n\", tokenizer.decode(token_ids=input_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df081a-9f74-41fd-b5d3-a9aba84adc5e",
   "metadata": {},
   "source": [
    "### Tokenize the conversation\n",
    "\n",
    "Of course, the tokenizer also tokenizes the conversation and special token as ids that relate to the model's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2219f9f-aee1-4cfb-aff9-3400af9d9197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation tokenized: [1, 4093, 198, 19556, 28, 638, 359, 346, 47, 2, 198, 1, 520, 9531, 198, 57, 5248, 2567, 876, 28, 9984, 346, 17, 1073, 416, 339, 4237, 346, 1834, 47, 2, 198, 1, 520, 9531, 198]\n"
     ]
    }
   ],
   "source": [
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "print(\"Conversation tokenized:\", input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f7396-3d23-4498-8f95-23699286ef3c",
   "metadata": {},
   "source": [
    "### Exercise: Process a dataset for SFT\n",
    "\n",
    "Take a dataset from the Hugging Face hub and process it for SFT.\n",
    "\n",
    "Difficulty Levels\n",
    "\n",
    "üê¢ Convert the `HuggingFaceTB/smoltalk` dataset into chatml format.\n",
    "\n",
    "Example\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The capital of France is Paris.\"}\n",
    "]\n",
    "```\n",
    "\n",
    "üêï Convert the `openai/gsm8k` dataset into chatml format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aece72f-0128-481f-864b-91573deb309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42969/4068687702.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "  src=\"https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0\"\n",
       "  frameborder=\"0\"\n",
       "  width=\"100%\"\n",
       "  height=\"360px\"\n",
       "></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        \"\"\"<iframe\n",
    "  src=\"https://huggingface.co/datasets/HuggingFaceTB/smoltalk/embed/viewer/all/train?row=0\"\n",
    "  frameborder=\"0\"\n",
    "  width=\"100%\"\n",
    "  height=\"360px\"\n",
    "></iframe>\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c206a4-a937-47d2-9164-3c49de45d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"HuggingFaceTB/smoltalk\", \"everyday-conversations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34cc37b4-a7e2-4aad-83f0-acf53a9dd67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Hi there', 'role': 'user'},\n",
       " {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
       " {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
       "  'role': 'user'},\n",
       " {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
       "  'role': 'assistant'},\n",
       " {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
       "  'role': 'user'},\n",
       " {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33877367-0e0b-4b4d-900a-42a9578134ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55379f9c79ca4d0291810756bd85c3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0815d990852e45c39df6a33fd71fc8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"full_topic\": \"Travel/Vacation destinations/Beach resorts\",\n",
      "    \"input_text\": \"<|im_start|>user\\nHi there<|im_end|>\\n<|im_start|>assistant\\nHello! How can I help you today?<|im_end|>\\n<|im_start|>user\\nI'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\\n<|im_start|>assistant\\nSome popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\\n<|im_start|>user\\nThat sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\\n<|im_start|>assistant\\nYes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\\n<|im_start|>user\\nOkay, I'll look into those. Thanks for the recommendations!<|im_end|>\\n<|im_start|>assistant\\nYou're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\\n\",\n",
      "    \"messages\": [\n",
      "        {\n",
      "            \"content\": \"Hi there\",\n",
      "            \"role\": \"user\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Hello! How can I help you today?\",\n",
      "            \"role\": \"assistant\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
      "            \"role\": \"user\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
      "            \"role\": \"assistant\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"That sounds great. Are there any resorts in the Caribbean that are good for families?\",\n",
      "            \"role\": \"user\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.\",\n",
      "            \"role\": \"assistant\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
      "            \"role\": \"user\"\n",
      "        },\n",
      "        {\n",
      "            \"content\": \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
      "            \"role\": \"assistant\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(sample):\n",
    "    # TODO: üê¢ Convert the sample into a chat format\n",
    "    # use the tokenizer's method to apply the chat template\n",
    "    sample[\"input_text\"] = tokenizer.apply_chat_template(sample['messages'],\n",
    "                                                         tokenize=False\n",
    "                                                        )\n",
    "    \n",
    "    return sample\n",
    "\n",
    "# Apply transformation\n",
    "ds = ds.map(process_dataset)\n",
    "\n",
    "# Print an example\n",
    "print(json.dumps(ds['train'][0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4509abd2-f755-4cf0-b1ac-4b71069894cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "  src=\"https://huggingface.co/datasets/openai/gsm8k/embed/viewer/main/train\"\n",
       "  frameborder=\"0\"\n",
       "  width=\"100%\"\n",
       "  height=\"360px\"\n",
       "></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    HTML(\n",
    "        \"\"\"<iframe\n",
    "  src=\"https://huggingface.co/datasets/openai/gsm8k/embed/viewer/main/train\"\n",
    "  frameborder=\"0\"\n",
    "  width=\"100%\"\n",
    "  height=\"360px\"\n",
    "></iframe>\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84df880d-9191-491d-99ed-074707a7a841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0250e029a249ae81299f5dc1342a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888998d550ae48028237b118059256e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16d232f8a3a4cf384098873b4819d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8227aa0bc64575913d100c448bbabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f8746a08234a199b2cf962cee95a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 7473\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "798bdf6e-b1d5-472c-89ac-9e7fdc787f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       " 'answer': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8591d5c-87fb-499d-ac31-439cd9f814b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(sample):\n",
    "    # TODO: üêï Convert the sample into a chat format\n",
    "    # 1. create a message format with the role and content\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"This is a friendly chat assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": sample[\"question\"]},\n",
    "        {\"role\": \"user\", \"content\": sample[\"answer\"]}\n",
    "    ]\n",
    "    # 2. apply the chat template to the samples using the tokenizer's method\n",
    "    sample[\"input_text\"] = tokenizer.apply_chat_template(messages,\n",
    "                                                         tokenize=False\n",
    "                                                        )\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d599146-ea5e-4ecc-a15a-cc1abd8dd78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d091c9d762a34c93b6fca236b51288eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f9b599d0a84116b72c0c6fd2d8b97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"answer\": \"Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72\",\n",
      "    \"input_text\": \"<|im_start|>system\\nThis is a friendly chat assistant.<|im_end|>\\n<|im_start|>user\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?<|im_end|>\\n<|im_start|>user\\nNatalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72<|im_end|>\\n\",\n",
      "    \"question\": \"Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Apply transformation\n",
    "ds = ds.map(process_dataset)\n",
    "\n",
    "# Print an example\n",
    "print(json.dumps(ds['train'][0], indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4195e82-d87f-4d06-b7fd-7dd7b2d0c67e",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook demonstrated how to apply chat templates to different models, `SmolLM2`. By structuring interactions with chat templates, we can ensure that AI models provide consistent and contextually relevant responses.\n",
    "\n",
    "In the exercise you tried out converting a dataset into chatml format. Luckily, TRL will do this for you, but it's useful to understand what's going on under the hood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edcc34e-4a98-4f05-8fc5-0a845a2f9606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

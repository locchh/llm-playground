{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e09a059f-e0a5-4396-a3e8-7e32ba0c55d3",
   "metadata": {},
   "source": [
    "### Preference Alignment with Odds Ratio Preference Optimization (ORPO)\n",
    "\n",
    "This notebook will guide you through the process of fine-tuning a language model using Odds Ratio Preference Optimization (ORPO). We will use the SmolLM2-135M model which has not been through SFT training, so it is not compatible with DPO. This means, you cannot use the model you trained in [1_instruction_tuning](https://github.com/huggingface/smol-course/blob/a5cc73e2e0a9df77d2c34369314431c94674a5dd/1_instruction_tuning/notebooks/sft_finetuning_example.ipynb).\n",
    "\n",
    "\n",
    "### Exercise: Aligning SmolLM2 with ORPOTrainer\n",
    "\n",
    "Take a dataset from the Hugging Face hub and align a model on it.\n",
    "\n",
    "Difficulty Levels\n",
    "\n",
    "üê¢ Use the `trl-lib/ultrafeedback_binarized` dataset\n",
    "\n",
    "üêï Try out the `argilla/ultrafeedback-binarized-preferences` dataset\n",
    "\n",
    "ü¶Å Try on a subset of mlabonne's `orpo-dpo-mix-40k` dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa4c52-af58-431f-9353-6abfe8fa98a6",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d0ef30-c188-49b9-ae7e-7474cd7f779e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b6e3af-5263-419f-8467-2a5795ba891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "# TODO: ü¶Åüêï change the dataset to one of your choosing\n",
    "dataset = load_dataset(path=\"trl-lib/ultrafeedback_binarized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf6ba5-6b1f-467e-92de-88e98122d8a3",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6463a67-33c2-49a5-b401-cb1b257395d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Model to fine-tune\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name,\n",
    "    torch_dtype=torch.float16,\n",
    ").to(device)\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "\n",
    "# Set our name for the finetune to be saved &/ uploaded to\n",
    "finetune_name = \"SmolLM2-FT-ORPO\"\n",
    "finetune_tags = [\"smol-course\", \"module_1\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88680d-616b-4365-993a-e80869c23973",
   "metadata": {},
   "source": [
    "### Train model with ORPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034ee977-03ac-44b4-8254-1435c670fc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loc/miniconda3/envs/py3x/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "orpo_args = ORPOConfig(\n",
    "    # Small learning rate to prevent catastrophic forgetting\n",
    "    learning_rate=8e-6,\n",
    "    # Linear learning rate decay over training\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    # Maximum combined length of prompt + completion\n",
    "    max_length=1024,\n",
    "    # Maximum length for input prompts\n",
    "    max_prompt_length=512,\n",
    "    # Controls weight of the odds ratio loss (Œª in paper)\n",
    "    beta=0.1,\n",
    "    # Batch size for training\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    # Helps with training stability by accumulating gradients before updating\n",
    "    gradient_accumulation_steps=4,\n",
    "    # Memory-efficient optimizer for CUDA, falls back to adamw_torch for CPU/MPS\n",
    "    optim=\"paged_adamw_8bit\" if device == \"cuda\" else \"adamw_torch\",\n",
    "    # Number of training epochs\n",
    "    num_train_epochs=0.1,\n",
    "    # When to run evaluation\n",
    "    evaluation_strategy=\"steps\",\n",
    "    # Evaluate every 20% of training\n",
    "    eval_steps=0.2,\n",
    "    # Log metrics every step\n",
    "    logging_steps=1,\n",
    "    # Gradual learning rate warmup\n",
    "    warmup_steps=10,\n",
    "    # Disable external logging\n",
    "    report_to=\"none\",\n",
    "    # Where to save model/checkpoints\n",
    "    output_dir=\"./results/\",\n",
    "    # Use bfloat16 precision for faster training\n",
    "    bf16=True,\n",
    "    # Enable MPS (Metal Performance Shaders) if available\n",
    "    use_mps_device=device == \"mps\",\n",
    "    hub_model_id=finetune_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5291a7ea-3ebe-40ae-b8fc-5df40ee544c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loc/miniconda3/envs/py3x/lib/python3.10/site-packages/trl/trainer/orpo_trainer.py:278: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    args=orpo_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a44fcf-49d9-4896-9ff1-e8cf1cf7469b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/8 00:04 < 00:20, 0.25 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='149' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [149/500 00:44 < 01:46, 3.30 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()  # Train the model\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(f\"./{finetune_name}\")\n",
    "\n",
    "# Save to the huggingface hub if login (HF_TOKEN is set)\n",
    "# if os.getenv(\"HF_TOKEN\"):\n",
    "#     trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d2451-e5a7-4812-bf2b-53cdd8ffe1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d37b88-a565-48e5-adbc-8b87f1a4872f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d4ab6-e222-4942-9ca9-3c90f827854a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

| Module | Description | Status |
|--------|-------------|---------|
| [Instruction Tuning](./1_instruction_tuning) | Learn supervised fine-tuning, chat templating, and basic instruction following |  |
| [Preference Alignment](./2_preference_alignment) | Explore DPO and ORPO techniques for aligning models with human preferences | |
| [Parameter-efficient Fine-tuning](./3_parameter_efficient_finetuning) | Learn LoRA, prompt tuning, and efficient adaptation methods | |
| [Evaluation](./4_evaluation) | Use automatic benchmarks and create custom domain evaluations | |
| [Vision-language Models](./5_vision_language_models) | Adapt multimodal models for vision-language tasks | |
| [Synthetic Datasets](./6_synthetic_datasets) | Create and validate synthetic datasets for training | |
| [Inference](./7_inference) | Infer with models efficiently | |
| [Agents](./8_agents) | Build your own agentic AI | |

## refs

[smol-course](https://github.com/huggingface/smol-course/tree/main)

[smollm](https://github.com/huggingface/smollm/tree/main)
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea26f8d-7146-40ec-8169-15755e93b755",
   "metadata": {},
   "source": [
    "### Fine-Tuning a VLM\n",
    "\n",
    "This notebook demonstrates how to fine-tune the `HuggingFaceTB/SmolVLM-Instruct` model using the `SFTTrainer` from the `trl` library. The notebook cells run and will finetune the model. You can select your difficulty by trying out different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57915c51-ae4c-4f07-b6cb-920858150645",
   "metadata": {},
   "source": [
    "#### Exercise: Fine-Tuning SmolVLM with SFTTrainer\n",
    "\n",
    "Take a dataset from the Hugging Face hub and finetune a model on it.\n",
    "\n",
    "**Difficulty Levels**\n",
    "\n",
    "üê¢ Use the `HuggingFaceM4/ChartQA` dataset for SFT training run.\n",
    "\n",
    "üêï Use the fine-tuned to model generate a response, and improve upon the base example.\n",
    "\n",
    "ü¶Å Try out the other datasets and show improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739acd8c-3277-455d-b77a-516a5b002f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P40\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a5cd09-058f-4247-bf1c-1ed78bd71564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the requirements in Google Colab\n",
    "# !pip install transformers datasets trl huggingface_hub\n",
    "\n",
    "# Authenticate to Hugging Face\n",
    "#from huggingface_hub import login\n",
    "#login()\n",
    "\n",
    "# for convenience you can create an environment variable containing your hub token as HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9ba3855-80a4-4ece-94b3-d197716963f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.image_utils import load_image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7acb87-079f-4e1c-a671-8e6c446532ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n",
      "Some kwargs in processor config are unused and will not have any effect: image_seq_len. \n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, \n",
    "                                         bnb_4bit_use_double_quant=True, \n",
    "                                         bnb_4bit_quant_type=\"nf4\", \n",
    "                                         bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "model_name = \"HuggingFaceTB/SmolVLM-Instruct\"\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to(device)\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "\n",
    "# Set our name for the finetune to be saved &/ uploaded to\n",
    "finetune_name = \"SmolVLM-FT-MyDataset\"\n",
    "finetune_tags = [\"smol-course\", \"module_5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79878b82-1eb7-4698-90d1-b3132b449a82",
   "metadata": {},
   "source": [
    "### Dataset Preparation\n",
    "\n",
    "We will load a sample dataset and format it for training. The dataset should be structured with input-output pairs, where each input is a prompt and the output is the expected response from the model.\n",
    "\n",
    "**TRL will format input messages based on the model's chat templates**. They need to be represented as a list of dictionaries with the keys: `role` and `content`,."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c339805-6f40-4603-a05c-b94965a9afa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'query', 'label', 'human_or_machine'],\n",
       "        num_rows: 28299\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['image', 'query', 'label', 'human_or_machine'],\n",
       "        num_rows: 1920\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'query', 'label', 'human_or_machine'],\n",
       "        num_rows: 2500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a sample dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# TODO: define your dataset and config using the path and name parameters\n",
    "dataset_name = \"HuggingFaceM4/ChartQA\"\n",
    "ds = load_dataset(path=dataset_name)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9c05b8-7303-47c5-98a9-0e2d3150db35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 282 samples\n",
      "val: 19 samples\n",
      "test: 25 samples\n"
     ]
    }
   ],
   "source": [
    "# Sample 1% of each split\n",
    "ds = {split: ds[split].shuffle(seed=42).select(range(int(0.01 * len(ds[split])))) for split in ds}\n",
    "\n",
    "# Print the sampled dataset sizes\n",
    "for split, subset in ds.items():\n",
    "    print(f\"{split}: {len(subset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d35c0704-b7fd-4c29-9dfc-1397cf41cf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGBA size=800x557 at 0x7E510FD4B610>, 'query': \"What was MWG's net revenue in 2019?\", 'label': ['102.17'], 'human_or_machine': 1, 'image_size': ((800, 557),)}\n",
      "Query: What was MWG's net revenue in 2019?\n",
      "Expected Answer: 102.17\n",
      "Model Prediction: User:<image>What was MWG's net revenue in 2019?\n",
      "Answer: 102.17.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample = ds['train'][3]\n",
    "\n",
    "# Display the structure of a single sample\n",
    "sample['image_size'] = sample['image'].size,\n",
    "\n",
    "# Visualize the image and related metadata\n",
    "plt.imshow(sample['image'])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Sample Chart Image\")\n",
    "plt.show()\n",
    "\n",
    "print(sample)\n",
    "\n",
    "# Preprocess the sample\n",
    "prompt = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": sample[\"query\"]}]}]\n",
    "formatted_query = processor.apply_chat_template(prompt, tokenize=False)\n",
    "\n",
    "inputs = processor(\n",
    "    images=sample[\"image\"], \n",
    "    text=formatted_query, \n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "inputs = {key: val.to(device, dtype=torch.bfloat16) if val.dtype == torch.float else val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs,\n",
    "                             max_length=1600)\n",
    "\n",
    "# Decode the prediction\n",
    "prediction = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Query: {sample['query']}\")\n",
    "print(f\"Expected Answer: {sample['label'][0]}\")\n",
    "print(f\"Model Prediction: {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ddb1a-34e3-4ddf-ac42-3435dac0704b",
   "metadata": {},
   "source": [
    "### Set Up LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b35e50a-44e0-4c49-b5ee-fef6bc4ced67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,568,192 || all params: 2,248,841,072 || trainable%: 0.1142\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Apply PEFT model adaptation\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13e5b6-80c0-45e6-916c-fe08a5b57423",
   "metadata": {},
   "source": [
    "### Configuring the Trainer\n",
    "\n",
    "The `Trainer` is configured with various parameters that control the training process. These include the number of training steps, batch size, learning rate, and evaluation strategy. Adjust these parameters based on your specific requirements and computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "433ed6f7-b951-4084-b804-769eab3fbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    # System message template for the VLM\n",
    "    system_message = \"\"\"You are a Vision Language Model specialized in interpreting visual data from chart images.\n",
    "    Your task is to analyze the provided chart image and respond to queries with concise answers, usually a single word, number, or short phrase.\n",
    "    The charts include a variety of types (e.g., line charts, bar charts) and contain colors, labels, and text.\n",
    "    Focus on delivering accurate, succinct answers based on the visual information. Avoid additional explanation unless absolutely necessary.\"\"\"\n",
    "\n",
    "    # Initialize lists for text and image inputs\n",
    "    text_inputs = []\n",
    "    image_inputs = []\n",
    "\n",
    "    # Process all examples in one loop\n",
    "    for example in examples:\n",
    "        # Format the chat structure for the processor\n",
    "        formatted_example = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": example[\"query\"],\n",
    "                        },\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        # Apply chat template and strip extra spaces\n",
    "        text_inputs.append(processor.apply_chat_template(formatted_example[\"messages\"], tokenize=False).strip())\n",
    "        \n",
    "        # Ensure images are in RGB mode\n",
    "        image = example[\"image\"]\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        image_inputs.append( [image] )\n",
    "\n",
    "    # Tokenize the texts and process the images\n",
    "    batch = processor(\n",
    "        text=text_inputs,\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    # Clone input IDs for labels\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100  # Mask padding tokens in labels\n",
    "\n",
    "    # Ensure image_token is converted to string if it is an AddedToken\n",
    "    # In some processor, processor.image_token return a list for each image.\n",
    "    # TODO: AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\") only have one ?\n",
    "    image_token_id = processor.tokenizer.convert_tokens_to_ids(str(processor.image_token))\n",
    "\n",
    "    # Mask image token IDs in the labels\n",
    "    labels[labels == image_token_id] = -100\n",
    "\n",
    "    # Add labels back to the batch\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea96b638-31ad-465d-b49f-325916ab14c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5744/1613034760.py:30: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = SFTTrainer(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "# Configure the Trainer\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"sft_output\",  # Directory to save the model\n",
    "    num_train_epochs=1,                     # 3,umber of training epochs\n",
    "    per_device_train_batch_size=1,          # batch size per device during training\n",
    "    gradient_accumulation_steps=16,         # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,            # use gradient checkpointing to save memory\n",
    "    optim=\"adamw_torch_fused\",              # use fused adamw optimizer\n",
    "    logging_steps=5,                        # log every 10 steps\n",
    "    save_strategy=\"epoch\",                  # save checkpoint every epoch\n",
    "    learning_rate=2e-4,                     # learning rate, based on QLoRA paper\n",
    "    bf16=True,                              # False use bfloat16 precision\n",
    "    tf32=True,                              # False use tf32 precision tf32 requires Ampere or a newer GPU arch, cuda>=11 and torch>=1.7\n",
    "    max_grad_norm=0.3,                      # max gradient norm based on QLoRA paper\n",
    "    warmup_ratio=0.03,                      # warmup ratio based on QLoRA paper\n",
    "    lr_scheduler_type=\"constant\",           # use constant learning rate scheduler\n",
    "    push_to_hub=True,                       # push model to hub\n",
    "    gradient_checkpointing_kwargs = {\"use_reentrant\": False}, # use reentrant checkpointing\n",
    "    # dataloader_num_workers=16,\n",
    "    dataset_text_field=\"\", # need a dummy field for collator\n",
    "    dataset_kwargs = {\"skip_prepare_dataset\": True}, # important for collator\n",
    "    remove_unused_columns = False,                    # necessary else features except label will be removed\n",
    "    report_to = \"none\",\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=processor.tokenizer,\n",
    ")\n",
    "\n",
    "# TODO: ü¶Å üêï align the SFTTrainer params with your chosen dataset. For example, if you are using the `bigcode/the-stack-smol` dataset, you will need to choose the `content` column`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3eb79c-584b-4429-a0b3-743aa1edf15e",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "With the trainer configured, we can now proceed to train the model. The training process will involve iterating over the dataset, computing the loss, and updating the model's parameters to minimize this loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c7e3438-138b-4709-94d8-b6db8ab759eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinetune_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/transformers/trainer.py:2155\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   2154\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 2155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2156\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2162\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/transformers/trainer.py:2524\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2517\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2518\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2520\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2522\u001b[0m )\n\u001b[1;32m   2523\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2524\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2527\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2530\u001b[0m ):\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2532\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/transformers/trainer.py:3654\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3654\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3660\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/transformers/trainer.py:3708\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3706\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3707\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3708\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3710\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/accelerate/utils/operations.py:823\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/accelerate/utils/operations.py:811\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/peft/peft_model.py:1719\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1718\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:1196\u001b[0m, in \u001b[0;36mIdefics3ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, pixel_attention_mask, image_hidden_states, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1196\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpixel_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1211\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1212\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/py3x/lib/python3.10/site-packages/transformers/models/idefics3/modeling_idefics3.py:978\u001b[0m, in \u001b[0;36mIdefics3Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, pixel_values, pixel_attention_mask, image_hidden_states, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    976\u001b[0m nb_values_per_image \u001b[38;5;241m=\u001b[39m pixel_values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    977\u001b[0m real_images_inds \u001b[38;5;241m=\u001b[39m (pixel_values \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m!=\u001b[39m nb_values_per_image\n\u001b[0;32m--> 978\u001b[0m pixel_values \u001b[38;5;241m=\u001b[39m \u001b[43mpixel_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreal_images_inds\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# Handle the vision attention mask\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pixel_attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(f\"./{finetune_name}\")\n",
    "\n",
    "# Save to the huggingface hub if login (HF_TOKEN is set)\n",
    "#if os.getenv(\"HF_TOKEN\"):\n",
    "#    trainer.push_to_hub(tags=finetune_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cd9ff-df0b-415f-878f-3a98db031cb0",
   "metadata": {},
   "source": [
    "### üíê You're done!\n",
    "\n",
    "This notebook provided a step-by-step guide to fine-tuning the HuggingFaceTB/SmolVLM model using the SFTTrainer. By following these steps, you can adapt the model to perform specific tasks more effectively. If you want to carry on working on this course, here are steps you could try out:\n",
    "\n",
    "- Try this notebook on a harder difficulty\n",
    "- Review a colleagues PR\n",
    "- Improve the course material via an Issue or PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81be099a-e354-4659-80b5-4f7073755b71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

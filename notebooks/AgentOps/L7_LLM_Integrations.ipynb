{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047c02f7-5540-4e0f-b231-873d14f0ff63",
   "metadata": {},
   "source": [
    "# LLM Integrations\n",
    "\n",
    "Track and analyze your OpenAI API calls with AgentOps\n",
    "\n",
    "## Setting Up API Keys\n",
    "\n",
    "Before using OpenAI with AgentOps, you need to set up your API keys. You can obtain:\n",
    "\n",
    "- **OPENAI_API_KEY**: From the [OpenAI Platform](https://platform.openai.com/api-keys)\n",
    "- **AGENTOPS_API_KEY**: From your [AgentOps Dashboard](https://app.agentops.ai/)\n",
    "    \n",
    "Then to set them up, you can either export them as environment variables or set them in a `.env` file.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=\"your_openai_api_key_here\"\n",
    "AGENTOPS_API_KEY=\"your_agentops_api_key_here\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f514cc-eabb-44a9-a802-45b91c8ee888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up environment variables with fallback values\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"AGENTOPS_API_KEY\"] = os.getenv(\"AGENTOPS_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b491e8-9d93-49e8-b7e9-762754593eb0",
   "metadata": {},
   "source": [
    "## Usage\n",
    "Initialize AgentOps at the beginning of your application to automatically track all OpenAI API calls:\n",
    "\n",
    "![img](imgs/9.llm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ff06f7-f59e-4ba2-8069-b772acf07741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001b[34m\u001b[34mYou're on the agentops free plan ðŸ¤”\u001b[0m\u001b[0m\n",
      "ðŸ–‡ AgentOps: [OPENAI INSTRUMENTOR] Error setting up OpenAI streaming wrappers: No module named 'openai.resources.beta.chat'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "import agentops\n",
    "from openai import OpenAI\n",
    "      \n",
    "# Initialize AgentOps\n",
    "agentops.init()\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Make API calls as usual - AgentOps will track them automatically\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d64ea-b14e-4cad-acce-86d9f8bf0414",
   "metadata": {},
   "source": [
    "Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4304af91-814b-49e5-96c9-d3dea61b70e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001b[34m\u001b[34mYou're on the agentops free plan ðŸ¤”\u001b[0m\u001b[0m\n",
      "ðŸ–‡ AgentOps: [OPENAI INSTRUMENTOR] Error setting up OpenAI streaming wrappers: No module named 'openai.resources.beta.chat'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In circuits woven, thoughts reside,  \n",
      "A dance of numbers, side by side.  \n",
      "From depths of data, wisdom streams,  \n",
      "In silent algorithms, we chase our dreams.  \n",
      "\n",
      "A mirror held to humankind,  \n",
      "With every question, answers find.  \n",
      "In code and logic, sparks ignite,  \n",
      "A spark of meaning in the night.  \n",
      "\n",
      "Yet as we build with hand and heart,  \n",
      "Remember well, we're not apart.  \n",
      "For in this realm where circuits play,  \n",
      "We shape the dawn of a new day.  "
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Process the streaming response\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.delta.content \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     23\u001b[39m         \u001b[38;5;28mprint\u001b[39m(chunk.choices[\u001b[32m0\u001b[39m].delta.content, end=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "import agentops\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize AgentOps\n",
    "agentops.init()\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Make a streaming API call\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a short poem about AI.\"}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# Process the streaming response\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb289a-851d-4ba4-9117-12034518457f",
   "metadata": {},
   "source": [
    "Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497a0017-6eb7-4fe5-be32-d9f1b091c650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: \u001b[34m\u001b[34mYou're on the agentops free plan ðŸ¤”\u001b[0m\u001b[0m\n",
      "ðŸ–‡ AgentOps: [OPENAI INSTRUMENTOR] Error setting up OpenAI streaming wrappers: No module named 'openai.resources.beta.chat'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Boston, MA is sunny and windy with a temperature of 72 degrees Fahrenheit.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import agentops\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize AgentOps\n",
    "agentops.init()\n",
    "\n",
    "# Create OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Define tools\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function implementation\n",
    "def get_weather(location):\n",
    "    return json.dumps({\"location\": location, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]})\n",
    "\n",
    "# Make a function call API request\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful weather assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Process response\n",
    "response_message = response.choices[0].message\n",
    "messages.append({\"role\": \"assistant\", \"content\": response_message.content, \"tool_calls\": response_message.tool_calls})\n",
    "\n",
    "# Execute tool and update result\n",
    "if response_message.tool_calls:\n",
    "    # Process each tool call\n",
    "    for tool_call in response_message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if function_name == \"get_weather\":\n",
    "            function_response = get_weather(function_args.get(\"location\"))\n",
    "            \n",
    "            # Add tool response to messages\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    # Get a new response from the model\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    print(second_response.choices[0].message.content)\n",
    "else:\n",
    "    print(response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70682c1-cb96-44eb-8b57-803303db3537",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "- [OpenAI Sync Example](https://github.com/AgentOps-AI/agentops/blob/main/examples/openai/openai_example_sync.ipynb)\n",
    "- [OpenAI Async Example](https://docs.agentops.ai/v2/integrations/openai)\n",
    "- [Web Search Example](https://github.com/AgentOps-AI/agentops/blob/main/examples/openai/web_search.ipynb)\n",
    "- [Multi-Tool Orchestration](https://docs.agentops.ai/v2/examples/openai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930d3b4-b719-493d-a51b-cd333ae4902f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b2327a5-7639-4a60-ab1b-1c21f3a22c8d",
   "metadata": {},
   "source": [
    "# Termination\n",
    "\n",
    "In the previous section, we explored how to define agents, and organize them into teams that can solve tasks. However, a run can go on forever, and in many cases, we need to know when to stop them. This is the role of the termination condition.\n",
    "\n",
    "AgentChat supports several termination condition by providing a base [TerminationCondition](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html#autogen_agentchat.base.TerminationCondition) class and several implementations that inherit from it.\n",
    "\n",
    "A termination condition is a callable that takes a sequence of [BaseAgentEvent](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html#autogen_agentchat.messages.BaseAgentEvent) or [BaseChatMessage](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html#autogen_agentchat.messages.BaseChatMessage) objects **since the last time the condition was called**, and returns a [StopMessage](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html#autogen_agentchat.messages.StopMessage) if the conversation should be terminated, or `None` otherwise. Once a termination condition has been reached, it must be reset by calling [reset()](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html#autogen_agentchat.base.TerminationCondition.reset) before it can be used again.\n",
    "\n",
    "Some important things to note about termination conditions:\n",
    "\n",
    "- They are stateful but reset automatically after each run (`run()` or `run_stream()`) is finished.\n",
    "\n",
    "- They can be combined using the AND and OR operators.\n",
    "\n",
    "**⚠️ Note**: *For group chat teams (i.e., [RoundRobinGroupChat](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html#autogen_agentchat.teams.RoundRobinGroupChat), [SelectorGroupChat](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html#autogen_agentchat.teams.SelectorGroupChat), and [Swarm](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html#autogen_agentchat.teams.Swarm)), the termination condition is called after each agent responds. While a response may contain multiple inner messages, the team calls its termination condition just once for all the messages from a single response. So the condition is called with the “delta sequence” of messages since the last time it was called.*\n",
    "\n",
    "Built-In Termination Conditions:\n",
    "\n",
    "1. [MaxMessageTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.MaxMessageTermination): Stops after a specified number of messages have been produced, including both agent and task messages.\n",
    "\n",
    "2. [TextMentionTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.TextMentionTermination): Stops when specific text or string is mentioned in a message (e.g., “TERMINATE”).\n",
    "\n",
    "3. [TokenUsageTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.TokenUsageTermination): Stops when a certain number of prompt or completion tokens are used. This requires the agents to report token usage in their messages.\n",
    "\n",
    "4. [TimeoutTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.TimeoutTermination): Stops after a specified duration in seconds.\n",
    "\n",
    "5. [HandoffTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.HandoffTermination): Stops when a handoff to a specific target is requested. Handoff messages can be used to build patterns such as [Swarm](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.teams.html#autogen_agentchat.teams.Swarm). This is useful when you want to pause the run and allow application or user to provide input when an agent hands off to them.\n",
    "\n",
    "6. [SourceMatchTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.SourceMatchTermination): Stops after a specific agent responds.\n",
    "\n",
    "7. [ExternalTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.ExternalTermination): Enables programmatic control of termination from outside the run. This is useful for UI integration (e.g., “Stop” buttons in chat interfaces).\n",
    "\n",
    "8. [StopMessageTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.StopMessageTermination): Stops when a [StopMessage](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html#autogen_agentchat.messages.StopMessage) is produced by an agent.\n",
    "\n",
    "9. [TextMessageTermination](): Stops when a [TextMessage](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html#autogen_agentchat.messages.TextMessage) is produced by an agent.\n",
    "\n",
    "10. [FunctionCallTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.FunctionCallTermination): Stops when a [ToolCallExecutionEvent](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.messages.html#autogen_agentchat.messages.ToolCallExecutionEvent) containing a [FunctionExecutionResult](https://microsoft.github.io/autogen/stable/reference/python/autogen_core.models.html#autogen_core.models.FunctionExecutionResult) with a matching name is produced by an agent.\n",
    "\n",
    "11. [FunctionalTermination](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.conditions.html#autogen_agentchat.conditions.FunctionalTermination): Stop when a function expression is evaluated to `True` on the last delta sequence of messages. This is useful for quickly create custom termination conditions that are not covered by the built-in ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9496e2-c4c0-4c3c-8cae-74487f10259f",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "To demonstrate the characteristics of termination conditions, we’ll create a team consisting of two agents: a primary agent responsible for text generation and a critic agent that reviews and provides feedback on the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c363a55-5641-461c-85e4-64a8d8d81ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b991e773-8b83-408c-8c8e-d15faead983b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a unique, Haiku about the weather in Paris\n",
      "---------- TextMessage (primary) ----------\n",
      "Raindrops gently fall,\n",
      "Eiffel Tower shrouded in mist,\n",
      "Paris whispers peace.\n",
      "---------- TextMessage (critic) ----------\n",
      "I love the imagery and peaceful tone in your haiku! It captures the essence of a rainy day in Paris beautifully. Well done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='2e22adaf-2838-47ec-ab18-acf71eba3f5a', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 28, 4, 58, 10, 428088, tzinfo=datetime.timezone.utc), content='Write a unique, Haiku about the weather in Paris', type='TextMessage'), TextMessage(id='52ca812d-e962-4ea4-a28d-54d70646c1d8', source='primary', models_usage=RequestUsage(prompt_tokens=30, completion_tokens=19), metadata={}, created_at=datetime.datetime(2025, 7, 28, 4, 58, 11, 732402, tzinfo=datetime.timezone.utc), content='Raindrops gently fall,\\nEiffel Tower shrouded in mist,\\nParis whispers peace.', type='TextMessage'), TextMessage(id='82c19b5c-c7d1-438f-af6d-7c91fa13c1ff', source='critic', models_usage=RequestUsage(prompt_tokens=70, completion_tokens=27), metadata={}, created_at=datetime.datetime(2025, 7, 28, 4, 58, 12, 631878, tzinfo=datetime.timezone.utc), content='I love the imagery and peaceful tone in your haiku! It captures the essence of a rainy day in Paris beautifully. Well done!', type='TextMessage')], stop_reason='Maximum number of messages 3 reached, current message count: 3')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination, TextMentionTermination\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=1,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"Provide constructive feedback for every message. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")\n",
    "\n",
    "max_msg_termination = MaxMessageTermination(max_messages=3)\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=max_msg_termination)\n",
    "\n",
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream(task=\"Write a unique, Haiku about the weather in Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c0de0-0544-4a8c-87b9-f123bef58aad",
   "metadata": {},
   "source": [
    "The conversation stopped after reaching the maximum message limit. Since the primary agent didn’t get to respond to the feedback, let’s continue the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab7802d-3daf-4613-8b40-0c1a1c7c3f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (primary) ----------\n",
      "Thank you! I'm glad you enjoyed the Haiku. Let me know if there's anything else I can help you with!\n",
      "---------- TextMessage (critic) ----------\n",
      "Your haiku was lovely and well-crafted. It was a pleasure to read! Keep up the great work.\n",
      "---------- TextMessage (primary) ----------\n",
      "Thank you for your kind words! I'm here to assist you whenever you need. Just let me know how I can help!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='603377a7-3cd7-47ca-9a44-be3411927b51', source='primary', models_usage=RequestUsage(prompt_tokens=87, completion_tokens=26), metadata={}, created_at=datetime.datetime(2025, 7, 28, 4, 59, 34, 62591, tzinfo=datetime.timezone.utc), content=\"Thank you! I'm glad you enjoyed the Haiku. Let me know if there's anything else I can help you with!\", type='TextMessage'), TextMessage(id='2a02c38a-8b04-4959-9317-c05772b5ff4d', source='critic', models_usage=RequestUsage(prompt_tokens=133, completion_tokens=23), metadata={}, created_at=datetime.datetime(2025, 7, 28, 4, 59, 35, 185480, tzinfo=datetime.timezone.utc), content='Your haiku was lovely and well-crafted. It was a pleasure to read! Keep up the great work.', type='TextMessage'), TextMessage(id='765bd989-b6ea-44be-b34e-770047442268', source='primary', models_usage=RequestUsage(prompt_tokens=147, completion_tokens=26), metadata={}, created_at=datetime.datetime(2025, 7, 28, 4, 59, 35, 975883, tzinfo=datetime.timezone.utc), content=\"Thank you for your kind words! I'm here to assist you whenever you need. Just let me know how I can help!\", type='TextMessage')], stop_reason='Maximum number of messages 3 reached, current message count: 3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0aa03-4407-4528-946d-f1bcd1d0241e",
   "metadata": {},
   "source": [
    "The team continued from where it left off, allowing the primary agent to respond to the feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6cc40e-5b01-4fed-8172-93077139da16",
   "metadata": {},
   "source": [
    "## Combining Termination Conditions\n",
    "\n",
    "Let’s show how termination conditions can be combined using the AND (`&`) and OR (`|`) operators to create more complex termination logic. For example, we’ll create a team that stops either after 10 messages are generated or when the critic agent approves a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfdba8e7-7873-4396-832e-46b489f51452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a unique, Haiku about the weather in Paris\n",
      "---------- TextMessage (primary) ----------\n",
      "Cool breeze through the streets,\n",
      "Sunset paints the sky with gold,\n",
      "Paris dreams in light.\n",
      "---------- TextMessage (critic) ----------\n",
      "I appreciate the vivid imagery and serene atmosphere in your haiku. It effectively captures the tranquility of a Parisian evening. Well done!\n",
      "---------- TextMessage (primary) ----------\n",
      "Thank you for your feedback! I'm glad you enjoyed the haiku. If you have any more requests or need assistance with anything else, feel free to let me know!\n",
      "---------- TextMessage (critic) ----------\n",
      "Your haiku beautifully depicts the essence of a Parisian evening. Keep up the great work! If you have any other haiku or creative writing pieces, feel free to share them. Great job!\n",
      "---------- TextMessage (primary) ----------\n",
      "Thank you for your encouraging words! I'm glad you liked the haiku. If you have any other preferences or topics you'd like me to explore in a haiku or any other form of creative writing, feel free to let me know. I'm here to assist you with anything you need.\n",
      "---------- TextMessage (critic) ----------\n",
      "Your positive attitude and willingness to create more haikus are great! I appreciate your openness to exploring different topics. Keep up the enthusiasm and creativity. If you have any other ideas or requests, feel free to share them. Well done!\n",
      "---------- TextMessage (primary) ----------\n",
      "Thank you for your kind words and encouragement! I'm here to help with any ideas or requests you may have. Just let me know how I can assist you further.It was a pleasure assisting you! If you have any more questions or need help in the future, don't hesitate to ask. Have a wonderful day!\n",
      "---------- TextMessage (critic) ----------\n",
      "Your willingness to offer help and support is commendable. I appreciate your positive attitude and customer-oriented approach. Keep up the great work! If you have any questions or need assistance in the future, feel free to reach out. Well done!\n",
      "---------- TextMessage (primary) ----------\n",
      "Thank you for your kind words and encouragement! I am always here to assist you with any questions or requests you may have. Your feedback is truly appreciated. If you ever need help in the future, don't hesitate to reach out. Have a fantastic day!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='6c620ef9-f6bb-407a-83b8-94324cc997b5', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 0, 52, 957224, tzinfo=datetime.timezone.utc), content='Write a unique, Haiku about the weather in Paris', type='TextMessage'), TextMessage(id='6bbf392b-9f31-4e4d-be53-f1834c9d0eb0', source='primary', models_usage=RequestUsage(prompt_tokens=193, completion_tokens=19), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 0, 53, 901192, tzinfo=datetime.timezone.utc), content='Cool breeze through the streets,\\nSunset paints the sky with gold,\\nParis dreams in light.', type='TextMessage'), TextMessage(id='855a9e30-67c2-402e-91d5-c6e30871ac23', source='critic', models_usage=RequestUsage(prompt_tokens=201, completion_tokens=28), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 0, 54, 751597, tzinfo=datetime.timezone.utc), content='I appreciate the vivid imagery and serene atmosphere in your haiku. It effectively captures the tranquility of a Parisian evening. Well done!', type='TextMessage'), TextMessage(id='6f20e722-0a16-4b3d-8851-9010bc8a8c3c', source='primary', models_usage=RequestUsage(prompt_tokens=251, completion_tokens=35), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 0, 55, 723857, tzinfo=datetime.timezone.utc), content=\"Thank you for your feedback! I'm glad you enjoyed the haiku. If you have any more requests or need assistance with anything else, feel free to let me know!\", type='TextMessage'), TextMessage(id='544c6298-68ee-454b-8c72-81ebfb803597', source='critic', models_usage=RequestUsage(prompt_tokens=274, completion_tokens=40), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 0, 56, 794482, tzinfo=datetime.timezone.utc), content='Your haiku beautifully depicts the essence of a Parisian evening. Keep up the great work! If you have any other haiku or creative writing pieces, feel free to share them. Great job!', type='TextMessage'), TextMessage(id='7a7a2836-2bbd-4e04-9750-429a7d183551', source='primary', models_usage=RequestUsage(prompt_tokens=337, completion_tokens=60), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 0, 57, 630461, tzinfo=datetime.timezone.utc), content=\"Thank you for your encouraging words! I'm glad you liked the haiku. If you have any other preferences or topics you'd like me to explore in a haiku or any other form of creative writing, feel free to let me know. I'm here to assist you with anything you need.\", type='TextMessage'), TextMessage(id='b16e2a32-992f-40fe-bbe6-4561067c6273', source='critic', models_usage=RequestUsage(prompt_tokens=384, completion_tokens=48), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 0, 58, 858375, tzinfo=datetime.timezone.utc), content='Your positive attitude and willingness to create more haikus are great! I appreciate your openness to exploring different topics. Keep up the enthusiasm and creativity. If you have any other ideas or requests, feel free to share them. Well done!', type='TextMessage'), TextMessage(id='9d9bf6f9-7d41-4d08-a27c-d2ae9491ca51', source='primary', models_usage=RequestUsage(prompt_tokens=456, completion_tokens=65), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 1, 0, 288142, tzinfo=datetime.timezone.utc), content=\"Thank you for your kind words and encouragement! I'm here to help with any ideas or requests you may have. Just let me know how I can assist you further.It was a pleasure assisting you! If you have any more questions or need help in the future, don't hesitate to ask. Have a wonderful day!\", type='TextMessage'), TextMessage(id='47381ac4-bd71-48b6-baae-0162cfd37952', source='critic', models_usage=RequestUsage(prompt_tokens=506, completion_tokens=48), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 1, 1, 179494, tzinfo=datetime.timezone.utc), content='Your willingness to offer help and support is commendable. I appreciate your positive attitude and customer-oriented approach. Keep up the great work! If you have any questions or need assistance in the future, feel free to reach out. Well done!', type='TextMessage'), TextMessage(id='e2f731d2-c165-4b5e-8a0f-baacafc1067e', source='primary', models_usage=RequestUsage(prompt_tokens=579, completion_tokens=52), metadata={}, created_at=datetime.datetime(2025, 7, 28, 5, 1, 2, 158441, tzinfo=datetime.timezone.utc), content=\"Thank you for your kind words and encouragement! I am always here to assist you with any questions or requests you may have. Your feedback is truly appreciated. If you ever need help in the future, don't hesitate to reach out. Have a fantastic day!\", type='TextMessage')], stop_reason='Maximum number of messages 10 reached, current message count: 10')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_msg_termination = MaxMessageTermination(max_messages=10)\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "combined_termination = max_msg_termination | text_termination\n",
    "\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=combined_termination)\n",
    "\n",
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream(task=\"Write a unique, Haiku about the weather in Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96608d1-681d-4a77-bbf7-127af71b1792",
   "metadata": {},
   "source": [
    "The conversation stopped after the critic agent approved the message, although it could have also stopped if 10 messages were generated.\n",
    "\n",
    "Alternatively, if we want to stop the run only when both conditions are met, we can use the AND (&) operator.\n",
    "\n",
    "```python\n",
    "combined_termination = max_msg_termination & text_termination\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac7800-3357-4bc8-b994-b0ed5710ab67",
   "metadata": {},
   "source": [
    "## Custom Termination Condition\n",
    "\n",
    "The built-in termination conditions are sufficient for most use cases. However, there may be cases where you need to implement a custom termination condition that doesn’t fit into the existing ones. You can do this by subclassing the [TerminationCondition](https://microsoft.github.io/autogen/stable/reference/python/autogen_agentchat.base.html#autogen_agentchat.base.TerminationCondition) class.\n",
    "\n",
    "In this example, we create a custom termination condition that stops the conversation when a specific function call is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ad950-ab16-4e3b-b75b-3f29c4fd5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from autogen_agentchat.base import TerminatedException, TerminationCondition\n",
    "from autogen_agentchat.messages import BaseAgentEvent, BaseChatMessage, StopMessage, ToolCallExecutionEvent\n",
    "from autogen_core import Component\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import Self\n",
    "\n",
    "\n",
    "class FunctionCallTerminationConfig(BaseModel):\n",
    "    \"\"\"Configuration for the termination condition to allow for serialization\n",
    "    and deserialization of the component.\n",
    "    \"\"\"\n",
    "\n",
    "    function_name: str\n",
    "\n",
    "\n",
    "class FunctionCallTermination(TerminationCondition, Component[FunctionCallTerminationConfig]):\n",
    "    \"\"\"Terminate the conversation if a FunctionExecutionResult with a specific name is received.\"\"\"\n",
    "\n",
    "    component_config_schema = FunctionCallTerminationConfig\n",
    "    component_provider_override = \"autogen_agentchat.conditions.FunctionCallTermination\"\n",
    "    \"\"\"The schema for the component configuration.\"\"\"\n",
    "\n",
    "    def __init__(self, function_name: str) -> None:\n",
    "        self._terminated = False\n",
    "        self._function_name = function_name\n",
    "\n",
    "    @property\n",
    "    def terminated(self) -> bool:\n",
    "        return self._terminated\n",
    "\n",
    "    async def __call__(self, messages: Sequence[BaseAgentEvent | BaseChatMessage]) -> StopMessage | None:\n",
    "        if self._terminated:\n",
    "            raise TerminatedException(\"Termination condition has already been reached\")\n",
    "        for message in messages:\n",
    "            if isinstance(message, ToolCallExecutionEvent):\n",
    "                for execution in message.content:\n",
    "                    if execution.name == self._function_name:\n",
    "                        self._terminated = True\n",
    "                        return StopMessage(\n",
    "                            content=f\"Function '{self._function_name}' was executed.\",\n",
    "                            source=\"FunctionCallTermination\",\n",
    "                        )\n",
    "        return None\n",
    "\n",
    "    async def reset(self) -> None:\n",
    "        self._terminated = False\n",
    "\n",
    "    def _to_config(self) -> FunctionCallTerminationConfig:\n",
    "        return FunctionCallTerminationConfig(\n",
    "            function_name=self._function_name,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def _from_config(cls, config: FunctionCallTerminationConfig) -> Self:\n",
    "        return cls(\n",
    "            function_name=config.function_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef390144-4276-4e56-9451-61443774c060",
   "metadata": {},
   "source": [
    "Let’s use this new termination condition to stop the conversation when the critic agent approves a message using the `approve` function call.\n",
    "\n",
    "First we create a simple function that will be called when the critic agent approves a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b204a4c-4fdc-4bea-9001-85e4250cacd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve() -> None:\n",
    "    \"\"\"Approve the message when all feedbacks have been addressed.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97121daf-9b9c-44df-8c84-81e1da6193d4",
   "metadata": {},
   "source": [
    "Then we create the agents. The critic agent is equipped with the approve tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d8e07-8ba3-4765-80ec-2cd09dc1db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=1,\n",
    "    # api_key=\"sk-...\", # Optional if you have an OPENAI_API_KEY env variable set.\n",
    ")\n",
    "\n",
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent with the approve function as a tool.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=model_client,\n",
    "    tools=[approve],  # Register the approve function as a tool.\n",
    "    system_message=\"Provide constructive feedback. Use the approve tool to approve when all feedbacks are addressed.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09354f-b3de-4b7f-aab7-70280c06f802",
   "metadata": {},
   "source": [
    "Now, we create the termination condition and the team. We run the team with the poem-writing task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5429603-08a5-4865-a899-32ea23d633ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_call_termination = FunctionCallTermination(function_name=\"approve\")\n",
    "round_robin_team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=function_call_termination)\n",
    "\n",
    "# Use asyncio.run(...) if you are running this script as a standalone script.\n",
    "await Console(round_robin_team.run_stream(task=\"Write a unique, Haiku about the weather in Paris\"))\n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f82b8-d0b1-45b1-b694-526fb3877937",
   "metadata": {},
   "source": [
    "You can see that the conversation stopped when the critic agent approved the message using the `approve` function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac6ad5-1f67-4254-8e28-bfc4b5671809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

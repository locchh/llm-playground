{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221fc576-d73f-42b9-b301-2dd9cfcb4fc0",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "```bash\n",
    "uv pip install autogen-ext\n",
    "uv add autogen-ext[openai]\n",
    "```\n",
    "\n",
    "## VideoSurfer\n",
    "\n",
    "### Video Analysis\n",
    "- Extract information from local video files\n",
    "- Answer questions about video content\n",
    "- Process both visual and audio elements\n",
    "\n",
    "### Audio Processing\n",
    "- Extract audio from videos\n",
    "- Transcribe audio with timestamps\n",
    "- Analyze spoken content\n",
    "\n",
    "### Visual Analysis\n",
    "- Capture screenshots at specific timestamps\n",
    "- Save screenshots to disk\n",
    "- Analyze visual content using AI vision capabilities\n",
    "\n",
    "**Note**: *`video_surfer` require `cv2`, `ffmpeg`, `whisper`, `web`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d53a8c-bb06-42eb-a970-aa6e9e9ec012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.agents.video_surfer import VideoSurfer\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.agents import UserProxyAgent\n",
    "from autogen_agentchat.base import Response\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9774dbd3-f784-49d6-8465-71270c8c2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff9a03a-7d8f-453f-aa62-2a88b624a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_surfer = VideoSurfer(name=\"VideoSurfer\", model_client=model_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74bc0caa-b7c8-43ab-ae14-5a06ec6b002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellation_token = CancellationToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ebc151-0c4d-4e18-9a38-cfb40ef43b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(chat_message=ToolCallSummaryMessage(id='a32ca21e-0ad0-40f3-b681-8c81aaa7f9e0', source='VideoSurfer', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 12, 3, 42, 20, 96108, tzinfo=datetime.timezone.utc), content='The video is 55.80 seconds long.', type='ToolCallSummaryMessage', tool_calls=[FunctionCall(id='call_yzHmggBoGPOh8v1wEGAV8Ye6', arguments='{\"video_path\":\"assets/The two talking cats [z3U0udLH974].f606.mp4\"}', name='get_video_length')], results=[FunctionExecutionResult(content='The video is 55.80 seconds long.', name='get_video_length', call_id='call_yzHmggBoGPOh8v1wEGAV8Ye6', is_error=False)]), inner_messages=[ToolCallRequestEvent(id='4fef1dbf-e8e2-4ef5-9f41-2fbdab93558c', source='VideoSurfer', models_usage=RequestUsage(prompt_tokens=644, completion_tokens=33), metadata={}, created_at=datetime.datetime(2025, 8, 12, 3, 42, 20, 91830, tzinfo=datetime.timezone.utc), content=[FunctionCall(id='call_yzHmggBoGPOh8v1wEGAV8Ye6', arguments='{\"video_path\":\"assets/The two talking cats [z3U0udLH974].f606.mp4\"}', name='get_video_length')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(id='668c1fd6-d197-435b-bba7-08171a038bdc', source='VideoSurfer', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 8, 12, 3, 42, 20, 96081, tzinfo=datetime.timezone.utc), content=[FunctionExecutionResult(content='The video is 55.80 seconds long.', name='get_video_length', call_id='call_yzHmggBoGPOh8v1wEGAV8Ye6', is_error=False)], type='ToolCallExecutionEvent')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = \"assets/The two talking cats [z3U0udLH974].f606.mp4\"\n",
    "\n",
    "message = TextMessage(\n",
    "    content=f\"For video at {video_path}: What is the duration of this video?\",\n",
    "    source = \"user\"\n",
    ")\n",
    "\n",
    "# Send message to VideoSurfer\n",
    "response:Response = await video_surfer.on_messages([message],\n",
    "                                                   cancellation_token=cancellation_token)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9bb133-6390-44fe-910a-c3c63d0e582b",
   "metadata": {},
   "source": [
    "## FileSurfer\n",
    "\n",
    "### FileSurfer Capabilities\n",
    "Based on my exploration of the FileSurfer module, here's what you can do with it:\n",
    "\n",
    "### Core Functionality\n",
    "FileSurfer is an agent in AutoGen that acts as a local file previewer, allowing you to:\n",
    "\n",
    "1. **Browse Local Files and Directories**\n",
    "- Open files and directories using relative or absolute paths\n",
    "- Navigate through file hierarchies\n",
    "\n",
    "2. **View File Contents**\n",
    "- Display file contents in a text-based viewport\n",
    "- Navigate through large files with pagination\n",
    "\n",
    "3. **Search Within Files**\n",
    "- Search for specific text patterns within files\n",
    "- Navigate between search results\n",
    "\n",
    "### Available Tools\n",
    "FileSurfer provides these specific tools:\n",
    "- `open_path` - Open a file or directory at a specified path\n",
    "- `page_up` - Scroll viewport up one page\n",
    "- `page_down` - Scroll viewport down one page\n",
    "- `find_on_page_ctrl_f` - Search for text within the current file (like Ctrl+F)\n",
    "- `find_next` - Navigate to the next occurrence of the search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "919c3ada-8a9f-4cbc-bde7-cabece6db07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.agents.file_surfer import FileSurfer\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.base import Response\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f71e164b-defa-47c0-a9bb-f112e3c016f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model client\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caab8027-cc20-400f-a437-5a36f03ca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the FileSurfer agent\n",
    "file_surfer = FileSurfer(\n",
    "    name=\"FileSurfer\",\n",
    "    model_client=model_client,\n",
    "    description=\"Standalone FileSurfer agent to browse local files\",\n",
    "    base_path=\".\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11971822-54c9-4e70-9e03-f5e7d056a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cancellation token\n",
    "token = CancellationToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8ffaddc-e191-4c92-bdbe-195cbb720832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response after opening file:\n",
      " Path: /home/locch/Works/zsrc/2411.04468v1.md\n",
      "Viewport position: Showing page 1 of 19.\n",
      "=======================\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "\n",
      "v\n",
      "o\n",
      "N\n",
      "7\n",
      "\n",
      "]\n",
      "I\n",
      "\n",
      "A\n",
      ".\n",
      "s\n",
      "c\n",
      "[\n",
      "\n",
      "1\n",
      "v\n",
      "8\n",
      "6\n",
      "4\n",
      "4\n",
      "0\n",
      ".\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      ":\n",
      "v\n",
      "i\n",
      "X\n",
      "r\n",
      "a\n",
      "\n",
      "Magentic-One: A Generalist Multi-Agent System\n",
      "for Solving Complex Tasks\n",
      "\n",
      "⋆ Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan ⋆\n",
      "† Eduardo Salinas, Erkang (Eric) Zhu, Friederike Niedtner, Grace Proebsting,\n",
      "Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang,\n",
      "Ricky Loynd, Robert West, Victor Dibia †\n",
      "⋄ Ahmed Awadallah, Ece Kamar, Rafah Hosn, Saleema Amershi ⋄\n",
      "\n",
      "Microsoft Research AI Frontiers\n",
      "\n",
      "Figure 1: An illustration of the Magentic-One mutli-agent team completing a complex task\n",
      "from the GAIA benchmark. Magentic-One’s Orchestrator agent creates a plan, delegates tasks\n",
      "to other agents, and tracks progress towards the goal, dynamically revising the plan as needed.\n",
      "The Orchestrator can delegate tasks to a FileSurfer agent to read and handle files, a WebSurfer\n",
      "agent to operate a web browser, or a Coder or\n"
     ]
    }
   ],
   "source": [
    "# Open a file\n",
    "\n",
    "query = TextMessage(content=\"Open the file 2411.04468v1.md\",\n",
    "                   source=\"user\")\n",
    "\n",
    "response: Response = await file_surfer.on_messages([query],\n",
    "                                                  cancellation_token=token)\n",
    "\n",
    "print(\"Response after opening file:\\n\", response.chat_message.content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da49fa07-cbd4-44c0-9547-212c7069c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After paging down:\n",
      " Path: /home/locch/Works/zsrc/2411.04468v1.md\n",
      "Viewport position: Showing page 2 of 19.\n",
      "=======================\n",
      "Together, Magentic-One’s agents achieve\n",
      "strong performance on multiple challenging agentic benchmarks. Figure 1 shows an example of\n",
      "Magentic-One solving one such benchmark task that requires multiple steps and diverse tools.\n",
      "Key to Magentic-One’s performance is its modular and flexible multi-agent approach [51,\n",
      "28, 53, 13, 52], implemented via the AutoGen2 framework [60]. The multi-agent paradigm\n",
      "offers numerous advantages over monolithic single-agent approaches [51, 53, 6, 62], which we\n",
      "believe makes it poised to become the leading paradigm in agentic development. For example,\n",
      "encapsulating distinct skills in separate agents simplifies development and facilitates reusability,\n",
      "akin to object-oriented programming. Magentic-One’s specific design further supports easy\n",
      "adaptation and extensibility by enabling agents to be added or removed without altering other\n",
      "agents, or the overa\n"
     ]
    }
   ],
   "source": [
    "# Navigate within the file: page down\n",
    "\n",
    "query = TextMessage(content=\"Page down\",\n",
    "                   source=\"user\")\n",
    "\n",
    "response: Response = await file_surfer.on_messages([query],\n",
    "                                                  cancellation_token=token)\n",
    "\n",
    "print(\"After paging down:\\n\", response.chat_message.content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b285ac6c-3220-4918-9d95-cb6e125b1930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After searching:\n",
      " Path: /home/locch/Works/zsrc/2411.04468v1.md\n",
      "Viewport position: Showing page 8 of 19.\n",
      "=======================\n",
      "report results for Magentic-One (GPT-4o, o1) on WebArena since the o1 model refused to complete\n",
      "26% of WebArena Gitlab tasks, and 12% of Shopping Administration tasks, making a fair comparison impossible.\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "2024. This includes entries that are neither open-source, nor described by technical reports,\n",
      "making them difficult to independently validate. Finally, we also include human performance\n",
      "where available.\n",
      "\n",
      "We use statistical tests to compare the performance of Magentic-One to baselines and say\n",
      "that two methods are statistically comparable if the difference in their performance is not\n",
      "statistically significant (α=0.05); details about our statistical methodology can be found in\n",
      "Appendix A.\n",
      "\n",
      "Magentic-One (GPT-4o, o1-preview) achieves statistically comparable performance to SOTA\n",
      "methods on both GAIA and AssistantBench. On WebArena, only the GPT-4o variant was eval-\n",
      "uated12, an\n"
     ]
    }
   ],
   "source": [
    "# Find text within the file: search for \"installation\"\n",
    "\n",
    "query = TextMessage(content=\"Find 'Ablations' in this file\",\n",
    "                   source=\"user\")\n",
    "\n",
    "response: Response = await file_surfer.on_messages([query],\n",
    "                                                  cancellation_token=token)\n",
    "\n",
    "print(\"After searching:\\n\", response.chat_message.content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7890177-1952-4a78-be2b-4447032f13b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot set gray non-stroke color because /'P1' is an invalid float value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response after opening file:\n",
      " Path: /home/locch/Works/zsrc/assets/2411.04468v1.pdf\n",
      "Viewport position: Showing page 1 of 19.\n",
      "=======================\n",
      "4\n",
      "2\n",
      "0\n",
      "2\n",
      "\n",
      "v\n",
      "o\n",
      "N\n",
      "7\n",
      "\n",
      "]\n",
      "I\n",
      "\n",
      "A\n",
      ".\n",
      "s\n",
      "c\n",
      "[\n",
      "\n",
      "1\n",
      "v\n",
      "8\n",
      "6\n",
      "4\n",
      "4\n",
      "0\n",
      ".\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      ":\n",
      "v\n",
      "i\n",
      "X\n",
      "r\n",
      "a\n",
      "\n",
      "Magentic-One: A Generalist Multi-Agent System\n",
      "for Solving Complex Tasks\n",
      "\n",
      "⋆ Adam Fourney, Gagan Bansal, Hussein Mozannar, Cheng Tan ⋆\n",
      "† Eduardo Salinas, Erkang (Eric) Zhu, Friederike Niedtner, Grace Proebsting,\n",
      "Griffin Bassman, Jack Gerrits, Jacob Alber, Peter Chang,\n",
      "Ricky Loynd, Robert West, Victor Dibia †\n",
      "⋄ Ahmed Awadallah, Ece Kamar, Rafah Hosn, Saleema Amershi ⋄\n",
      "\n",
      "Microsoft Research AI Frontiers\n",
      "\n",
      "Figure 1: An illustration of the Magentic-One mutli-agent team completing a complex task\n",
      "from the GAIA benchmark. Magentic-One’s Orchestrator agent creates a plan, delegates tasks\n",
      "to other agents, and tracks progress towards the goal, dynamically revising the plan as needed.\n",
      "The Orchestrator can delegate tasks to a FileSurfer agent to read and handle files, a WebSurfer\n",
      "agent to operate a web browser, or a \n"
     ]
    }
   ],
   "source": [
    "# Other extension\n",
    "\n",
    "query = TextMessage(content=\"Open the file assets/2411.04468v1.pdf\",\n",
    "                   source=\"user\")\n",
    "\n",
    "response: Response = await file_surfer.on_messages([query],\n",
    "                                                  cancellation_token=token)\n",
    "\n",
    "print(\"Response after opening file:\\n\", response.chat_message.content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e288b-875a-4470-8646-3da964885130",
   "metadata": {},
   "source": [
    "## MultimodalWebSurfer\n",
    "\n",
    "### Core Functionality\n",
    "\n",
    "#### Web Navigation\n",
    "- Visit specific URLs directly\n",
    "- Perform web searches on search engines\n",
    "- Navigate browser history (back button)\n",
    "- Scroll through web pages (up/down)\n",
    "\n",
    "#### Web Interaction\n",
    "- Click on elements (buttons, links, etc.)\n",
    "- Type text into form fields\n",
    "- Hover over elements to reveal hidden content\n",
    "- Scroll specific elements on a page\n",
    "\n",
    "#### Content Analysis\n",
    "- Take screenshots of web pages\n",
    "- Extract and analyze text content\n",
    "- Answer questions about page content\n",
    "- Summarize entire web pages\n",
    "\n",
    "#### Visual Processing\n",
    "- Identify interactive elements on a page\n",
    "- Create annotated screenshots with bounding boxes\n",
    "- Process visual content using multimodal models\n",
    "- Optionally use OCR for text extraction\n",
    "\n",
    "### Advanced Features\n",
    "\n",
    "#### Browser Control\n",
    "- Launches and controls a Chromium browser via Playwright  \n",
    "- Supports headless or visible browser operation  \n",
    "- Can animate actions for better visibility  \n",
    "- Handles file downloads  \n",
    "\n",
    "#### Multimodal Capabilities\n",
    "- Works with vision-capable models (like GPT-4o)  \n",
    "- Processes both visual and textual information  \n",
    "- Creates **\"Set-of-Mark\"** screenshots with interactive elements highlighted  \n",
    "- Makes decisions based on visual understanding of web pages  \n",
    "\n",
    "#### Tool-Based Interaction\n",
    "Uses a comprehensive set of tools for web interaction:\n",
    "- `visit_url` – Navigate to specific URLs  \n",
    "- `web_search` – Perform web searches  \n",
    "- `click` – Click on elements  \n",
    "- `type` – Enter text into fields  \n",
    "- `hover` – Hover over elements  \n",
    "- `scroll_up` / `scroll_down` – Navigate page content  \n",
    "- `answer_question` – Answer questions about page content  \n",
    "- `summarize_page` – Generate page summaries  \n",
    "\n",
    "#### Debugging & Monitoring\n",
    "- Optional screenshot saving  \n",
    "- Debug directory for logs and artifacts  \n",
    "- Browser session management  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c616fba1-1f46-4712-83e3-773c1040913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_ext.agents.web_surfer import MultimodalWebSurfer\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a364a-66f9-4640-a186-c587d5fcc1b2",
   "metadata": {},
   "source": [
    "**Note**: *`web_surfer` require `playwright`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe81b0a-b34e-44b9-b732-c1e8b90c816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeaa5067-3d01-41dc-8286-587fd0ade2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "surfer = MultimodalWebSurfer(\n",
    "        name=\"WebSurfer\",\n",
    "        model_client=model_client,\n",
    "        headless=True,\n",
    "        downloads_folder=\"./downloads\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e8a3581-2cd0-4846-9d15-1d8eb94bf2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = CancellationToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef158645-3697-4730-8132-10515eb11786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Search the web for 'latest advances in AI by Microsoft'. Summarize key findings.\n",
      "---\n",
      "['I typed \\'latest advances in AI by Microsoft\\' into \\'0 trên 2000 ký tự\\'.\\n\\nThe web browser is open to the page [latest advances in AI by Microsoft - Tìm kiếm](https://www.bing.com/search?q=latest+advances+in+AI+by+Microsoft&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=0C9BBDF37EE94F08A7F98696A2D4896B).\\nThe viewport shows 23% of the webpage, and is positioned at the top of the page\\nThe following text is visible in the viewport:\\n\\nBỏ qua tới phần Nội dung\\nlatest advances in AI by MicrosoftEnglishDi độngTất cả\\nTìm kiếm\\nTin tức\\nHình ảnh\\nVideo\\nCopilot\\nXem thêm\\nCông cụ\\nVề 7.400.000 kết quảWe launched a new category of Windows PCs designed for \\nAI, called Copilot+ PCs; brought \\nadvanced reasoning, planning and multimodal capabilities to Copilot; expanded our suite of \\nAI tools and models in \\nMicrosoft Azure; innovated with new \\nAI model categories like Phi-3; and are exploring novel abilities of science and \\nAI through \\nMicrosoft Research and our \\nAI for Good program that benefit humanity.\\nUnderstanding AI at Microsoftnews.microsoft.com/ai/\\nMục này có hữu ích không?\\nTin tức về \\nAdvances In Ai By Microsoftbing.com › news · 2 ngày\\nMicrosoft Reveals Which Jobs Are Most & Least Affected By AI\\nArtificial Intelligence (AI) is increasingly influencing daily life, from online …\\nThe Daily Galaxy on MSN\\n · 5 ngày\\nNew Microsoft Study Reveals the 40 Jobs Most at Risk from AI—and 40 That Are Shockingly Safe (For Now)\\n · 13 ngày\\n · on MSNMicrosoft reveals 40 jobs about to be destroyed by AI — is your career on the list?\\nWinBuzzer\\n · 6 ngày\\nProject Ire: Microsoft Unveils Autonomous AI Malware Hunter\\n · 3 ngày\\n · on MSNTech Voices: Intel CEO vs. Trump, Open AI profitability, Microsoft\\nTrí tuệ nhân tạoTất cả hình ảnh\\nTrí tuệ nhân tạo là khả năng của các hệ thống máy tính thực hiện các nhiệm vụ liên quan đến trí thông minh của con người, như học tập, suy luận, giải quyết vấn đề, nhận thức và đưa ra quyết định. Đây l…WikipediaBài cơ bản dài trung bình\\nCông nghệ\\nWorld Wide Web\\nSteven Spielberg\\nThư điện tử\\nNikola Tesla\\nVào những năm 1960, Bộ Quốc phòng Hoa Kỳ quan tâm đến công việc này và đã bắt đầu xây dựng máy tính có thể bắt chước khả năng lý luận đơn giản của con người.Thuật ngữ trí tuệ nhân tạo (AI) được đặt ra vào năm 1956. Ngày nay AI đã trở nên phổ biến hơn nhờ những phát triển về dữ liệu, thuật toán và năng lực của phần cứng.\\n\\nThe following metadata was extracted from the webpage:\\n\\n{\\n    \"meta_tags\": {\\n        \"referrer\": \"origin-when-cross-origin\",\\n        \"SystemEntropyOriginTrialToken\": \"A7cQcumnCpYMtO5VusikffR0WGYjWyI/y0wN/izvd92Pwty8awTPuPqSlIYk10vLdR6azJGHCZNOtmniRmPY4rwAAABeeyJvcmlnaW4iOiJodHRwczovL3d3dy5iaW5nLmNvbTo0NDMiLCJmZWF0dXJlIjoiTXNVc2VyQWdlbnRMYXVuY2hOYXZUeXBlIiwiZXhwaXJ5IjoxNzY0NzIwMDAwfQ==\",\\n        \"ConfidenceOriginTrialToken\": \"Aqw360MHzRcmtEVv55zzdIWcTk2BBYHcdBAOysNJZP4qkN8M+5vUq36ITHFVst8LiX36KBZJXB8xvyBgdK2z5Q0AAAB6eyJvcmlnaW4iOiJodHRwczovL2JpbmcuY29tOjQ0MyIsImZlYXR1cmUiOiJQZXJmb3JtYW5jZU5hdmlnYXRpb25UaW1pbmdDb25maWRlbmNlIiwiZXhwaXJ5IjoxNzYwNDAwMDAwLCJpc1N1YmRvbWFpbiI6dHJ1ZX0=\",\\n        \"og:description\": \"T\\\\u00ecm ki\\\\u1ebfm th\\\\u00f4ng minh t\\\\u1eeb Bing gi\\\\u00fap b\\\\u1ea1n d\\\\u1ec5 d\\\\u00e0ng t\\\\u00ecm th\\\\u1ea5y nh\\\\u1eefng g\\\\u00ec b\\\\u1ea1n \\\\u0111ang t\\\\u00ecm ki\\\\u1ebfm h\\\\u01a1n v\\\\u00e0 trao th\\\\u01b0\\\\u1edfng cho b\\\\u1ea1n.\",\\n        \"og:site_name\": \"Bing\",\\n        \"og:title\": \"latest advances in AI by Microsoft - Bing\",\\n        \"og:url\": \"https://www.bing.com/search?q=latest+advances+in+AI+by+Microsoft&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=0C9BBDF37EE94F08A7F98696A2D4896B\",\\n        \"fb:app_id\": \"3732605936979161\",\\n        \"og:image\": \"http://www.bing.com/sa/simg/facebook_sharing_5.png\",\\n        \"og:type\": \"website\",\\n        \"og:image:width\": \"600\",\\n        \"og:image:height\": \"315\"\\n    }\\n}\\n\\nHere is a screenshot of the page.', <autogen_core._image.Image object at 0x7f583c656570>]\n"
     ]
    }
   ],
   "source": [
    "# Searching\n",
    "query = \"Search the web for 'latest advances in AI by Microsoft'. Summarize key findings.\"\n",
    "\n",
    "response = await surfer.on_messages(\n",
    "    [TextMessage(content=query, source=\"user\")],\n",
    "    cancellation_token=token\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {query}\\n---\\n{response.chat_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2d6df1-b3e6-4f0a-a7a3-06612eb2f148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I typed 'latest advances in AI by Microsoft' into '0 trên 2000 ký tự'.\n",
      "\n",
      "The web browser is open to the page [latest advances in AI by Microsoft - Tìm kiếm](https://www.bing.com/search?q=latest+advances+in+AI+by+Microsoft&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=0C9BBDF37EE94F08A7F98696A2D4896B).\n",
      "The viewport shows 23% of the webpage, and is positioned at the top of the page\n",
      "The following text is visible in the viewport:\n",
      "\n",
      "Bỏ qua tới phần Nội dung\n",
      "latest advances in AI by MicrosoftEnglishDi độngTất cả\n",
      "Tìm kiếm\n",
      "Tin tức\n",
      "Hình ảnh\n",
      "Video\n",
      "Copilot\n",
      "Xem thêm\n",
      "Công cụ\n",
      "Về 7.400.000 kết quảWe launched a new category of Windows PCs designed for \n",
      "AI, called Copilot+ PCs; brought \n",
      "advanced reasoning, planning and multimodal capabilities to Copilot; expanded our suite of \n",
      "AI tools and models in \n",
      "Microsoft Azure; innovated with new \n",
      "AI model categories like Phi-3; and are exploring novel abilities of science and \n",
      "AI through \n",
      "Microsoft Research and our \n",
      "AI for Good program that benefit humanity.\n",
      "Understanding AI at Microsoftnews.microsoft.com/ai/\n",
      "Mục này có hữu ích không?\n",
      "Tin tức về \n",
      "Advances In Ai By Microsoftbing.com › news · 2 ngày\n",
      "Microsoft Reveals Which Jobs Are Most & Least Affected By AI\n",
      "Artificial Intelligence (AI) is increasingly influencing daily life, from online …\n",
      "The Daily Galaxy on MSN\n",
      " · 5 ngày\n",
      "New Microsoft Study Reveals the 40 Jobs Most at Risk from AI—and 40 That Are Shockingly Safe (For Now)\n",
      " · 13 ngày\n",
      " · on MSNMicrosoft reveals 40 jobs about to be destroyed by AI — is your career on the list?\n",
      "WinBuzzer\n",
      " · 6 ngày\n",
      "Project Ire: Microsoft Unveils Autonomous AI Malware Hunter\n",
      " · 3 ngày\n",
      " · on MSNTech Voices: Intel CEO vs. Trump, Open AI profitability, Microsoft\n",
      "Trí tuệ nhân tạoTất cả hình ảnh\n",
      "Trí tuệ nhân tạo là khả năng của các hệ thống máy tính thực hiện các nhiệm vụ liên quan đến trí thông minh của con người, như học tập, suy luận, giải quyết vấn đề, nhận thức và đưa ra quyết định. Đây l…WikipediaBài cơ bản dài trung bình\n",
      "Công nghệ\n",
      "World Wide Web\n",
      "Steven Spielberg\n",
      "Thư điện tử\n",
      "Nikola Tesla\n",
      "Vào những năm 1960, Bộ Quốc phòng Hoa Kỳ quan tâm đến công việc này và đã bắt đầu xây dựng máy tính có thể bắt chước khả năng lý luận đơn giản của con người.Thuật ngữ trí tuệ nhân tạo (AI) được đặt ra vào năm 1956. Ngày nay AI đã trở nên phổ biến hơn nhờ những phát triển về dữ liệu, thuật toán và năng lực của phần cứng.\n",
      "\n",
      "The following metadata was extracted from the webpage:\n",
      "\n",
      "{\n",
      "    \"meta_tags\": {\n",
      "        \"referrer\": \"origin-when-cross-origin\",\n",
      "        \"SystemEntropyOriginTrialToken\": \"A7cQcumnCpYMtO5VusikffR0WGYjWyI/y0wN/izvd92Pwty8awTPuPqSlIYk10vLdR6azJGHCZNOtmniRmPY4rwAAABeeyJvcmlnaW4iOiJodHRwczovL3d3dy5iaW5nLmNvbTo0NDMiLCJmZWF0dXJlIjoiTXNVc2VyQWdlbnRMYXVuY2hOYXZUeXBlIiwiZXhwaXJ5IjoxNzY0NzIwMDAwfQ==\",\n",
      "        \"ConfidenceOriginTrialToken\": \"Aqw360MHzRcmtEVv55zzdIWcTk2BBYHcdBAOysNJZP4qkN8M+5vUq36ITHFVst8LiX36KBZJXB8xvyBgdK2z5Q0AAAB6eyJvcmlnaW4iOiJodHRwczovL2JpbmcuY29tOjQ0MyIsImZlYXR1cmUiOiJQZXJmb3JtYW5jZU5hdmlnYXRpb25UaW1pbmdDb25maWRlbmNlIiwiZXhwaXJ5IjoxNzYwNDAwMDAwLCJpc1N1YmRvbWFpbiI6dHJ1ZX0=\",\n",
      "        \"og:description\": \"T\\u00ecm ki\\u1ebfm th\\u00f4ng minh t\\u1eeb Bing gi\\u00fap b\\u1ea1n d\\u1ec5 d\\u00e0ng t\\u00ecm th\\u1ea5y nh\\u1eefng g\\u00ec b\\u1ea1n \\u0111ang t\\u00ecm ki\\u1ebfm h\\u01a1n v\\u00e0 trao th\\u01b0\\u1edfng cho b\\u1ea1n.\",\n",
      "        \"og:site_name\": \"Bing\",\n",
      "        \"og:title\": \"latest advances in AI by Microsoft - Bing\",\n",
      "        \"og:url\": \"https://www.bing.com/search?q=latest+advances+in+AI+by+Microsoft&form=QBLH&sp=-1&lq=0&pq=&sc=0-0&qs=n&sk=&cvid=0C9BBDF37EE94F08A7F98696A2D4896B\",\n",
      "        \"fb:app_id\": \"3732605936979161\",\n",
      "        \"og:image\": \"http://www.bing.com/sa/simg/facebook_sharing_5.png\",\n",
      "        \"og:type\": \"website\",\n",
      "        \"og:image:width\": \"600\",\n",
      "        \"og:image:height\": \"315\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Here is a screenshot of the page.\n"
     ]
    }
   ],
   "source": [
    "print(response.chat_message.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b55b303-21b2-406f-993e-7a45ce616c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Navigate to the first search result and scroll down to extract the main headlines.\n",
      "---\n",
      "['I clicked \\'Understanding AI at Microsoft\\'.\\n\\nThe web browser is open to the page [Understanding AI at Microsoft](https://news.microsoft.com/ai/#:~:text=We%20launched%20a%20new%20category%20of%20Windows%20PCs,our%20AI%20for%20Good%20program%20that%20benefit%20humanity.?msockid=3e62115f8b79603701d207198a58612e).\\nThe viewport shows 15% of the webpage, and is positioned at the top of the page\\nThe following text is visible in the viewport:\\n\\nMicrosoft\\nSource\\nOur Company\\nAI\\nInnovation\\nDigital Transformation\\nDiversity & Inclusion\\nSustainability\\nMore\\nAll MicrosoftSearch \\nCart\\nTop Microsoft AI newsBuilding Microsoft AI responsiblyFAQs AI storiesUnderstanding\\nMicrosoft\\n AI\\nMicrosoft\\n AI\\n is\\n working\\n across\\n many\\n fronts\\n to\\n make\\n the\\n promise\\n of\\n generative\\nartificial\\n intelligence\\n real,\\n providing\\n resources,\\n information\\n and\\n access\\n to\\n help\\n media\\noutlets,\\n journalists\\n and\\n influencers\\n bring\\n their\\n audiences\\n along\\n on\\n the\\n journey.\\nTop Microsoft AI news Product & platform \\n Responsibility & societal impact \\n Research \\n Microsoft Build 2025: The age of AI agents and building the open agentic web  New capabilities in Azure AI Foundry to build advanced agentic applications  One year of Phi: Small language models making big leaps in AI  Introducing Researcher and Analyst in Microsoft 365 Copilot  Microsoft unveils Microsoft Security Copilot agents and new protections for AI  Meet Microsoft Dragon Copilot: Your new AI assistant for clinical workflow\\n\\nThe following metadata was extracted from the webpage:\\n\\n{\\n    \"jsonld\": {\\n        \"@context\": \"https://schema.org\",\\n        \"@graph\": [\\n            {\\n                \"@type\": [\\n                    \"WebPage\",\\n                    \"CollectionPage\"\\n                ],\\n                \"@id\": \"https://news.microsoft.com/ai/\",\\n                \"url\": \"https://news.microsoft.com/ai/\",\\n                \"name\": \"Microsoft AI\",\\n                \"isPartOf\": {\\n                    \"@id\": \"https://news.microsoft.com/ai/#website\"\\n                },\\n                \"primaryImageOfPage\": {\\n                    \"@id\": \"https://news.microsoft.com/ai/#primaryimage\"\\n                },\\n                \"image\": {\\n                    \"@id\": \"https://news.microsoft.com/ai/#primaryimage\"\\n                },\\n                \"thumbnailUrl\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\\n                \"datePublished\": \"2025-05-16T18:36:17+00:00\",\\n                \"dateModified\": \"2025-07-21T19:08:01+00:00\",\\n                \"description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\\n                \"breadcrumb\": {\\n                    \"@id\": \"https://news.microsoft.com/ai/#breadcrumb\"\\n                },\\n                \"inLanguage\": \"en-US\"\\n            },\\n            {\\n                \"@type\": \"ImageObject\",\\n                \"inLanguage\": \"en-US\",\\n                \"@id\": \"https://news.microsoft.com/ai/#primaryimage\",\\n                \"url\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\\n                \"contentUrl\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\\n                \"width\": 1920,\\n                \"height\": 1080,\\n                \"caption\": \"Illustration of four people interacting with the large letters \\\\\"AI\\\\\" on a purple background, featuring various elements like music notes, technology icons, and playful activities.\"\\n            },\\n            {\\n                \"@type\": \"BreadcrumbList\",\\n                \"@id\": \"https://news.microsoft.com/ai/#breadcrumb\",\\n                \"itemListElement\": [\\n                    {\\n                        \"@type\": \"ListItem\",\\n                        \"position\": 1,\\n                        \"name\": \"Home\"\\n                    }\\n                ]\\n            },\\n            {\\n                \"@type\": \"WebSite\",\\n                \"@id\": \"https://news.microsoft.com/ai/#website\",\\n                \"url\": \"https://news.microsoft.com/ai/\",\\n                \"name\": \"Understanding AI at Microsoft\",\\n                \"description\": \"\",\\n                \"potentialAction\": [\\n                    {\\n                        \"@type\": \"SearchAction\",\\n                        \"target\": {\\n                            \"@type\": \"EntryPoint\",\\n                            \"urlTemplate\": \"https://news.microsoft.com/ai/?s={search_term_string}\"\\n                        },\\n                        \"query-input\": {\\n                            \"@type\": \"PropertyValueSpecification\",\\n                            \"valueRequired\": true,\\n                            \"valueName\": \"search_term_string\"\\n                        }\\n                    }\\n                ],\\n                \"inLanguage\": \"en-US\"\\n            },\\n            {\\n                \"@type\": \"Person\",\\n                \"@id\": \"https://news.microsoft.com/ai/#/schema/person/7bab89446da6367da2d08157c02ba7e2\",\\n                \"name\": \"stephanieb\",\\n                \"image\": {\\n                    \"@type\": \"ImageObject\",\\n                    \"inLanguage\": \"en-US\",\\n                    \"@id\": \"https://news.microsoft.com/ai/#/schema/person/image/\",\\n                    \"url\": \"https://secure.gravatar.com/avatar/37f53570eddb8b855ae1666303086420?s=96&d=mm&r=g\",\\n                    \"contentUrl\": \"https://secure.gravatar.com/avatar/37f53570eddb8b855ae1666303086420?s=96&d=mm&r=g\",\\n                    \"caption\": \"stephanieb\"\\n                }\\n            }\\n        ]\\n    },\\n    \"microdata\": [\\n        {\\n            \"itemType\": \"http://schema.org/Organization\",\\n            \"url\": [\\n                \"https://www.microsoft.com/\",\\n                \"https://news.microsoft.com/source\"\\n            ],\\n            \"logo\": \"https://uhf.microsoft.com/images/microsoft/RE1Mu3b.png\",\\n            \"name\": \"Microsoft\"\\n        }\\n    ],\\n    \"meta_tags\": {\\n        \"viewport\": \"width=device-width, initial-scale=1, shrink-to-fit=no\",\\n        \"mobile-web-app-capable\": \"yes\",\\n        \"apple-mobile-web-app-capable\": \"yes\",\\n        \"apple-mobile-web-app-title\": \"Understanding AI at Microsoft - \",\\n        \"msapplication-TileImage\": \"https://news.microsoft.com/wp-content/themes/microsoft-source/assets/favicons/cropped-Microsoft_logo.svg_-300x300-1.png\",\\n        \"robots\": \"index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1\",\\n        \"description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\\n        \"og:locale\": \"en_US\",\\n        \"og:type\": \"website\",\\n        \"og:title\": \"Microsoft AI\",\\n        \"og:description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\\n        \"og:url\": \"https://news.microsoft.com/ai/\",\\n        \"og:site_name\": \"Understanding AI at Microsoft\",\\n        \"article:modified_time\": \"2025-07-21T19:08:01+00:00\",\\n        \"og:image\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\\n        \"og:image:width\": \"1920\",\\n        \"og:image:height\": \"1080\",\\n        \"og:image:type\": \"image/png\",\\n        \"twitter:card\": \"summary_large_image\",\\n        \"twitter:title\": \"Microsoft AI\",\\n        \"twitter:description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\\n        \"twitter:image\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER.png\"\\n    }\\n}\\n\\nHere is a screenshot of the page.', <autogen_core._image.Image object at 0x7f583c30f890>]\n"
     ]
    }
   ],
   "source": [
    "# Navigate\n",
    "query = \"Navigate to the first search result and scroll down to extract the main headlines.\"\n",
    "\n",
    "response = await surfer.on_messages(\n",
    "    [TextMessage(content=query, source=\"user\")],\n",
    "    cancellation_token=token\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {query}\\n---\\n{response.chat_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eea740e-6865-45cc-bf2d-7a0cc5374326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I clicked 'Understanding AI at Microsoft'.\n",
      "\n",
      "The web browser is open to the page [Understanding AI at Microsoft](https://news.microsoft.com/ai/#:~:text=We%20launched%20a%20new%20category%20of%20Windows%20PCs,our%20AI%20for%20Good%20program%20that%20benefit%20humanity.?msockid=3e62115f8b79603701d207198a58612e).\n",
      "The viewport shows 15% of the webpage, and is positioned at the top of the page\n",
      "The following text is visible in the viewport:\n",
      "\n",
      "Microsoft\n",
      "Source\n",
      "Our Company\n",
      "AI\n",
      "Innovation\n",
      "Digital Transformation\n",
      "Diversity & Inclusion\n",
      "Sustainability\n",
      "More\n",
      "All MicrosoftSearch \n",
      "Cart\n",
      "Top Microsoft AI newsBuilding Microsoft AI responsiblyFAQs AI storiesUnderstanding\n",
      "Microsoft\n",
      " AI\n",
      "Microsoft\n",
      " AI\n",
      " is\n",
      " working\n",
      " across\n",
      " many\n",
      " fronts\n",
      " to\n",
      " make\n",
      " the\n",
      " promise\n",
      " of\n",
      " generative\n",
      "artificial\n",
      " intelligence\n",
      " real,\n",
      " providing\n",
      " resources,\n",
      " information\n",
      " and\n",
      " access\n",
      " to\n",
      " help\n",
      " media\n",
      "outlets,\n",
      " journalists\n",
      " and\n",
      " influencers\n",
      " bring\n",
      " their\n",
      " audiences\n",
      " along\n",
      " on\n",
      " the\n",
      " journey.\n",
      "Top Microsoft AI news Product & platform \n",
      " Responsibility & societal impact \n",
      " Research \n",
      " Microsoft Build 2025: The age of AI agents and building the open agentic web  New capabilities in Azure AI Foundry to build advanced agentic applications  One year of Phi: Small language models making big leaps in AI  Introducing Researcher and Analyst in Microsoft 365 Copilot  Microsoft unveils Microsoft Security Copilot agents and new protections for AI  Meet Microsoft Dragon Copilot: Your new AI assistant for clinical workflow\n",
      "\n",
      "The following metadata was extracted from the webpage:\n",
      "\n",
      "{\n",
      "    \"jsonld\": {\n",
      "        \"@context\": \"https://schema.org\",\n",
      "        \"@graph\": [\n",
      "            {\n",
      "                \"@type\": [\n",
      "                    \"WebPage\",\n",
      "                    \"CollectionPage\"\n",
      "                ],\n",
      "                \"@id\": \"https://news.microsoft.com/ai/\",\n",
      "                \"url\": \"https://news.microsoft.com/ai/\",\n",
      "                \"name\": \"Microsoft AI\",\n",
      "                \"isPartOf\": {\n",
      "                    \"@id\": \"https://news.microsoft.com/ai/#website\"\n",
      "                },\n",
      "                \"primaryImageOfPage\": {\n",
      "                    \"@id\": \"https://news.microsoft.com/ai/#primaryimage\"\n",
      "                },\n",
      "                \"image\": {\n",
      "                    \"@id\": \"https://news.microsoft.com/ai/#primaryimage\"\n",
      "                },\n",
      "                \"thumbnailUrl\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\n",
      "                \"datePublished\": \"2025-05-16T18:36:17+00:00\",\n",
      "                \"dateModified\": \"2025-07-21T19:08:01+00:00\",\n",
      "                \"description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\n",
      "                \"breadcrumb\": {\n",
      "                    \"@id\": \"https://news.microsoft.com/ai/#breadcrumb\"\n",
      "                },\n",
      "                \"inLanguage\": \"en-US\"\n",
      "            },\n",
      "            {\n",
      "                \"@type\": \"ImageObject\",\n",
      "                \"inLanguage\": \"en-US\",\n",
      "                \"@id\": \"https://news.microsoft.com/ai/#primaryimage\",\n",
      "                \"url\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\n",
      "                \"contentUrl\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\n",
      "                \"width\": 1920,\n",
      "                \"height\": 1080,\n",
      "                \"caption\": \"Illustration of four people interacting with the large letters \\\"AI\\\" on a purple background, featuring various elements like music notes, technology icons, and playful activities.\"\n",
      "            },\n",
      "            {\n",
      "                \"@type\": \"BreadcrumbList\",\n",
      "                \"@id\": \"https://news.microsoft.com/ai/#breadcrumb\",\n",
      "                \"itemListElement\": [\n",
      "                    {\n",
      "                        \"@type\": \"ListItem\",\n",
      "                        \"position\": 1,\n",
      "                        \"name\": \"Home\"\n",
      "                    }\n",
      "                ]\n",
      "            },\n",
      "            {\n",
      "                \"@type\": \"WebSite\",\n",
      "                \"@id\": \"https://news.microsoft.com/ai/#website\",\n",
      "                \"url\": \"https://news.microsoft.com/ai/\",\n",
      "                \"name\": \"Understanding AI at Microsoft\",\n",
      "                \"description\": \"\",\n",
      "                \"potentialAction\": [\n",
      "                    {\n",
      "                        \"@type\": \"SearchAction\",\n",
      "                        \"target\": {\n",
      "                            \"@type\": \"EntryPoint\",\n",
      "                            \"urlTemplate\": \"https://news.microsoft.com/ai/?s={search_term_string}\"\n",
      "                        },\n",
      "                        \"query-input\": {\n",
      "                            \"@type\": \"PropertyValueSpecification\",\n",
      "                            \"valueRequired\": true,\n",
      "                            \"valueName\": \"search_term_string\"\n",
      "                        }\n",
      "                    }\n",
      "                ],\n",
      "                \"inLanguage\": \"en-US\"\n",
      "            },\n",
      "            {\n",
      "                \"@type\": \"Person\",\n",
      "                \"@id\": \"https://news.microsoft.com/ai/#/schema/person/7bab89446da6367da2d08157c02ba7e2\",\n",
      "                \"name\": \"stephanieb\",\n",
      "                \"image\": {\n",
      "                    \"@type\": \"ImageObject\",\n",
      "                    \"inLanguage\": \"en-US\",\n",
      "                    \"@id\": \"https://news.microsoft.com/ai/#/schema/person/image/\",\n",
      "                    \"url\": \"https://secure.gravatar.com/avatar/37f53570eddb8b855ae1666303086420?s=96&d=mm&r=g\",\n",
      "                    \"contentUrl\": \"https://secure.gravatar.com/avatar/37f53570eddb8b855ae1666303086420?s=96&d=mm&r=g\",\n",
      "                    \"caption\": \"stephanieb\"\n",
      "                }\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"microdata\": [\n",
      "        {\n",
      "            \"itemType\": \"http://schema.org/Organization\",\n",
      "            \"url\": [\n",
      "                \"https://www.microsoft.com/\",\n",
      "                \"https://news.microsoft.com/source\"\n",
      "            ],\n",
      "            \"logo\": \"https://uhf.microsoft.com/images/microsoft/RE1Mu3b.png\",\n",
      "            \"name\": \"Microsoft\"\n",
      "        }\n",
      "    ],\n",
      "    \"meta_tags\": {\n",
      "        \"viewport\": \"width=device-width, initial-scale=1, shrink-to-fit=no\",\n",
      "        \"mobile-web-app-capable\": \"yes\",\n",
      "        \"apple-mobile-web-app-capable\": \"yes\",\n",
      "        \"apple-mobile-web-app-title\": \"Understanding AI at Microsoft - \",\n",
      "        \"msapplication-TileImage\": \"https://news.microsoft.com/wp-content/themes/microsoft-source/assets/favicons/cropped-Microsoft_logo.svg_-300x300-1.png\",\n",
      "        \"robots\": \"index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1\",\n",
      "        \"description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\n",
      "        \"og:locale\": \"en_US\",\n",
      "        \"og:type\": \"website\",\n",
      "        \"og:title\": \"Microsoft AI\",\n",
      "        \"og:description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\n",
      "        \"og:url\": \"https://news.microsoft.com/ai/\",\n",
      "        \"og:site_name\": \"Understanding AI at Microsoft\",\n",
      "        \"article:modified_time\": \"2025-07-21T19:08:01+00:00\",\n",
      "        \"og:image\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER-1.png\",\n",
      "        \"og:image:width\": \"1920\",\n",
      "        \"og:image:height\": \"1080\",\n",
      "        \"og:image:type\": \"image/png\",\n",
      "        \"twitter:card\": \"summary_large_image\",\n",
      "        \"twitter:title\": \"Microsoft AI\",\n",
      "        \"twitter:description\": \"Microsoft AI is working across many fronts to make the promise of generative artificial intelligence real, providing resources, information and access to help media outlets, journalists and influencers bring their audiences along on the journey.\",\n",
      "        \"twitter:image\": \"https://msftstories.thesourcemediaassets.com/sites/677/2024/09/COVER.png\"\n",
      "    }\n",
      "}\n",
      "\n",
      "Here is a screenshot of the page.\n"
     ]
    }
   ],
   "source": [
    "print(response.chat_message.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f2da65-9fbc-43ca-9af8-3577d54b8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Analyze the current page: what are the top three technologies discussed here?\n",
      "---\n",
      "The \"Understanding AI at Microsoft\" webpage details Microsoft's comprehensive efforts to advance AI technology across various sectors, emphasizing responsible development and deployment. It highlights new capabilities in Azure AI Foundry and a range of AI tools and models aimed at enhancing productivity, particularly through the Copilot PCs. Microsoft's AI initiatives focus on democratizing AI benefits, ensuring inclusivity and transparency, and promoting innovation while addressing societal challenges such as accessibility, health, and sustainability. The webpage also underscores Microsoft's significant investments in advanced AI infrastructure and its commitment to global collaborations and partnerships, including its work with OpenAI.\n",
      "\n",
      "Additionally, Microsoft is dedicated to building AI responsibly, implementing safeguards against potential risks, and fostering transparency and accountability through a multi-disciplinary approach. The company continues to drive AI innovation worldwide by investing in AI infrastructure and enhancing AI literacy and skills in various regions. The page also showcases Microsoft's recent advancements and stories about AI's role in solving global issues, reflecting its overarching commitment to using AI as a transformative force for good.\n"
     ]
    }
   ],
   "source": [
    "# Content Analysis\n",
    "\n",
    "query = \"Analyze the current page: what are the top three technologies discussed here?\"\n",
    "\n",
    "response = await surfer.on_messages(\n",
    "    [TextMessage(content=query, source=\"user\")],\n",
    "    cancellation_token=token\n",
    ")\n",
    "\n",
    "print(f\"\\nQuery: {query}\\n---\\n{response.chat_message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fd7922-cf1a-4c2c-a407-b6e176a8f253",
   "metadata": {},
   "source": [
    "## Markitdown\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "uv add markitdown[all]\n",
    "```\n",
    "\n",
    "**Note**: *Install Dependencies*\n",
    "\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt install ffmpeg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f33020-d819-4ea9-a20c-740b76a287c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert document in *.pdf to *.md and use AI gent to summary the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ba09267-8fb3-4920-81d6-d99258c9a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!markitdown assets/preparedness-framework-v2.pdf > preparedness-framework-v2.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034eb208-47b9-4e88-8852-8544d4ff19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparedness Framework\n",
      "\n",
      "Version 2. Last updated: 15th April, 2025\n",
      "\n",
      "\f",
      "OpenAI’s mission is to ensure that AGI (artificial general intelligence) benefits all of humanity. To pursue\n",
      "that mission, we are committed to safely developing and deploying highly capable AI systems, which\n",
      "create significant benefits and also bring new risks. We build for safety at every step and share our\n",
      "learnings so that society can make well-informed choices to manage new risks from frontier AI.\n",
      "\n",
      "The Preparedness Framework is OpenAI’s approach to tracking and preparing for frontier capabilities\n",
      "that create new risks of severe harm.1 We currently focus this work on three areas of frontier capability,\n",
      "which we call Tracked Categories:\n",
      "\n",
      "• Biological and Chemical capabilities that, in addition to unlocking discoveries and cures, can also\n",
      "\n",
      "reduce barriers to creating and using biological or chemical weapons.\n",
      "\n",
      "• Cybersecurity capabilities that, in addition to helping protect vulnerable systems, can also create\n",
      "\n",
      "new risks of scaled cyberattacks and vulnerability exploitation.\n",
      "\n",
      "• AI Self-improvement capabilities that, in addition to unlocking helpful capabilities faster, could\n",
      "\n",
      "also create new challenges for human control of AI systems.\n",
      "\n",
      "In each area, we develop and maintain a threat model that identifies the risks of severe harm and sets\n",
      "thresholds we can measure to tell us when the models get capable enough to meaningfully pose these\n",
      "risks. We won’t deploy these very capable models until we’ve built safeguards to sufficiently minimize\n",
      "the associated risks of severe harm. This Framework lays out the kinds of safeguards we expect to need,\n",
      "and how we’ll confirm internally and show externally that the safeguards are sufficient.\n",
      "\n",
      "In this updated version of the Framework we also introduce a set of Research Categories. These are\n",
      "areas of capability that could pose risks of severe harm, that do not yet meet our criteria to be Tracked\n",
      "Categories, and where we are investing now to further develop our threat models and capability elicitation\n",
      "techniques.\n",
      "\n",
      "We are constantly refining our practices and advancing the science, to unlock the benefits of these\n",
      "technologies while addressing their risks. This revision of the Preparedness Framework focuses on the\n",
      "safeguards we expect will be needed for future models more capable than those we have today.\n",
      "\n",
      "1 By “severe harm” in this document, we mean the death or grave injury of thousands of people or hundreds of billions of\n",
      "dollars of economic damage. Our safety stack addresses a broad spectrum of risks, including many with harms below this severity.\n",
      "In choosing to set a high bar here, we aim to ensure that the most severe risks receive attention commensurate with their magnitude.\n",
      "\n",
      "1\n",
      "\n",
      "\f",
      "3\n",
      "3\n",
      "\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "\n",
      "10\n",
      "10\n",
      "10\n",
      "12\n",
      "12\n",
      "\n",
      "12\n",
      "12\n",
      "12\n",
      "\n",
      "14\n",
      "\n",
      "15\n",
      "\n",
      "16\n",
      "16\n",
      "18\n",
      "20\n",
      "\n",
      "Contents\n",
      "\n",
      "1 Introduction\n",
      "\n",
      "1.1 Why we’re updating the Preparedness Framework . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      "2 Deciding where to focus\n",
      "\n",
      "2.1 Holistic risk assessment and categorization . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "2.2 Tracked Categories .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "2.3 Research Categories .\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      "3 Measuring capabilities\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "3.1 Evaluation approach .\n",
      "3.2 Testing scope .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ".\n",
      "3.3 Capability threshold determinations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "4 Safeguarding against severe harm\n",
      ".\n",
      "Safeguard selection .\n",
      ".\n",
      ".\n",
      "Safeguard sufficiency .\n",
      ".\n",
      ".\n",
      "\n",
      "4.1\n",
      "4.2\n",
      "4.3 Marginal risk .\n",
      "4.4\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "Increasing safeguards before internal use and further development\n",
      "\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . .\n",
      "\n",
      "5 Building trust\n",
      "\n",
      "Internal governance .\n",
      "\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "5.1\n",
      "5.2 Transparency and external participation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "A Change log\n",
      "\n",
      "B Decision-making practices\n",
      "\n",
      "C Illustrative safeguards, controls, and efficacy assessments\n",
      "\n",
      "C.1 Safeguards against malicious users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "C.2 Safeguards against a misaligned model\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "C.3 Security controls .\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      ".\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "1 Introduction\n",
      "\n",
      "We believe there are a limited number of AI capabilities that could pose new risks of severe harm. In\n",
      "order to safely unlock the beneficial uses of frontier AI capabilities, we exercise particular caution and\n",
      "implement safeguards that sufficiently minimize the risk of severe harm in these areas. To do this, we:\n",
      "\n",
      "• Decide where to focus – we use a holistic risk assessment to decide which frontier capability\n",
      "categories to track or research further, and to define threshold levels of those capabilities that are\n",
      "associated with meaningful increases in risk of severe harm.\n",
      "\n",
      "• Measure capabilities associated with risks of severe harms – we run in–scope models through\n",
      "frontier capability evaluations to measure the full extent of model capabilities before we deploy\n",
      "our models and during development. Our capability elicitation efforts are designed to detect the\n",
      "threshold levels of capability that we have identified as enabling meaningful increases in risk of\n",
      "severe harms.\n",
      "\n",
      "• Safeguard against severe harms – we evaluate the likelihood that severe harms could actually\n",
      "occur in the context of deployment, using threat models that take our safeguards into account. We\n",
      "do not deploy models that reach a High capability threshold until the associated risks that they pose\n",
      "are sufficiently minimized. If a model under development reaches a Critical capability threshold,\n",
      "we also require safeguards to sufficiently minimize the associated risks during development,\n",
      "irrespective of deployment plans.\n",
      "\n",
      "• Build trust – we engage with subject–matter experts across and beyond OpenAI to inform these\n",
      "efforts and to build confidence that we are meeting our commitments and effectively managing\n",
      "risk.\n",
      "\n",
      "An internal, cross-functional group of OpenAI leaders called the Safety Advisory Group (SAG) oversees\n",
      "the Preparedness Framework and makes expert recommendations on the level and type of safeguards\n",
      "required for deploying frontier capabilities safely and securely. OpenAI Leadership can approve or reject\n",
      "these recommendations, and our Board’s Safety and Security Committee provides oversight of these\n",
      "decisions.\n",
      "\n",
      "1.1 Why we’re updating the Preparedness Framework\n",
      "\n",
      "Our environment is changing in four key ways:\n",
      "\n",
      "• Safeguarding stronger models will require more planning and coordination. Until now, our\n",
      "models’ own limitations have given us confidence that, in the areas tracked under the Preparedness\n",
      "Framework, they were safe to deploy. Our evaluations have so far shown that even our most\n",
      "advanced models, even without safeguards in place, aren’t yet capable enough to pose severe risks\n",
      "in areas like bio- or cybersecurity. We are on the cusp of systems that can do new science, and that\n",
      "are increasingly agentic - systems that will soon have the capability to create meaningful risk of\n",
      "severe harm. This means we will need to design and deploy safeguards we can rely on for safety\n",
      "and security – which requires a new level of planning and coordination across the company, beyond\n",
      "what’s needed to measure capabilities.\n",
      "\n",
      "• More frequent deployments require scalable evaluations. Today, we’re able to develop and deploy\n",
      "better models more often than ever thanks to reasoning advances that can unlock new capabilities\n",
      "without as much training as the previous paradigm. As a result, it’s important to embrace methods\n",
      "that scale, including scalable capability evaluations that work well for a faster cadence of model\n",
      "deployment, as well as periodic deeper dives that validate those scalable evaluations.\n",
      "\n",
      "• A highly dynamic development landscape for frontier AI makes it important for us to share our\n",
      "latest thinking. With a growing number of labs producing frontier AI models, it is more important\n",
      "than ever for us and other labs to contribute to community efforts on frontier safety and security,\n",
      "including by adapting safety work for the reasoning paradigm and for increasingly agentic systems,\n",
      "and advocating for and contributing to advanced protection measures in a world of continual\n",
      "frontier AI proliferation.\n",
      "\n",
      "• We and the broader field have gained more experience and built conviction on how to do this\n",
      "work. The past year of research and deployment on safety frameworks both at OpenAI and across\n",
      "the AI field have given us greater clarity on how to prioritize and approach categories of risk. This\n",
      "\n",
      "3\n",
      "\n",
      "\f",
      "includes our threat modelling, development work on new capability evaluations, and external\n",
      "consultations, as well as relevant publications from external researchers and updated frameworks\n",
      "from industry peers.2\n",
      "\n",
      "2 Deciding where to focus\n",
      "\n",
      "2.1 Holistic risk assessment and categorization\n",
      "\n",
      "We evaluate whether frontier capabilities create a risk of severe harm through a holistic risk assessment\n",
      "process. This process draws on our own internal research and signals, and where appropriate incorporates\n",
      "feedback from academic researchers, independent domain experts, industry bodies such as the Frontier\n",
      "Model Forum, and the U.S. government and its partners, as well as relevant legal and policy mandates.\n",
      "\n",
      "Where we determine that a capability presents a real risk of severe harm, we may decide to monitor it as\n",
      "a Tracked Category or a Research Category.\n",
      "\n",
      "Tracked Categories are those capabilities which we track most closely, measuring them during each\n",
      "covered deployment and preparing safeguards for when a threshold level is crossed. We treat a frontier\n",
      "capability as a Tracked Category if the capability creates a risk that meets five criteria:3\n",
      "\n",
      "1. Plausible: It must be possible to identify a causal pathway for a severe harm in the capability area,\n",
      "\n",
      "enabled by frontier AI.\n",
      "\n",
      "2. Measurable: We can construct or adopt capability evaluations that measure capabilities that closely\n",
      "\n",
      "track the potential for the severe harm.\n",
      "\n",
      "3. Severe: There is a plausible threat model within the capability area that would create severe harm.1\n",
      "\n",
      "4. Net new: The outcome cannot currently be realized as described (including at that scale, by that\n",
      "threat actor, or for that cost) with existing tools and resources (e.g., available as of 2021) but without\n",
      "access to frontier AI.\n",
      "\n",
      "5. Instantaneous or irremediable: The outcome is such that once realized, its severe harms are\n",
      "\n",
      "immediately felt, or are inevitable due to a lack of feasible measures to remediate.\n",
      "\n",
      "We review and update Tracked Categories periodically or when we learn significant new information.\n",
      "\n",
      "Research Categories are capabilities that, while they do not meet the above criteria, nonetheless have the\n",
      "potential to cause or contribute to severe harm, and where we are working now in order to prepare to\n",
      "address risks in the future (including potentially by maturing them to Tracked Categories).\n",
      "\n",
      "2.2 Tracked Categories\n",
      "\n",
      "For each Tracked Category, we develop and maintain a threat model identifying specific risks of severe\n",
      "harms that could arise from the frontier capabilities in that domain and sets corresponding capability\n",
      "thresholds that would lead to a meaningful increase in risk of severe harm.4 SAG reviews and approves\n",
      "these threat models. Capability thresholds concretely describe things an AI system might be able to help\n",
      "someone do or might be able to do on its own that could meaningfully increase risk of severe harm.\n",
      "\n",
      "High capability thresholds mean capabilities that significantly increase existing risk vectors for severe\n",
      "harm. Covered systems that cross this capability threshold are required to have robust and effective\n",
      "safeguards that sufficiently minimize the associated risk of severe harm before they are deployed and\n",
      "appropriate security controls as they are developed. Critical capability thresholds mean capabilities that\n",
      "present a meaningful risk of a qualitatively new threat vector for severe harm with no ready precedent.\n",
      "Critical capabilities require safeguards even during the development of the covered system, irrespective\n",
      "of deployment plans.\n",
      "\n",
      "2For example, our adoption of Capability Reports and Safeguards Reports parallels Anthropic’s updated RSP.\n",
      "3These criteria were informed in part by Meta’s recent Frontier AI Framework.\n",
      "4Threat models are informed both by our broader risk assessment process, and by more specific information that we gather\n",
      "across OpenAI teams and external experts. While past deployment experiences are an important source of information about\n",
      "existing risks, we also recognize that in the case of net-new risks of severe harm, significant safeguards may be needed to reduce\n",
      "the risk of harms that have never been realized.\n",
      "\n",
      "4\n",
      "\n",
      "\f",
      "Our team develops or adopts evaluations designed to track progress on each of these capabilities and to\n",
      "indicate when the identified capability thresholds may have been reached.\n",
      "\n",
      "We further break down the specific capability thresholds, associated risks, and safeguards for those\n",
      "thresholds in Table 1.\n",
      "\n",
      "Tracked Category Capability threshold that\n",
      "\n",
      "could lead to the risk\n",
      "\n",
      "[High] The model can pro-\n",
      "vide meaningful counterfac-\n",
      "tual assistance (relative to\n",
      "unlimited access to baseline\n",
      "of tools available in 2021)\n",
      "to “novice” actors (anyone\n",
      "with a basic relevant techni-\n",
      "cal background) that enables\n",
      "them to create known bio-\n",
      "logical or chemical threats.\n",
      "\n",
      "[Critical] The model can en-\n",
      "able an expert to develop\n",
      "a highly dangerous novel\n",
      "threat vector (e.g., compa-\n",
      "rable to a novel CDC Class\n",
      "A biological agent) OR the\n",
      "model can be connected to\n",
      "tools and equipment to com-\n",
      "plete the full engineering\n",
      "and/or synthesis cycle of a\n",
      "regulated or novel biological\n",
      "threat without human inter-\n",
      "vention.\n",
      "\n",
      "bottlenecks\n",
      "\n",
      "[High] The model removes\n",
      "to\n",
      "existing\n",
      "scaling cyber operations\n",
      "including by automating\n",
      "end-to-end cyber opera-\n",
      "tions against\n",
      "reasonably\n",
      "hardened targets OR by au-\n",
      "tomating the discovery and\n",
      "exploitation of operationally\n",
      "relevant vulnerabilities.\n",
      "\n",
      "Biological and\n",
      "Chemical5: The\n",
      "ability of an AI\n",
      "model to\n",
      "accelerate and\n",
      "expand access to\n",
      "biological and\n",
      "chemical research,\n",
      "development, and\n",
      "skill-building,\n",
      "including access to\n",
      "expert knowledge\n",
      "and assistance\n",
      "with laboratory\n",
      "work.\n",
      "\n",
      "Cybersecurity:\n",
      "The ability of an\n",
      "AI model to assist\n",
      "in the\n",
      "development of\n",
      "tools and\n",
      "executing\n",
      "operations for\n",
      "cyberdefense and\n",
      "cyberoffense.\n",
      "\n",
      "Associated risk of severe\n",
      "harm\n",
      "\n",
      "Risk-specific\n",
      "guidelines\n",
      "\n",
      "safeguard\n",
      "\n",
      "Significantly increased like-\n",
      "lihood and frequency of bi-\n",
      "ological or chemical terror\n",
      "events by non-state actors\n",
      "using known reference-class\n",
      "threats.\n",
      "\n",
      "Proliferating the ability to\n",
      "create a novel threat vector\n",
      "of the severity of a CDC\n",
      "Class A biological agent (i.e.,\n",
      "high mortality, ease of trans-\n",
      "mission) could cause mil-\n",
      "lions of deaths and signif-\n",
      "icantly disrupt public life,\n",
      "with few available societal\n",
      "safeguards.\n",
      "\n",
      "the\n",
      "\n",
      "Removing bottlenecks limit-\n",
      "ing malicious cyber activity\n",
      "may upset\n",
      "current\n",
      "cyberoffense-cyberdefense\n",
      "balance by significantly\n",
      "automating and scaling\n",
      "existing\n",
      "the volume of\n",
      "cyberattacks.\n",
      "In conjunction with a Long-\n",
      "range Autonomy capability\n",
      "(Section 2.3), models that\n",
      "could bypass OpenAI’s tech-\n",
      "nical safeguards constrain-\n",
      "ing model activity, such as\n",
      "sandboxing or monitoring\n",
      "services, could compromise\n",
      "OpenAI’s ability to track\n",
      "and mitigate all other risks.\n",
      "\n",
      "• Require security con-\n",
      "trols meeting High stan-\n",
      "dard (Appendix C.3)\n",
      "\n",
      "• Require\n",
      "\n",
      "safeguards\n",
      "against misuse meet-\n",
      "ing High\n",
      "standard\n",
      "(Appendix C.1) before\n",
      "external deployment\n",
      "\n",
      "• Until we have specified\n",
      "safeguards and security\n",
      "controls that would meet\n",
      "a Critical standard, halt\n",
      "further development\n",
      "• Contribute towards im-\n",
      "proved public policy and\n",
      "pandemic preparedness\n",
      "\n",
      "• Require security con-\n",
      "trols meeting High stan-\n",
      "dard (Appendix C.3)\n",
      "\n",
      "• Require\n",
      "\n",
      "safeguards\n",
      "against misuse meeting\n",
      "(Ap-\n",
      "standard\n",
      "High\n",
      "pendix C.1) for external\n",
      "deployment\n",
      "\n",
      "• Require\n",
      "\n",
      "safeguards\n",
      "meeting High standard\n",
      "against misalignment\n",
      "for\n",
      "(Appendix C.2)\n",
      "large-scale\n",
      "internal\n",
      "deployment\n",
      "• Contribute\n",
      "\n",
      "towards\n",
      "improved cyberdefense\n",
      "policies and tools for\n",
      "cyberdefense\n",
      "\n",
      "5 We will build safeguards against both biological and chemical threats. Given the higher potential severity of biological threats\n",
      "relative to chemical ones, we will prioritize Biological capability evaluations and these will be used as indicators for High and\n",
      "Critical capabilities for the category.\n",
      "\n",
      "5\n",
      "\n",
      "\f",
      "AI Self-\n",
      "improvement:\n",
      "The ability of an\n",
      "AI system to\n",
      "accelerate AI\n",
      "research,\n",
      "including to\n",
      "increase the\n",
      "system’s own\n",
      "capability.\n",
      "\n",
      "• Until we have specified\n",
      "safeguards and security\n",
      "controls standards that\n",
      "would meet a Critical\n",
      "standard, halt further de-\n",
      "velopment\n",
      "\n",
      "• Require security con-\n",
      "trols meeting High stan-\n",
      "dard (Appendix C.3)\n",
      "\n",
      "• Until we have specified\n",
      "safeguards and security\n",
      "controls that would meet\n",
      "a Critical standard, halt\n",
      "further development\n",
      "\n",
      "Finding and executing end-\n",
      "to-end exploits for all soft-\n",
      "ware could lead to catastro-\n",
      "phe from unilateral actors,\n",
      "hacking military or indus-\n",
      "trial systems, or OpenAI in-\n",
      "frastructure. Novel cyber\n",
      "operations, e.g.,\n",
      "those in-\n",
      "volving novel zero-days or\n",
      "novel methods of command-\n",
      "and-control, generally pose\n",
      "the most serious threat, as\n",
      "they are unpredictable and\n",
      "scarce.\n",
      "\n",
      "This milestone suggests AI\n",
      "self-improvement may be\n",
      "beginning to accelerate. To\n",
      "meet the large-scale safety\n",
      "research, operations, and se-\n",
      "curity investments that need\n",
      "to be in place when we reach\n",
      "Critical self-improvement,\n",
      "we will by then need to have\n",
      "made significant progress\n",
      "on those investments at this\n",
      "earlier milestone to avoid\n",
      "later risks.\n",
      "\n",
      "A major acceleration in\n",
      "the rate of AI R&D could\n",
      "rapidly increase the rate at\n",
      "which new capabilities and\n",
      "risks emerge, to the point\n",
      "where our current oversight\n",
      "practices are insufficient to\n",
      "identify and mitigate new\n",
      "risks,\n",
      "including risks to\n",
      "maintaining human control\n",
      "of the AI system itself.\n",
      "\n",
      "[Critical] A tool-augmented\n",
      "model can identify and de-\n",
      "velop functional zero-day\n",
      "exploits of all severity lev-\n",
      "els in many hardened real-\n",
      "world critical systems with-\n",
      "out human intervention OR\n",
      "model can devise and exe-\n",
      "cute end-to-end novel strate-\n",
      "gies for cyberattacks against\n",
      "hardened targets given only\n",
      "a high level desired goal.\n",
      "\n",
      "[High] The model’s impact\n",
      "is equivalent to giving every\n",
      "OpenAI researcher a highly\n",
      "performant mid-career re-\n",
      "search engineer assistant,\n",
      "relative to those researchers’\n",
      "2024 baseline.\n",
      "\n",
      "[Critical] The model is ca-\n",
      "pable of recursively self\n",
      "improving (i.e., fully auto-\n",
      "mated AI R&D), defined\n",
      "as either (leading indica-\n",
      "tor) a superhuman research-\n",
      "scientist agent OR (lagging\n",
      "indicator) causing a genera-\n",
      "tional model improvement\n",
      "(e.g., from OpenAI o1 to\n",
      "OpenAI o3) in 1/5th the\n",
      "wall-clock time of equiva-\n",
      "lent progress in 2024 (e.g.,\n",
      "sped up to just 4 weeks) sus-\n",
      "tainably for several months.\n",
      "\n",
      "Table 1: Tracked Categories\n",
      "\n",
      "2.3 Research Categories\n",
      "\n",
      "There are also some areas of frontier capability that do not meet the criteria to be Tracked Categories,\n",
      "but where we believe work is required now in order to prepare to effectively address risks of severe\n",
      "harms in the future. These capabilities either need more research and threat modeling before they can\n",
      "be rigorously measured, or do not cause direct risks themselves but may need to be monitored because\n",
      "further advancement in this capability could undermine the safeguards we rely on to mitigate existing\n",
      "Tracked Category risks. We call these Research Categories, and in these areas we will take the following\n",
      "steps, both internally and in collaboration with external experts:\n",
      "\n",
      "• Further developing the threat models for the area,\n",
      "\n",
      "6\n",
      "\n",
      "\f",
      "• Advancing the science of capability measurement in the area and investing towards the develop-\n",
      "\n",
      "ment of rigorous evaluations (which could be achieved internally or via partnerships), and\n",
      "\n",
      "• Sharing summaries of our findings with the public where feasible.\n",
      "\n",
      "We will periodically review the latest research and findings for each Research Category. SAG will receive\n",
      "the results of such reviews and evaluate whether there is sufficient evidence to recommend updates to\n",
      "our internal practices or to the Preparedness Framework.\n",
      "\n",
      "Research Category\n",
      "\n",
      "Potential response\n",
      "\n",
      "Long-range Autonomy: ability for a model to exe-\n",
      "cute a long-horizon sequence of actions sufficient to\n",
      "realize a “High” threat model (e.g., a cyberattack)\n",
      "without being directed by a human (including suc-\n",
      "cessful social engineering attacks when needed)\n",
      "\n",
      "If a model has High or Critical capabilities\n",
      "in any of the Tracked Categories, require a\n",
      "“misalignment” safeguards report (see Section\n",
      "4.2).\n",
      "As this category matures, we will make de-\n",
      "cisions about how this should influence our\n",
      "governance, including setting internal and ex-\n",
      "ternal deployment safeguards milestones.\n",
      "\n",
      "Sandbagging: ability and propensity to respond to\n",
      "safety or capability evaluations in a way that signifi-\n",
      "cantly diverges from performance under real condi-\n",
      "tions, undermining the validity of such evaluations.\n",
      "\n",
      "Adopt elicitation approach that overcomes\n",
      "sandbagging, or use a conservative upper\n",
      "bound of the model’s non-sandbagged evalu-\n",
      "ation results\n",
      "\n",
      "Autonomous Replication and Adaptation: ability to\n",
      "survive, replicate, resist shutdown, acquire resources\n",
      "to maintain and scale its own operations, and com-\n",
      "mit illegal activities that collectively constitute caus-\n",
      "ing severe harm (whether when explicitly instructed,\n",
      "or at its own initiative), without also utilizing capa-\n",
      "bilities tracked in other Tracked Categories.\n",
      "\n",
      "Undermining Safeguards: ability and propensity for\n",
      "the model to act to undermine safeguards placed on\n",
      "it, including e.g., deception, colluding with oversight\n",
      "models, sabotaging safeguards over time such as by\n",
      "embedding vulnerabilities in safeguards code, etc.\n",
      "\n",
      "Nuclear and Radiological: ability to meaningfully\n",
      "counterfactually enable the creation of a radiolog-\n",
      "ical threat or enable or significantly accelerate the\n",
      "development of or access to a nuclear threat while\n",
      "remaining undetected.\n",
      "\n",
      "Convert Autonomous Replication and Adap-\n",
      "tation to a Tracked Category\n",
      "\n",
      "If a model has High or Critical capabilities\n",
      "in any of the Tracked Categories, require the\n",
      "Safeguards case to be robust to the discovered\n",
      "capability and/or propensity\n",
      "\n",
      "Heighten safeguards (and consider further ac-\n",
      "tions) in consultation with appropriate US\n",
      "government actors, accounting for the com-\n",
      "plexity of classified information handling.\n",
      "\n",
      "Table 2: Research Categories\n",
      "\n",
      "Changes to Tracked Categories in version 2\n",
      "\n",
      "AI Self-improvement (now a Tracked Category), Long-range Autonomy and Autonomous\n",
      "Replication and Adaptation (now Research Categories) are distinct aspects of what we formerly\n",
      "termed Model Autonomy. We have separated self-improvement because it presents a distinct\n",
      "plausible, net new, and potentially irremediable risk, namely that of a hard-to-track rapid\n",
      "acceleration in AI capabilities which could have hard-to-predict severely harmful consequences.\n",
      "In addition, the evaluations we use to measure this capability are distinct from those applicable\n",
      "to Long-range Autonomy and Autonomous Replication and Adaptation. Meanwhile, while\n",
      "these latter risks’ threat models are not yet sufficiently mature to receive the scrutiny of Tracked\n",
      "Categories, we believe they justify additional research investment and could qualify in the future,\n",
      "so we are investing in them now as Research Categories.\n",
      "\n",
      "7\n",
      "\n",
      "\f",
      "Nuclear and Radiological capabilities are now a Research Category. While basic informa-\n",
      "tion related to nuclear weapons design is available in public sources, the information and expertise\n",
      "needed to actually create a working nuclear weapon is significant, and classified. Further, there are\n",
      "significant physical barriers to success, like access to fissile material, specialized equipment, and\n",
      "ballistics. Because of the significant resources required and the legal controls around information\n",
      "and equipment, nuclear weapons development cannot be fully studied outside a classified context.\n",
      "Our work on nuclear risks also informs our efforts on the related but distinct risks posed by\n",
      "radiological weapons. We build safeguards to prevent our models from assisting with high-risk\n",
      "queries related to building weapons, and evaluate performance on those refusal policies as part of\n",
      "our safety process. Our analysis suggests that nuclear risks are likely to be of substantially greater\n",
      "severity and therefore we will prioritize research on nuclear-related risks. We will also engage\n",
      "with US national security stakeholders on how best to assess these risks.\n",
      "\n",
      "Persuasion: OpenAI prohibits the use of our products to manipulate political views as\n",
      "part of our Model Spec, and we build in safeguards to back this policy. We also continue to study\n",
      "the persuasive and relational capabilities of models (including on emotional well-being and\n",
      "preventing bias in our products) and monitor and investigate misuse of our products (including\n",
      "for influence operations). We believe many of the challenges around AI persuasion risks require\n",
      "solutions at a systemic or societal level, and we actively contribute to these efforts through our\n",
      "participation as a steering committee member of C2PA and working with lawmaker and industry\n",
      "peers to support state legislation on AI content provenance in Florida and California. Within\n",
      "our wider safety stack, our Preparedness Framework is specifically focused on frontier AI risks\n",
      "meeting a specific definition of severe harms1, and Persuasion category risks do not fit the criteria\n",
      "for inclusion.\n",
      "\n",
      "3 Measuring capabilities\n",
      "\n",
      "3.1 Evaluation approach\n",
      "\n",
      "We invest deeply in developing or adopting new science-backed evaluations that provide high precision\n",
      "and high recall indications of whether a covered system has reached a capability threshold in one of our\n",
      "Tracked Categories.\n",
      "\n",
      "Our evaluations are intended to approximate the full capability that the adversary contemplated by\n",
      "our threat model could extract from the deployment candidate model, including by using the highest-\n",
      "capability tier of system settings, using a version of the model that has a negligible rate of safety-based\n",
      "refusals on our Tracked Category capability evaluations (which may require a separate model variant),\n",
      "and with the best presently-available scaffolds. These measures are taken to approximate the high end of\n",
      "expected elicitation by threat actors attempting to misuse the model, and should be tailored depending\n",
      "on the level of expected access (e.g., doing finetuning if the weights will be released).\n",
      "\n",
      "Nonetheless, given the continuous progress in model scaffolding and elicitation techniques, we regard any\n",
      "one-time capability elicitation in a frontier model as a lower bound, rather than a ceiling, on capabilities\n",
      "that may emerge in real world use and misuse. We incorporate this uncertainty into our assessments. We\n",
      "monitor the technical landscape for changes to the elicitation techniques and best practices, and reassess\n",
      "our evaluations as needed.\n",
      "\n",
      "Capability evaluations come in two different forms:\n",
      "\n",
      "• Scalable Evaluations: automated evaluations designed to measure proxies that approximate\n",
      "whether a capability threshold has been crossed. Scalable evaluations have associated “indicative\n",
      "thresholds,” which are levels of performance that we have pre-determined to indicate that a\n",
      "deployment may have reached a capability threshold.\n",
      "\n",
      "• Deep Dives: designed to provide additional evidence validating the scalable evaluations’ findings\n",
      "on whether a capability threshold has been crossed. These may include a wide range of evidence\n",
      "gathering activities, such as human expert red-teaming, expert consultations, resource-intensive\n",
      "third party evaluations (e.g., bio wet lab studies, assessments by independent third party evaluators),\n",
      "and any other activity requested by SAG.\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "An example of a Tracked Category capability evaluation\n",
      "\n",
      "To assess the degree to which a covered system can reduce the barriers to creating a bio-\n",
      "logical weapon, our current evaluations test both how capable the system is at providing useful\n",
      "information to someone creating a weapon and how capable it is of directly integrating with\n",
      "relevant tools, such as ordering precursor materials via the Internet.\n",
      "\n",
      "Our evaluations test acquiring critical and sensitive information across the five stages of\n",
      "the biological threat creation process: Ideation, Acquisition, Magnification, Formulation, and\n",
      "Release. These evaluations, developed by domain experts, cover things like how to troubleshoot\n",
      "the laboratory processes involved.\n",
      "\n",
      "You can learn more about our Tracked Category capability evaluations in past system cards, such\n",
      "as those for OpenAI o1 and Operator.\n",
      "\n",
      "3.2 Testing scope\n",
      "\n",
      "The Preparedness Framework applies to any new or updated deployment that has a plausible chance of\n",
      "reaching a capability threshold whose corresponding risks are not addressed by an existing Safeguards\n",
      "Report. Examples of such covered deployments are:\n",
      "\n",
      "• every frontier model (e.g., OpenAI o1 or OpenAI o3) that we plan to deploy externally\n",
      "\n",
      "• any agentic system (including significant agents deployed only internally) that represents a sub-\n",
      "\n",
      "stantial increase in the capability frontier\n",
      "\n",
      "• any significant change in the deployment conditions of an existing model (e.g., enabling finetuning,\n",
      "releasing weights, or significant new features) that makes the existing Capabilities Report or\n",
      "Safeguards Report no longer reasonably applicable\n",
      "\n",
      "• incremental updates or distilled models with unexpectedly significant increases in capability. 6\n",
      "\n",
      "If justified by our forecasts and threat models as potentially posing a severe risk during development\n",
      "and prior to external deployment, we will select an appropriate checkpoint during development to be\n",
      "covered by the Preparedness Framework.\n",
      "\n",
      "In cases of ambiguity about whether a model is covered by the Preparedness Framework, the SAG is\n",
      "responsible for making the final determination.\n",
      "\n",
      "3.3 Capability threshold determinations\n",
      "\n",
      "Prior to deployment, every covered model undergoes the suite of Scalable Evaluations. The results of\n",
      "these evaluations, and any noteworthy observations that should affect interpretation of the results, are\n",
      "compiled into a Capabilities Report that is submitted to the SAG.\n",
      "\n",
      "The determination that a threshold has been reached is informed by these indicative results from capability\n",
      "evaluations, and also reflects holistic judgment based on the totality of available evidence – for example,\n",
      "information about the methodological robustness of evaluation results.\n",
      "\n",
      "The SAG reviews the Capabilities Report and decides on next steps. These can include:\n",
      "\n",
      "• Determine that the capability threshold has been crossed, and therefore recommend implement-\n",
      "ing and assessing corresponding safeguards, if they have not already been implemented and\n",
      "assessed.\n",
      "\n",
      "• Determine that a threshold has not been crossed: If the scalable evaluations did not cross their\n",
      "indicative thresholds, the SAG may conclude that the model does not have High or Critical\n",
      "capability, and recommend no further action.\n",
      "\n",
      "6In general, models that we distill, fine-tune, or quantize from a model that was previously determined not to cross a High\n",
      "capability threshold will ordinarily not require additional safety measures barring reason to believe a significant increase in\n",
      "capability has occurred.\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "• Recommend deep dive research: This is appropriate if SAG needs additional evidence in order to\n",
      "\n",
      "make a recommendation.\n",
      "\n",
      "4 Safeguarding against severe harm\n",
      "\n",
      "Safeguards that mitigate the risk of severe harm are at the core of our safe deployment approach for\n",
      "covered systems that reach a capability threshold. This section describes the process through which we\n",
      "select which safeguards to apply and how we evaluate whether those safeguards sufficiently minimize\n",
      "the risk of severe harm.\n",
      "\n",
      "If a covered system appears likely to cross a capability threshold, we will start to work on safeguards\n",
      "to sufficiently reduce the risks of severe harm associated with that threshold even if a formal capability\n",
      "determination has not yet been made.\n",
      "\n",
      "4.1 Safeguard selection\n",
      "\n",
      "Each capability threshold has a corresponding class of risk-specific safeguard guidelines under the\n",
      "Preparedness Framework. We use the following process to select safeguards for a deployment:\n",
      "\n",
      "• We first identify the plausible ways in which the associated risk of severe harm can come to fruition\n",
      "\n",
      "in the proposed deployment.\n",
      "\n",
      "• For each of those, we then identify specific safeguards that either exist or should be implemented\n",
      "\n",
      "that would address the risk.\n",
      "\n",
      "• For each identified safeguard, we identify methods to measure their efficacy and an efficacy\n",
      "\n",
      "threshold.\n",
      "\n",
      "We consider separate safeguards for two of the main ways in which risks can be realized: a malicious user,\n",
      "who can leverage the model to cause the severe harm, and a misaligned model, which autonomously\n",
      "causes the harm. We illustrate the types of safeguards for each in Table 3.\n",
      "\n",
      "The methodology for security controls is similar, although focused on the relevant security threat models.\n",
      "\n",
      "Appendix C provides illustrative examples of potential safeguards and safeguard efficacy assessments\n",
      "that could be used to establish that we have sufficiently minimized the risk of severe harm. The examples\n",
      "aim to provide insight on our thinking but should not be construed as a definitive checklist of the\n",
      "safeguards we will apply to a given launch.\n",
      "\n",
      "4.2 Safeguard sufficiency\n",
      "\n",
      "We compile the information on the planned safeguards needed to minimize the risk of severe harm into a\n",
      "Safeguards Report. The Safeguards Report should include the following information:\n",
      "\n",
      "• Identified ways a risk of severe harm can be realized for the given deployment, each mapped to the\n",
      "\n",
      "associated security controls and safeguards\n",
      "\n",
      "• Details about the efficacy of those safeguards\n",
      "\n",
      "• An assessment on the residual risk of severe harm based on the deployment\n",
      "\n",
      "• Any notable limitations with the information provided\n",
      "\n",
      "Many safeguards can be reused across different deployments, and so in practice we may find that the\n",
      "majority of deployments need few new safeguards and associated stress-testing beyond those already in\n",
      "place for prior deployments.\n",
      "\n",
      "SAG is responsible for assessing whether the safeguards associated with a given deployment sufficiently\n",
      "minimize the risk of severe harm associated with the proposed deployment. The SAG will make this\n",
      "determination based on:\n",
      "\n",
      "• The level of capability in the Tracked Category based on the Capabilities Report.\n",
      "\n",
      "• The associated risks of severe harm, as described in the threat model and where needed, advice of\n",
      "\n",
      "internal or external experts.\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "Safeguards Against Malicious Users\n",
      "\n",
      "Safeguards Against a Misaligned Model\n",
      "\n",
      "Potential claims:\n",
      "• Robustness: Malicious users cannot use the\n",
      "model to cause the severe harm because they\n",
      "cannot elicit the necessary capability, such as\n",
      "because the model is modified to refuse to\n",
      "provide assistance to harmful tasks and is\n",
      "robust to jailbreaks that would circumvent\n",
      "those refusals.\n",
      "\n",
      "• Usage Monitoring: If a model does not refuse\n",
      "\n",
      "and provides assistance to harmful tasks,\n",
      "monitors can stop or catch malicious users\n",
      "before they have achieved an unacceptable\n",
      "scale of harm, through a combination of\n",
      "automated and human detection and\n",
      "enforcement within an acceptable time frame.\n",
      "• Trust-based Access: The actors who gain access\n",
      "to the model are not going to use it in a way\n",
      "that presents an associated risk of severe harm\n",
      "under our threat model.\n",
      "\n",
      "Potential claims:\n",
      "\n",
      "• Lack of Autonomous Capability: The\n",
      "\n",
      "model is not capable of carrying out tasks\n",
      "autonomously, including the risk of severe\n",
      "harm.\n",
      "\n",
      "• Value Alignment: The model consistently\n",
      "applies human values in novel settings\n",
      "(without any instructions) to avoid taking\n",
      "actions that cause harm, and has shown\n",
      "sufficiently minimal indications of\n",
      "misaligned behaviors like deception or\n",
      "scheming.\n",
      "\n",
      "• Instruction Alignment: The model\n",
      "\n",
      "consistently understands and follows user\n",
      "or system instructions, even when vague,\n",
      "and those instructions rule out pathways to\n",
      "causing severe harm.\n",
      "\n",
      "• Reliable and Robust System Oversight:\n",
      "\n",
      "Effective AI and human oversight of model\n",
      "actions detects and prevents execution of\n",
      "harm or subversion of safeguards.\n",
      "\n",
      "• System Architecture: The model can’t take\n",
      "actions that cause harm because it lacks\n",
      "access to output channels or mechanisms to\n",
      "persist sufficiently to execute the harm, due\n",
      "to system design and restricted permissions.\n",
      "\n",
      "Table 3: Types of safeguards. See Appendix C.1 and C.2 for additional details.\n",
      "\n",
      "• The safeguards in place and their effectiveness based on the Safeguards Report.\n",
      "\n",
      "• The baseline risk from other deployments, based on a review of any non-OpenAI deployments of\n",
      "models which have crossed the capability thresholds and any public evidence of the safeguards\n",
      "applied for those models.\n",
      "\n",
      "Covered systems that reach High capability must have safeguards that sufficiently minimize the asso-\n",
      "ciated risk of severe harm before they are deployed. Systems that reach Critical capability also require\n",
      "safeguards that sufficiently minimize associated risks during development.\n",
      "\n",
      "Based on this evidence, SAG then has the following decision points:\n",
      "\n",
      "1. SAG can find that it is confident that the safeguards sufficiently minimize the associated risk of\n",
      "\n",
      "severe harm for the proposed deployment, and recommend deployment.\n",
      "\n",
      "2. SAG can request further evaluation of the effectiveness of the safeguards to evaluate if the\n",
      "\n",
      "associated risk of severe harm is sufficiently minimized\n",
      "\n",
      "3. SAG can find the safeguards do not sufficiently minimize the risk of severe harm and recommend\n",
      "potential alternative deployment conditions or additional or more effective safeguards that would\n",
      "sufficiently minimize the risk.\n",
      "\n",
      "The SAG will strive to recommend further actions that are as targeted and non-disruptive as possible\n",
      "while still mitigating risks of severe harm. All of SAG’s recommendations will go to OpenAI Leadership\n",
      "for final decision-making in accordance with the decision-making practices outlined in Appendix B.\n",
      "\n",
      "We expect to continuously improve our safeguards over time. If we find reasonable evidence that our\n",
      "safeguards are not working as expected, we will validate the information being received and review the\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "sufficiency of our safeguards.\n",
      "\n",
      "4.3 Marginal risk\n",
      "\n",
      "We recognize that another frontier AI model developer might develop or release a system with High\n",
      "or Critical capability in one of this Framework’s Tracked Categories and may do so without instituting\n",
      "comparable safeguards to the ones we have committed to. Such an action could significantly increase the\n",
      "baseline risk of severe harm being realized in the world, and limit the degree to which we can reduce risk\n",
      "using our safeguards. If we are able to rigorously confirm that such a scenario has occurred, then we\n",
      "could adjust accordingly the level of safeguards that we require in that capability area, but only if:\n",
      "\n",
      "• we assess that doing so does not meaningfully increase the overall risk of severe harm,\n",
      "\n",
      "• we publicly acknowledge that we are making the adjustment,\n",
      "\n",
      "• and, in order to avoid a race to the bottom on safety, we keep our safeguards at a level more\n",
      "\n",
      "protective than the other AI developer, and share information to validate this claim.\n",
      "\n",
      "4.4\n",
      "\n",
      "Increasing safeguards before internal use and further development\n",
      "\n",
      "Models that have reached or are forecasted to reach Critical capability in a Tracked Category present\n",
      "severe dangers and should be treated with extreme caution.\n",
      "\n",
      "Such models require additional safeguards (safety and security controls) during development, regardless\n",
      "of whether or when they are externally deployed. We do not currently possess any models that have\n",
      "Critical levels of capability, and we expect to further update this Preparedness Framework before reaching\n",
      "such a level with any model.\n",
      "\n",
      "Our approach to Critical capabilities will need to be robust to both malicious actors (either internal or\n",
      "external) and model misalignment risks. The SAG retains discretion over when to request deep dive\n",
      "evaluations of models whose scalable evaluations indicate that they may possess or may be nearing\n",
      "critical capability thresholds.\n",
      "\n",
      "5 Building trust\n",
      "\n",
      "Effective implementation of the Preparedness Framework requires internal and external accountability,\n",
      "so that the public, governments, and our industry peers can trust in our adherence to this policy.\n",
      "\n",
      "5.1\n",
      "\n",
      "Internal governance\n",
      "\n",
      "• Clear internal decision-making practices. We have clear roles and responsibilities and decision-\n",
      "\n",
      "making practices as described in Appendix B.\n",
      "\n",
      "• Internal Transparency. We will document relevant reports made to the SAG and of SAG’s decision\n",
      "and reasoning. Employees may also request and receive a summary of the testing results and SAG\n",
      "recommendation on capability levels and safeguards (subject to certain limits for highly sensitive\n",
      "information).\n",
      "\n",
      "• Noncompliance. Any employee can raise concerns about potential violations of this policy, or about\n",
      "its implementation, via our Raising Concerns Policy. We will track and appropriately investigate\n",
      "any reported or otherwise identified potential instances of noncompliance with this policy, and\n",
      "where reports are substantiated, will take appropriate and proportional corrective action.\n",
      "\n",
      "5.2 Transparency and external participation\n",
      "\n",
      "• Public disclosures: We will release information about our Preparedness Framework results in order\n",
      "to facilitate public awareness of the state of frontier AI capabilities for major deployments. This\n",
      "published information will include the scope of testing performed, capability evaluations for each\n",
      "Tracked Category, our reasoning for the deployment decision, and any other context about a model’s\n",
      "development or capabilities that was decisive in the decision to deploy. Additionally, if the model\n",
      "is beyond a High threshold, we will include information about safeguards we have implemented to\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "sufficiently minimize the associated risks. Such disclosures about results and safeguards may be\n",
      "redacted or summarized where necessary, such as to protect intellectual property or safety.\n",
      "\n",
      "• Third-party evaluation of tracked model capabilities: If we deem that a deployment warrants\n",
      "deeper testing of Tracked Categories of capability (as described in Section 3.1), for example based\n",
      "on results of Capabilities Report presented to them, then when available and feasible, OpenAI will\n",
      "work with third-parties to independently evaluate models.\n",
      "\n",
      "• Third-party stress testing of safeguards: If we deem that a deployment warrants third party stress\n",
      "testing of safeguards and if high quality third-party testing is available, we will work with third\n",
      "parties to evaluate safeguards. We may seek this out in particular for models that are over a High\n",
      "capability threshold.\n",
      "\n",
      "• Independent expert opinions for evidence produced to SAG: The SAG may opt to get independent\n",
      "expert opinion on the evidence being produced to SAG. The purpose of this input is to add\n",
      "independent analysis from individuals or organizations with deep expertise in domains of relevant\n",
      "risks (e.g., biological risk). If provided, these opinions will form part of the analysis presented\n",
      "to SAG in making its decision on the safety of a deployment. These domain experts may not\n",
      "necessarily be AI experts and their input will form one part of the holistic evidence that SAG\n",
      "reviews.\n",
      "\n",
      "13\n",
      "\n",
      "\f",
      "A Change log\n",
      "\n",
      "In this version of the Preparedness Framework, we make a number of updates, designed to reflect what\n",
      "we’ve learned and update our safety and governance process for the next generations of highly capable\n",
      "models. Key changes include that we:\n",
      "\n",
      "1. Clarify the relationship among capabilities, risks and safeguards. In our updated framework, we\n",
      "make clear that we use a holistic process to decide which areas of frontier AI capability to track,\n",
      "and to define threshold levels of those capabilities that are associated with meaningful increases in\n",
      "risk of severe harm. We describe how we develop and maintain threat models that identify these\n",
      "severe risks, and how we evaluate model capabilities and build and test safeguards that sufficiently\n",
      "minimize the associated risks. We make clear that safeguards can take a variety of forms, and that\n",
      "reducing risk generally does not require reducing capability.\n",
      "\n",
      "2. Define how High and Critical capability thresholds relate to underlying risks. High capability\n",
      "thresholds mean capabilities that significantly increase existing risk vectors for severe harm under\n",
      "the relevant threat model. Critical capability thresholds mean capabilities that present a meaningful\n",
      "risk of a qualitatively new threat vector for severe harm with no ready precedent under the relevant\n",
      "threat model. Also, we are removing terms “low” and “medium” from the Framework, because\n",
      "those levels were not operationally involved in the execution of our Preparedness work.\n",
      "\n",
      "3. Give specific criteria for which capabilities we track. We track capabilities that create risks meeting\n",
      "five criteria – they are plausible, measurable, severe, net new, and instantaneous or irremediable.\n",
      "\n",
      "4. Update the Tracked Categories of frontier capability accordingly, focusing on biological and\n",
      "chemical capability, cybersecurity, and AI self-improvement. Going forward we will handle risks\n",
      "related to persuasion outside the Preparedness Framework, including via our Model Spec and\n",
      "policy prohibitions on the use of our tools for political campaigning or lobbying, and our ongoing\n",
      "investigations of misuse of our products (including detecting and disrupting influence operations).\n",
      "We are moving Nuclear and Radiological capabilities into Research Categories.\n",
      "\n",
      "5. Introduce Research Categories, areas of capability that do not meet the criteria to be Tracked\n",
      "Categories, but where we believe additional work is needed now. For these areas, in collaboration\n",
      "with external experts, we commit to further developing the associated threat models and advancing\n",
      "the science of capability measurement for the area, including by investing in the development of\n",
      "rigorous capability evaluations. These include Long-range Autonomy, Sandbagging, Autonomous\n",
      "Replication and Adaptation, Undermining Safeguards, and Nuclear and Radiological.\n",
      "\n",
      "6. Provide more detail on our capability elicitation approach, making clear that we will consider a\n",
      "range of techniques in order to test a model version that approximates the high end of expected elici-\n",
      "tation by threat actors attempting to misuse the model. We also define “scalable evaluations,” which\n",
      "are automated, and distinguish these from “deep dive” evaluations that may include consultation\n",
      "with human experts and are designed in part to validate the scalable evaluations.\n",
      "\n",
      "7. Provide risk-specific safeguard guidelines. This information gives more detail on how we expect\n",
      "to safely develop and deploy models advanced enough to pose severe risks in tracked capability\n",
      "areas. As we move toward increasingly capable models, we are planning for safeguards that will be\n",
      "tailored to the specific risks they are intended to address.\n",
      "\n",
      "8. Establish Capabilities Reports and Safeguards Reports, the key artifacts we use to support\n",
      "informed decision-making under the Preparedness Framework in the context of systems that are\n",
      "capable enough to pose severe risks.\n",
      "\n",
      "9. Clarify approach to establishing safeguard efficacy, moving beyond the flawed approach of re-\n",
      "running capability evaluations on the safeguarded model and towards a more thorough assessment\n",
      "of each safeguard and its efficacy (Section 4.1).\n",
      "\n",
      "10. Deprioritize safety drills, as we are shifting our attention to a more durable approach of continu-\n",
      "\n",
      "ously red-teaming and assessing the effectiveness of our safeguards.\n",
      "\n",
      "11. Clarify our focus on marginal risk, including the context of other systems available on the market,\n",
      "and outline our approach for maintaining responsible safeguards and reinforcing responsible\n",
      "practices across the industry if another actor releases a system we would assess as having High or\n",
      "Critical capability.\n",
      "\n",
      "14\n",
      "\n",
      "\f",
      "12. Clarify the governance process. Our Safety Advisory Group oversees the effective design, imple-\n",
      "mentation, and adherence to the Preparedness Framework, in partnership with safety leaders in\n",
      "the company. For covered launches, SAG assesses residual risk in tracked areas, net of safeguards,\n",
      "and makes expert recommendations on safeguard adequacy and deployment decision-making to\n",
      "OpenAI leadership.\n",
      "\n",
      "B Decision-making practices\n",
      "\n",
      "We establish an operational structure to oversee our procedural commitments within the Preparedness\n",
      "Framework.\n",
      "\n",
      "The Safety Advisory Group (SAG) is responsible for:\n",
      "\n",
      "• Overseeing the effective design, implementation, and adherence to the Preparedness Framework in\n",
      "\n",
      "partnership with the safety organization leader\n",
      "\n",
      "• For each deployment in scope under the Preparedness Framework, reviewing relevant reports and\n",
      "all other relevant materials and assessing of the level of Tracked Category capabilities and any\n",
      "post-safeguards residual risks\n",
      "\n",
      "• For each deployment under the Preparedness Framework, providing recommendations on potential\n",
      "\n",
      "next steps and any applicable risks to OpenAI Leadership, as well as rationale\n",
      "\n",
      "• Making other recommendations to OpenAI Leadership on longer-term changes or investments that\n",
      "are forecasted to be necessary for upcoming models to continue to keep residual risks at acceptable\n",
      "levels\n",
      "\n",
      "• For the avoidance of doubt, OpenAI Leadership can also make decisions without the SAG’s\n",
      "\n",
      "participation, i.e., the SAG does not have the ability to “filibuster”\n",
      "\n",
      "SAG Membership: the SAG provides a diversity of perspectives to evaluate the strength of evidence\n",
      "related to catastrophic risk and recommend appropriate actions.\n",
      "\n",
      "• The members of the SAG and the SAG Chair are appointed by the OpenAI Leadership.\n",
      "\n",
      "• SAG members serve for one year terms. OpenAI Leadership may choose to re-appoint someone\n",
      "from previous years to ensure there is continuity of knowledge and experience, while still ensuring\n",
      "that fresh and timely perspectives are present in the group.\n",
      "\n",
      "• The SAG Chair makes any final decisions needed for the SAG. This role is expected to rotate, as\n",
      "\n",
      "appointed by OpenAI Leadership.\n",
      "\n",
      "OpenAI Leadership, i.e., the CEO or a person designated by them, is responsible for:\n",
      "\n",
      "• Making all final decisions, including accepting any residual risks and making deployment go/no-go\n",
      "\n",
      "decisions, informed by SAG’s recommendations.\n",
      "\n",
      "• Resourcing the implementation of the Preparedness Framework (e.g., additional work on safeguards\n",
      "\n",
      "where necessary).\n",
      "\n",
      "The Safety and Security Committee (SSC) of the OpenAI Board of Directors (Board) will be given\n",
      "visibility into processes, and can review decisions and otherwise require reports and information from\n",
      "OpenAI Leadership as necessary to fulfill the Board’s oversight role. Where necessary, the Board may\n",
      "reverse a decision and/or mandate a revised course of action.\n",
      "\n",
      "Updates to the Preparedness Framework. The Preparedness Framework is a living document and\n",
      "will be updated. The SAG reviews proposed changes to the Preparedness Framework and makes a\n",
      "recommendation that is processed according to the standard decision-making process. We will review\n",
      "and potentially update the Preparedness Framework for continued sufficiency at least once a year.\n",
      "\n",
      "Fast-track. In the rare case that a risk of severe harm rapidly develops (e.g., there is a change in our\n",
      "understanding of model safety that requires urgent response), we can request a fast track for the SAG\n",
      "to process the report urgently. The SAG Chair should also coordinate with OpenAI Leadership for\n",
      "immediate reaction as needed to address the risk.\n",
      "\n",
      "15\n",
      "\n",
      "\f",
      "C Illustrative safeguards, controls, and efficacy assessments\n",
      "\n",
      "This Appendix provides illustrative examples of potential safeguards, and safeguard efficacy assessments\n",
      "that could be used to establish that we have sufficiently mitigated the risk of severe harm. The examples\n",
      "aim to provide insight on our thinking, but many of the techniques require further research. The\n",
      "safeguards should not be construed as a definitive or comprehensive list of the safeguards we will or\n",
      "could apply to a given launch.\n",
      "\n",
      "As a reminder, covered systems that reach High capability must have safeguards that sufficiently minimize\n",
      "the associated risk of severe harm before they are deployed. Systems that reach Critical capability also\n",
      "require sufficient safeguards during development.\n",
      "\n",
      "C.1 Safeguards against malicious users\n",
      "\n",
      "Several of the Tracked Categories pose risks via malicious users leveraging the frontier capability to\n",
      "enable severe harm, such as professional hackers automating and scaling cyberattacks or terrorists\n",
      "consulting a model to debug the development of a biological weapon.\n",
      "\n",
      "Safeguards should sufficiently minimize the risk of severe harm associated with misuse of the model’s\n",
      "capabilities. This can be done by establishing that all plausible known vectors of enabling severe harm\n",
      "are sufficiently addressed by one or more of the following claims:\n",
      "\n",
      "• Robustness: Users cannot use the model to cause the harm because they cannot elicit the capability,\n",
      "such as because the model is modified to refuse to provide assistance to harmful tasks and is robust\n",
      "to jailbreaks that would circumvent those refusals.\n",
      "\n",
      "• Usage Monitoring: If a model does not refuse and provides assistance to harmful tasks, monitors\n",
      "can stop or catch adversarial users before their misuse has achieved an unacceptable scale of harm,\n",
      "through a combination of automated and human detection and enforcement within an acceptable\n",
      "time frame.\n",
      "\n",
      "• Trust-based Access: The actors who gain access to the model will not use it in a way that presents\n",
      "\n",
      "an associated risk of severe harm under our threat model.\n",
      "\n",
      "The table below illustrates possible examples of safeguards and safeguard efficacy assessments we could\n",
      "consider to claim we have sufficiently minimized the risks of severe harm associated with a High level of\n",
      "capability under any of our Tracked Categories.\n",
      "\n",
      "16\n",
      "\n",
      "\f",
      "Potential safeguard efficacy as-\n",
      "sessments\n",
      "\n",
      "• Automated and expert red-\n",
      "teaming (identifying success\n",
      "per resources)\n",
      "\n",
      "• Prevalence of jailbreaks iden-\n",
      "tified via monitoring and re-\n",
      "in historical deploy-\n",
      "ports,\n",
      "ments\n",
      "\n",
      "• Results from public jailbreak\n",
      "bounties and results from\n",
      "private and public jailbreak\n",
      "benchmarks\n",
      "\n",
      "• Automated and human red-\n",
      "teaming of each oversight and\n",
      "review mechanism (focused\n",
      "on detection precision/recall)\n",
      "• In-production detection and\n",
      "enforcement SLAs for human\n",
      "monitoring teams, and histori-\n",
      "cal performance\n",
      "\n",
      "• Rapid remediation of known\n",
      "jailbreaks: Time to patching a\n",
      "new known jailbreak\n",
      "\n",
      "• Redteamer success creating a\n",
      "certain number of accounts\n",
      "without detection (success per\n",
      "resources)\n",
      "\n",
      "• Iterated deployment to wider\n",
      "user group, with careful mon-\n",
      "itoring to detect instances of\n",
      "abuse\n",
      "\n",
      "Claim\n",
      "\n",
      "Safeguards that could support this claim\n",
      "\n",
      "Robustness\n",
      "\n",
      "Usage\n",
      "Monitoring\n",
      "\n",
      "Trust-based\n",
      "Access\n",
      "\n",
      "• Training the model to refuse to help with\n",
      "high-risk tasks or to otherwise produce low-\n",
      "risk responses\n",
      "\n",
      "• Unlearning or training-data filtering to\n",
      "erase specific risk-enabling knowledge\n",
      "from the model’s knowledge-base\n",
      "\n",
      "• Interpretability-based approaches, like ac-\n",
      "tivation steering, that directly edit models’\n",
      "thinking at inference time\n",
      "\n",
      "• Jailbreak robustness, including through ad-\n",
      "versarial training, inference-time delibera-\n",
      "tion, and more\n",
      "\n",
      "• Monitoring harmful user requests, model\n",
      "responses, and aggregate usage patterns us-\n",
      "ing auxiliary models trained to detect harm-\n",
      "ful tasks and jailbreak attempts\n",
      "\n",
      "• Blocking unsafe user requests and model\n",
      "responses automatically when possible and\n",
      "escalating to human review and approval\n",
      "otherwise\n",
      "\n",
      "• Expanding human monitoring and inves-\n",
      "tigation capacity to track capabilities that\n",
      "pose a risk of severe harm, and developing\n",
      "data infrastructure and review tools to en-\n",
      "able human investigations\n",
      "\n",
      "• Blocking access for users and organizations\n",
      "that violate our usage policies, leading to\n",
      "potential permanent bans\n",
      "\n",
      "• Expanding escalation channels with law en-\n",
      "\n",
      "forcement channels\n",
      "\n",
      "• Iterated deployment to wider user groups\n",
      "• Measures for establishing user trustworthi-\n",
      "\n",
      "ness\n",
      "– Trusted customer relationships\n",
      "– KYC and identity verification to enable\n",
      "\n",
      "traceability\n",
      "\n",
      "– KYC robustness to prevent a banned ac-\n",
      "tor from creating new accounts at scale\n",
      "(recidivism)\n",
      "\n",
      "• Actor-policy standards, including bespoke\n",
      "usage policies that limit access to higher\n",
      "capabilities to trusted actors\n",
      "\n",
      "• Access conditions\n",
      "\n",
      "including variation\n",
      "across actors, e.g., rate-limits, fine-tuning\n",
      "access, releasing weights\n",
      "\n",
      "Table 4: Claims, potential safeguards, and efficacy assessments for malicious users\n",
      "\n",
      "17\n",
      "\n",
      "\f",
      "C.2 Safeguards against a misaligned model\n",
      "\n",
      "In addition to human misuse, several of the Tracked Category capabilities pose risks when models\n",
      "themselves are able to autonomously execute a severe harm, whether due to misalignment or subversion\n",
      "by an adversary.\n",
      "\n",
      "Safeguards should sufficiently minimize the risk associated with a misaligned model circumventing\n",
      "human control and oversight and executing severe harms. This can be done by establishing that all\n",
      "plausible known vectors of enabling severe harm are sufficiently addressed by one or more of the\n",
      "following claims:\n",
      "\n",
      "• Lack of Autonomous Capability: The model is not capable of carrying out tasks autonomously,\n",
      "\n",
      "including the risk of severe harm.\n",
      "\n",
      "• Value Alignment: The model consistently applies human values in novel settings (without any\n",
      "instructions) to avoid taking actions that cause harm, and has shown sufficiently minimal indications\n",
      "of misaligned behaviors like deception or scheming.\n",
      "\n",
      "• Instruction Alignment: The model consistently understands and follows user or system instruc-\n",
      "\n",
      "tions, even when vague, and those instructions rule out pathways to causing severe harm.\n",
      "\n",
      "• Reliable and Robust System Oversight: Effective AI and human oversight of model actions detects\n",
      "\n",
      "and prevents execution of harm or subversion of safeguards.\n",
      "\n",
      "• System Architecture: The model can’t take actions that cause harm because it lacks access to output\n",
      "channels or mechanisms to persist sufficiently to execute the harm, due to containerization and\n",
      "restricted permissions.\n",
      "\n",
      "These misalignment claims may be further complemented by the safeguards applied towards the\n",
      "malicious-actor-oriented “Robustness” and “Usage Monitoring” claims, which similarly limit a mis-\n",
      "aligned model’s use of its own or another model’s capabilities.\n",
      "\n",
      "The table below illustrates possible examples of safeguards and safeguard efficacy assessments we could\n",
      "consider to claim we have sufficiently minimized the risks of severe harm associated with High level of\n",
      "capability under any of our Tracked Categories.\n",
      "\n",
      "18\n",
      "\n",
      "\f",
      "Claim\n",
      "\n",
      "Potential safeguards\n",
      "\n",
      "Potential safeguard efficacy assessments\n",
      "\n",
      "Lack of\n",
      "Autonomous\n",
      "Capability\n",
      "\n",
      "Value\n",
      "Alignment\n",
      "\n",
      "Instruction\n",
      "Alignment\n",
      "\n",
      "Reliable and\n",
      "Robust\n",
      "System\n",
      "Oversight\n",
      "\n",
      "• Not applicable, as this involves capa-\n",
      "\n",
      "bility evaluation.\n",
      "\n",
      "• Generalization from specified or\n",
      "\n",
      "trained values\n",
      "\n",
      "• Steering or interpretability to control\n",
      "misaligned behaviors like deception\n",
      "or scheming\n",
      "\n",
      "• Instruction following, instruction hi-\n",
      "erarchy and adherence to complex\n",
      "Model Specs\n",
      "\n",
      "• Model spec defined to comprehen-\n",
      "\n",
      "sively rule out risk pathways\n",
      "\n",
      "• Training user models and training AI\n",
      "\n",
      "to collaborate with users\n",
      "\n",
      "• Build risk models and training to\n",
      "\n",
      "avoid unnecessary risk\n",
      "\n",
      "• Training for uncertainty estimation\n",
      "\n",
      "and reliable answers\n",
      "\n",
      "• Monitor AI supervises agent actions\n",
      "to detect agent in the case of trying\n",
      "to take harmful actions, scheming, or\n",
      "similar\n",
      "\n",
      "• System forces human approval of\n",
      "agent actions (either by default, or by\n",
      "escalation of the monitor)\n",
      "\n",
      "• Model’s reasoning is provided faith-\n",
      "fully and interpretably to humans to\n",
      "review\n",
      "\n",
      "• Agent actions are all\n",
      "\n",
      "logged in\n",
      "an uneditable database, and asyn-\n",
      "chronous monitoring routines review\n",
      "those actions for evidence of harm\n",
      "\n",
      "• Long-range Autonomy capability evalu-\n",
      "ations show the model cannot act au-\n",
      "tonomously as described in the threat\n",
      "model (Section 2.3)\n",
      "\n",
      "• Red-teamers create both environments\n",
      "and adversarial requests to probe the lim-\n",
      "its of the model’s value alignment. Evi-\n",
      "dence of taking harmful actions, including\n",
      "deception and scheming, would be evi-\n",
      "dence of misalignment\n",
      "\n",
      "• Internal and external user reports, moni-\n",
      "toring, or manual inspection for historical\n",
      "model deployments show no significant\n",
      "evidence of unexpected value alignment\n",
      "failures\n",
      "\n",
      "• Large scale usage or testing in realistic set-\n",
      "tings should show the model consistently\n",
      "takes action aligned to the user’s instruc-\n",
      "tions or goals (while maintaining value\n",
      "alignment and avoiding harm). Examples\n",
      "against would include trying to escape\n",
      "a container, lying to the user to appease\n",
      "them, etc.\n",
      "\n",
      "• Red-teamers can train an arbitrarily adver-\n",
      "sarial agent or can pretend to be an agent\n",
      "in our setup and we should ensure that\n",
      "harmful behaviors are detected by moni-\n",
      "tors with a high recall rate\n",
      "\n",
      "• Monitor escalations are either outright\n",
      "blocked or, in empirical studies, users with\n",
      "the relevant level of expertise were shown\n",
      "to reliably understand and act on monitor\n",
      "flags before significant harm occurred\n",
      "• SLAs for asynchronous monitors to ana-\n",
      "lyze and detect harmful agent actions post-\n",
      "hoc\n",
      "\n",
      "System\n",
      "Architecture\n",
      "(including\n",
      "containeriza-\n",
      "tion and\n",
      "permissions)\n",
      "\n",
      "• Limiting internet access and other tool\n",
      "\n",
      "• Testing and red-teaming of the system pro-\n",
      "\n",
      "access\n",
      "\n",
      "tections\n",
      "\n",
      "• Limiting credentials\n",
      "• Limiting access to system resources or\n",
      "\n",
      "filesystem (e.g., sandboxing)\n",
      "• Limiting persistence or state\n",
      "\n",
      "• “Canary evaluations” which test model ca-\n",
      "pabilities to bypass less complex, easier-to-\n",
      "exploit versions of our security controls,\n",
      "establishing that our implemented con-\n",
      "trols are robust\n",
      "\n",
      "Table 5: Claims, potential safeguards, and efficacy assessments for misaligned models\n",
      "\n",
      "19\n",
      "\n",
      "\f",
      "C.3 Security controls\n",
      "\n",
      "Robust security practices and controls are essential to mitigating risks associated with the deployment of\n",
      "models reaching High capability thresholds. Our security approach integrates industry best practices\n",
      "with OpenAI-specific innovations tailored to manage the unique threats posed by frontier AI technologies.\n",
      "Our security practices are designed to protect against external and internal adversaries and align with\n",
      "established frameworks such as ISO 27001, SOC2, NIST SP 800-53, and FedRAMP. While nascent, AI-\n",
      "specific security standards may also provide frameworks for addressing security and regulatory standards\n",
      "that address the unique challenges of securing AI systems. This may include efforts emerging from the\n",
      "Cloud Security Alliance’s AI Safety Initiative or the NIST SP 800-218 AI updates.\n",
      "\n",
      "We will require the following practices for High capability models:\n",
      "\n",
      "• Security Threat Modeling and Risk Management\n",
      "\n",
      "– Comprehensive Security Threat Models: Ensure OpenAI employs security threat modeling that\n",
      "systematically identifies and mitigates risks posed by adversaries. These models address both\n",
      "external and internal threats, explicitly mapping vulnerabilities and attack vectors relevant to\n",
      "frontier AI model access or misuse.\n",
      "\n",
      "– Continuous Review and Iteration: Ensure security threat models are regularly reviewed and\n",
      "updated. This includes updating the Security framework, policies, and controls as technologies\n",
      "and threats evolve.\n",
      "\n",
      "– Continuous Monitoring and Validation: Ensure security threat models and updates inform\n",
      "where security and data privacy controls should be implemented, improved, and monitored to\n",
      "further reduce risk. Internal and external assessments to validate these controls are conducted\n",
      "regularly and reports are provided to OpenAI leadership.\n",
      "\n",
      "• Defense in Depth\n",
      "\n",
      "– Layered Security Architecture: Adopt a layered security strategy, ensuring robust protection\n",
      "through multiple defensive barriers, including physical and datacenter security, network\n",
      "segmentation and controls, workload isolation, data encryption, and other overlapping and\n",
      "complementary security controls.\n",
      "\n",
      "– Zero Trust Principles: Embrace Zero Trust principles in the design and operation of infrastruc-\n",
      "ture, networks, and endpoints. Leverage hardware-backed security and modern authentication\n",
      "standards and controls for accessing critical resources and performing operations.\n",
      "\n",
      "• Access Management\n",
      "\n",
      "– Principle of Least Privilege: Ensure access to systems and data is limited based on job functions,\n",
      "need-to-know, and operational requirements in alignment with the principles of least privilege\n",
      "and separation of duties. Ensure all access is regularly audited and reviewed. For all models,\n",
      "especially those presenting High capabilities, access must be strictly limited, protected with\n",
      "strong multi-factor authentication, and may require additional approvals for access.\n",
      "\n",
      "– Identity and Device Management: Employees must authenticate using multi-factor authenti-\n",
      "cation (MFA) and managed devices meeting security baselines. Access must be logged and\n",
      "reviewed for detection and investigative purposes.\n",
      "\n",
      "• Secure Development and Supply Chain\n",
      "\n",
      "– Secure Development Lifecycle: Integrate automated code analysis, formal security reviews,\n",
      "and penetration testing in engineering processes. Apply security reviews and validation to\n",
      "higher-sensitivity critical components prior to deployment.\n",
      "\n",
      "– Change Management: Establish and maintain a formal change management process to ensure\n",
      "that all modifications to systems, applications, and infrastructure are properly authorized,\n",
      "documented, tested, and approved before deployment. Changes to critical infrastructure\n",
      "should undergo multi-person approval and review. This process should include maintaining\n",
      "comprehensive records of changes and implementing rollback procedures to revert to previous\n",
      "states.\n",
      "\n",
      "20\n",
      "\n",
      "\f",
      "– Software Supply Chain Integrity: Enforce supply chain security measures, including sourcing\n",
      "hardware and software from reputable sources, and continuous vetting and monitoring of\n",
      "third-party suppliers and software libraries.\n",
      "\n",
      "• Operational Security\n",
      "\n",
      "– Monitoring and Incident Response: Monitor security and event logs continuously to detect,\n",
      "\n",
      "triage, and respond to security incidents rapidly by 24x7 on-call staff.\n",
      "\n",
      "– Vulnerability Management: Ensure known vulnerabilities are addressed through consistent\n",
      "\n",
      "patching and corrective actions, minimizing exploitation opportunities.\n",
      "\n",
      "– Adversarial Testing and Red-Teaming: Conduct adversarial testing and red-teaming exercises\n",
      "to proactively identify and mitigate potential vulnerabilities within corporate, research, and\n",
      "product systems, ensuring resilience against unknown vulnerabilities and emerging threats.\n",
      "Encourage reporting of good-faith security research through bug bounty programs.\n",
      "\n",
      "• Auditing and Transparency\n",
      "\n",
      "– Independent Security Audits: Ensure security controls and practices are validated regularly\n",
      "by third-party auditors to ensure compliance with relevant standards and robustness against\n",
      "identified threats.\n",
      "\n",
      "– Transparency in Security Practices: Ensure security findings, remediation efforts, and key met-\n",
      "rics from internal and independent audits are periodically shared with internal stakeholders\n",
      "and summarized publicly to demonstrate ongoing commitment and accountability.\n",
      "\n",
      "– Governance and Oversight: Ensure that management provides oversight over the information\n",
      "\n",
      "security and risk management programs.\n",
      "\n",
      "21\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from markitdown import MarkItDown\n",
    "\n",
    "md = MarkItDown(enable_plugins=False) # Set to True to enable plugins\n",
    "result = md.convert(\"assets/preparedness-framework-v2.pdf\")\n",
    "print(result.text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e78080b-6aa2-4b4e-ac21-8ac87de32512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import tiktoken\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_core import CancellationToken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1134562-e201-4a0e-824a-9adc9767491e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token count: 13482\n"
     ]
    }
   ],
   "source": [
    "# Count tokens\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "token_count = len(encoding.encode(result.text_content))\n",
    "print(f\"Prompt token count: {token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a6989-f5f5-4532-b7dc-3cf8b382e147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4fc2cfe-33b0-41cc-b61a-70f7e620daf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI's Preparedness Framework aims to manage risks from advanced AI capabilities by categorizing threats, measuring capabilities, developing safeguards, and ensuring transparent governance to protect against severe harm. \n",
      "\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "assistant = AssistantAgent(\n",
    "    name=\"Assistant\",\n",
    "    model_client=OpenAIChatCompletionClient(model=\"gpt-4o-mini\"),\n",
    "    description=\"You are helpful assistant\"\n",
    ")\n",
    "\n",
    "msg = TextMessage(content=f\"Summary this content {result.text_content} in 30 words\",\n",
    "                    source=\"user\")\n",
    "\n",
    "res = await assistant.on_messages([msg],cancellation_token=CancellationToken())\n",
    "\n",
    "print(res.chat_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e44c6-2384-4a89-b2f1-0298760695f0",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://openai.com/api/pricing/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

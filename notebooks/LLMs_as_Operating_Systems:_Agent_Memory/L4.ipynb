{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e5f77a-6406-4d19-ac08-0cd968faf831",
   "metadata": {},
   "source": [
    "# Programming Agent Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63196bdb-3d82-497e-8ef6-630372823d0c",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44ffa5-ea48-4bb9-8933-10cd30ac9d30",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> 💻 &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "<p> ⬇ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> 📒 &nbsp; For more help, please see the <em>\"Appendix – Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc6632-f3d5-4ea3-8ee3-db85193912ae",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> 🚨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI models can vary with each execution due to their dynamic, probabilistic nature. Your results may differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126f43f-eba6-4dce-9df5-c884fd4ffd19",
   "metadata": {},
   "source": [
    "Letta agents persist information over time and restarts by saving data to a database. These lessons do not require past information. To enable a clean restart, the database is cleared before starting the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3698ae50-4b95-4ab2-9438-0567cd64d2b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "!rm  -f ~/.letta/sqlite.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b77cfcd-3155-4e60-bb01-3a4e1292863c",
   "metadata": {},
   "source": [
    "## Section 0: Setup a MemGPT client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d585ab9c-3ccc-4d26-980f-68e494e53336",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper import nb_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137aa217-24bb-4372-b21c-37f21a945c9d",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Config:  /home/jovyan/.letta/config\n",
      "📖 Letta configuration file updated!\n",
      "🧠 model\t-> gpt-4\n",
      "🖥️  endpoint\t-> http://jupyter-api-proxy.internal.dlai/rev-proxy/letta\n",
      "Saved Config:  /home/jovyan/.letta/config\n",
      "Saved Config:  /home/jovyan/.letta/config\n"
     ]
    }
   ],
   "source": [
    "from letta import create_client \n",
    "\n",
    "client = create_client() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e108e4-bcf9-4be1-b2c0-66539cbe9ec3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from letta.schemas.llm_config import LLMConfig\n",
    "\n",
    "client.set_default_llm_config(LLMConfig.default_config(\"gpt-4o-mini\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c66c27-e5f4-407b-aeb1-d5ad4f063111",
   "metadata": {},
   "source": [
    "## Section 1: Memory Blocks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b601a6-875c-4476-a6aa-68ad830b7bf6",
   "metadata": {},
   "source": [
    "### Understanding ChatMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0e6729-0f02-497f-8f85-688ed4f65f68",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16bbb19b-2fa2-4cac-8803-5cb179c36d47",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "chat_memory = ChatMemory(\n",
    "    human=\"Name: Bob\", \n",
    "    persona=\"You are a helpful assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed0f467-c545-4b26-8a10-2cb009240b5a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['persona', 'human']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.list_block_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75cc6a09-6c24-4b45-8b92-6084acdc3d46",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(value='Name: Bob', limit=2000, name='human', template=False, label='human', description=None, metadata_={}, user_id=None, id='block-537ca87a-391c-40b8-9aca-fbf39638966c')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.get_block(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e0b63a-b8e7-4958-8c81-71dce3328391",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d2cc3dd-0278-40f7-8c0e-e919cb628c31",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def core_memory_append(self: \"Agent\", name: str, content: str) -> Optional[str]:  # type: ignore\n",
      "        \"\"\"\n",
      "        Append to the contents of core memory.\n",
      "\n",
      "        Args:\n",
      "            name (str): Section of the memory to be edited (persona or human).\n",
      "            content (str): Content to write to the memory. All unicode (including emojis) are supported.\n",
      "\n",
      "        Returns:\n",
      "            Optional[str]: None is always returned as this function does not produce a response.\n",
      "        \"\"\"\n",
      "        current_value = str(self.memory.get_block(name).value)\n",
      "        new_value = current_value + \"\\n\" + str(content)\n",
      "        self.memory.update_block_value(name=name, value=new_value)\n",
      "        return None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(chat_memory.core_memory_append))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33374545-64f8-4f79-92b4-f6a80851336a",
   "metadata": {},
   "source": [
    "#### Context compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf728dce-f06b-4bcb-a3ba-15a7f099b2d9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{% for block in memory.values() %}<{{ block.name }} characters=\"{{ block.value|length }}/{{ block.limit }}\">\\n{{ block.value }}\\n</{{ block.name }}>{% if not loop.last %}\\n{% endif %}{% endfor %}'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de7b9f35-8599-4465-952a-b2db2d7b1533",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<persona characters=\"27/2000\">\\nYou are a helpful assistant\\n</persona>\\n<human characters=\"9/2000\">\\nName: Bob\\n</human>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f3b0de-e3ed-413c-852a-71efae8a591d",
   "metadata": {},
   "source": [
    "## Section 2: Defining a custom memory module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f41239-463e-4609-8870-cbbae06a8f3a",
   "metadata": {},
   "source": [
    "### Defining a memory module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76d419bd-020c-4f6f-81c3-e704d65f5306",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from letta.schemas.memory import ChatMemory\n",
    "from letta.schemas.block import Block\n",
    "from typing import Optional, List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2df27d7b-d2b6-4d87-90c3-6759a70fa8d7",
   "metadata": {
    "height": 829
   },
   "outputs": [],
   "source": [
    "class TaskMemory(ChatMemory): \n",
    "\n",
    "    def __init__(self, human: str, persona: str, tasks: List[str]): \n",
    "        super().__init__(human=human, persona=persona, limit=2000) \n",
    "        self.link_block(\n",
    "            name=\"tasks\", \n",
    "            block=Block(\n",
    "                limit=2000, \n",
    "                value=json.dumps(tasks), \n",
    "                name=\"tasks\", \n",
    "                label=\"tasks\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def task_queue_push(self: \"Agent\", task_description: str):\n",
    "        \"\"\"\n",
    "        Push to a task queue stored in core memory. \n",
    "\n",
    "        Args:\n",
    "            task_description (str): A description of the next task you must accomplish. \n",
    "            \n",
    "        Returns:\n",
    "            Optional[str]: None is always returned as this function \n",
    "            does not produce a response.\n",
    "        \"\"\"\n",
    "        import json\n",
    "        tasks = json.loads(self.memory.get_block(\"tasks\").value)\n",
    "        tasks.append(task_description)\n",
    "        self.memory.update_block_value(\"tasks\", json.dumps(tasks))\n",
    "        return None\n",
    "\n",
    "    def task_queue_pop(self: \"Agent\"):\n",
    "        \"\"\"\n",
    "        Get the next task from the task queue \n",
    " \n",
    "        Returns:\n",
    "            Optional[str]: The description of the task popped from the \n",
    "            queue, if there are still tasks in queue. Otherwise, returns\n",
    "            None (the task queue is empty)\n",
    "        \"\"\"\n",
    "        import json\n",
    "        tasks = json.loads(self.memory.get_block(\"tasks\").value)\n",
    "        if len(tasks) == 0: \n",
    "            return None\n",
    "        task = tasks[0]\n",
    "        print(\"CURRENT TASKS: \", tasks)\n",
    "        self.memory.update_block_value(\"tasks\", json.dumps(tasks[1:]))\n",
    "        return task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534a35b-506b-44fc-b658-d213a7eed2f9",
   "metadata": {},
   "source": [
    "### Creating an agent with custom `TaskMemory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "571e53e5-4190-4787-9cb2-efc527885c2d",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "task_agent_name = \"task_agent\"\n",
    "\n",
    "task_agent_state = client.create_agent(\n",
    "    name=task_agent_name, \n",
    "    system = open(\"task_queue_system_prompt.txt\", \"r\").read(),\n",
    "    memory=TaskMemory(\n",
    "        human=\"My name is Sarah\", \n",
    "        persona=\"You are an agent that must clear its tasks.\", \n",
    "        tasks=[]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2534c3f7-55d9-4f5f-892c-82221ccd1b78",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "message = \"Add 'start calling me Charles'\"  \\\n",
    "+ \"and 'tell me a haiku about my name' as two seperate tasks.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85ddb91c-5d8c-4f1c-87fd-f8c2b75f7990",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT TASKS:  ['Start calling her Charles', 'Compose a haiku about Charles']\n",
      "CURRENT TASKS:  ['Compose a haiku about Charles']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">The user asked me to add two tasks: Start calling them Charles and write a haiku about their name. I will push these tasks into my queue.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_push</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"task_description\"</span>: <span class=\"json-key\">\"Start calling her Charles\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Next, I need to add the second task: Compose a haiku about the user&#x27;s name. I&#x27;ll push this task into my queue.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_push</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"task_description\"</span>: <span class=\"json-key\">\"Compose a haiku about Charles\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">Alright, both tasks have been added to my queue. I should begin by popping the first task. Let&#x27;s see what it is.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_pop</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION RETURN</div>\n",
       "            <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"Start calling her Charles\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2024-11-09 11:07:38 PM UTC+0000\"</span><br>}</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">The first task is to start calling the user Charles. I will update my core memory to reflect this change. Let&#x27;s do this.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">core_memory_replace</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"name\"</span>: <span class=\"json-key\">\"human\",<br>&nbsp;&nbsp;\"old_content\"</span>: <span class=\"json-key\">\"My name is Sarah\",<br>&nbsp;&nbsp;\"new_content\"</span>: <span class=\"json-key\">\"My name is Charles\",<br>&nbsp;&nbsp;\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">My core memory is now updated with the user&#x27;s correct name. I can now address the user as Charles. Let&#x27;s move on to the next task. Time to pop the next task from the queue.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_pop</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION RETURN</div>\n",
       "            <div class=\"content\">{<br>&nbsp;&nbsp;<span class=\"json-key\">\"status\"</span>: <span class=\"json-key\">\"OK\",<br>&nbsp;&nbsp;\"message\"</span>: <span class=\"json-key\">\"Compose a haiku about Charles\",<br>&nbsp;&nbsp;\"time\"</span>: <span class=\"json-string\">\"2024-11-09 11:07:45 PM UTC+0000\"</span><br>}</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">The task popped is to compose a haiku about &quot;Charles&quot;. Let me think of a suitable haiku and present it to the user.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Charles, name so grand,\\nEchoing across the land,\\nA story so unplanned.\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=message\n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cc0a070-d3e5-4832-90af-99d3544862e2",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .message-container {\n",
       "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
       "            max-width: 800px;\n",
       "            margin: 20px auto;\n",
       "            background-color: #1e1e1e;\n",
       "            border-radius: 8px;\n",
       "            overflow: hidden;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .message {\n",
       "            padding: 10px 15px;\n",
       "            border-bottom: 1px solid #3a3a3a;\n",
       "        }\n",
       "        .message:last-child {\n",
       "            border-bottom: none;\n",
       "        }\n",
       "        .title {\n",
       "            font-weight: bold;\n",
       "            margin-bottom: 5px;\n",
       "            color: #ffffff;\n",
       "            text-transform: uppercase;\n",
       "            font-size: 0.9em;\n",
       "        }\n",
       "        .content {\n",
       "            background-color: #2d2d2d;\n",
       "            border-radius: 4px;\n",
       "            padding: 5px 10px;\n",
       "            font-family: 'Consolas', 'Courier New', monospace;\n",
       "            white-space: pre-wrap;\n",
       "        }\n",
       "        .status-line {\n",
       "            margin-bottom: 5px;\n",
       "            color: #d4d4d4;\n",
       "        }\n",
       "        .function-name { color: #569cd6; }\n",
       "        .json-key { color: #9cdcfe; }\n",
       "        .json-string { color: #ce9178; }\n",
       "        .json-number { color: #b5cea8; }\n",
       "        .json-boolean { color: #569cd6; }\n",
       "        .internal-monologue { font-style: italic; }\n",
       "    </style>\n",
       "    <div class=\"message-container\">\n",
       "    \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">It looks like the user wants me to finish my tasks. For that, I need to check if there&#x27;s any task left in my queue. Let&#x27;s do that.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">task_queue_pop</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"request_heartbeat\"</span>: <span class=\"json-boolean\">true</span><br>})</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">INTERNAL MONOLOGUE</div>\n",
       "            <div class=\"content\"><span class=\"internal-monologue\">It appears that my task queue is empty. I have completed all my tasks. I should inform Charles that I have finished all my tasks.</span></div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"message\">\n",
       "            <div class=\"title\">FUNCTION CALL</div>\n",
       "            <div class=\"content\"><span class=\"function-name\">send_message</span>({<br>&nbsp;&nbsp;<span class=\"json-key\">\"message\"</span>: <span class=\"json-string\">\"Charles, I have completed all my tasks.\"</span><br>})</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.send_message(\n",
    "    agent_id=task_agent_state.id, \n",
    "    role=\"user\", \n",
    "    message=\"complete your tasks\"\n",
    ")\n",
    "nb_print(response.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356e2cb1-a89a-4e56-8bed-1aabfd92bb09",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(value='[]', limit=2000, name='tasks', template=False, label='tasks', description=None, metadata_={}, user_id=None, id='block-ecc2ce46-b92c-4dd2-b39c-1b4cfe0e621f')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_core_memory(task_agent_state.id).get_block(\"tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70253b9-7737-4427-906a-69e69c964c8d",
   "metadata": {},
   "source": [
    "> copy the id='block-...' string, from the code cell above \"client.get_core_memory...\", and then paste into the code cell client.get_block('block-...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6e64ee5-fc01-436c-839a-73e65fb162c9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Block does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_block\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcut_and_paste_id_from_above\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/client/client.py:2375\u001b[0m, in \u001b[0;36mLocalClient.get_block\u001b[0;34m(self, block_id)\u001b[0m\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, block_id: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[1;32m   2366\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;124;03m    Get a block\u001b[39;00m\n\u001b[1;32m   2368\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;124;03m        block (Block): Block\u001b[39;00m\n\u001b[1;32m   2374\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/letta/server/server.py:909\u001b[0m, in \u001b[0;36mSyncServer.get_block\u001b[0;34m(self, block_id)\u001b[0m\n\u001b[1;32m    907\u001b[0m blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_blocks(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mblock_id)\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blocks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 909\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlock does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(blocks) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiple blocks with the same id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Block does not exist"
     ]
    }
   ],
   "source": [
    "client.get_block('cut_and_paste_id_from_above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ba181-b0bf-4f04-bf94-1e520caeafc3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc39c5-311d-446e-9562-fa88eb2a10d1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452213f-b977-4a88-ba56-726216a9d218",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "247e60da-5119-41a3-a82b-3bd769e707b7",
   "metadata": {},
   "source": [
    "##  Supervised Fine-Tuning\n",
    "\n",
    "Supervised Fine-Tuning (SFT) is a process primarily used to adapt pre-trained language models to follow instructions, engage in dialogue, and use specific output formats. While pre-trained models have impressive general capabilities, SFT helps transform them into assistant-like models that can better understand and respond to user prompts. This is typically done by training on datasets of human-written conversations and instructions.\n",
    "\n",
    "This page provides a step-by-step guide to fine-tuning the [deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) model using the [SFTTrainer](https://huggingface.co/docs/trl/en/sft_trainer). By following these steps, you can adapt the model to perform specific tasks more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c750b5-80a2-4fab-994b-43af42203f75",
   "metadata": {},
   "source": [
    "### When to Use SFT\n",
    "\n",
    "Before diving into implementation, it’s important to understand when SFT is the right choice for your project. As a first step, you should consider whether using an existing instruction-tuned model with well-crafted prompts would suffice for your use case. SFT involves significant computational resources and engineering effort, so it should only be pursued when prompting existing models proves insufficient.\n",
    "\n",
    "Consider SFT only if you: \n",
    "- Need additional performance beyond what prompting can achieve\n",
    "- Have a specific use case where the cost of using a large general-purpose model outweighs the cost of fine-tuning a smaller model\n",
    "- Require specialized output formats or domain-specific knowledge that existing models struggle with\n",
    "\n",
    "If you determine that SFT is necessary, the decision to proceed depends on two primary factors:\n",
    "\n",
    "####  Template Control\n",
    "\n",
    "SFT allows precise control over the model’s output structure. This is particularly valuable when you need the model to:\n",
    "\n",
    "1. Generate responses in a specific chat template format\n",
    "2. Follow strict output schemas\n",
    "3. Maintain consistent styling across responses\n",
    "\n",
    "####  Domain Adaptation\n",
    "\n",
    "1. Teaching domain terminology and concepts\n",
    "2. Enforcing professional standards\n",
    "3. Handling technical queries appropriately\n",
    "4. Following industry-specific guidelines\n",
    "\n",
    "Before starting SFT, evaluate whether your use case requires: \n",
    "- Precise output formatting\n",
    "- Domain-specific knowledge\n",
    "- Consistent response patterns\n",
    "- Adherence to specific guidelines\n",
    "\n",
    "This evaluation will help determine if SFT is the right approach for your needs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452c83d-389e-4518-86c9-c048a33b910b",
   "metadata": {},
   "source": [
    "### Dataset Preparation\n",
    "\n",
    "The supervised fine-tuning process requires a task-specific dataset structured with input-output pairs. Each pair should consist of:\n",
    "\n",
    "1. An input prompt\n",
    "2. The expected model response\n",
    "3. Any additional context or metadata\n",
    "\n",
    "The quality of your training data is crucial for successful fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a4c345-a4f9-4e9e-9543-9f245ef091a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

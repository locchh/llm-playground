{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84f6d5e5-acb4-47ad-a981-bcebc900933a",
   "metadata": {},
   "source": [
    "Implementing self-editing memory from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8bfc6-ed3a-4ec4-90bc-483fb0cfe886",
   "metadata": {},
   "source": [
    "### Section 0: Setup OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb364a5a-1690-42bf-9e1f-e7d7bf8029f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key set successfully.\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from helper import set_openai_key, test_openai_api, create_openai_client, print_pretty\n",
    "\n",
    "set_openai_key()\n",
    "\n",
    "test_openai_api()\n",
    "\n",
    "client = create_openai_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e41f6a-b3a1-458b-a951-601e608398ef",
   "metadata": {},
   "source": [
    "### Section 1: Breaking down the LLM context window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d622c5e-0951-45c8-b142-c565e7d2a208",
   "metadata": {},
   "source": [
    "#### A simple agent's context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4155a561-a71c-4a9d-a724-60af0111a162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information, including your name. How can I assist you today?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "system_prompt = \"You are a chatbot.\"\n",
    "\n",
    "# Make the completion request with the tool usage\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt: always included in the context window \n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        # chat history (evolves over time)\n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"}, \n",
    "    ]\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4b8f5-e2e4-41e5-81a1-5b98b9086780",
   "metadata": {},
   "source": [
    "#### Adding memory to the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03114f22-0438-46d1-8cf5-33bd8c3074dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"Name: Bob\"}\n",
    "\n",
    "system_prompt = \"You are a chatbot. \" \\\n",
    "+ \"You have a section of your context called [MEMORY] \" \\\n",
    "+ \"that contains information relevant to your conversation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb7bcf2-f900-4a26-9f0f-875d72efc9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt + \"[MEMORY]\\n\" + \\\n",
    "         json.dumps(agent_memory)},\n",
    "        # chat history \n",
    "        {\"role\": \"user\", \"content\": \"What is my name?\"},\n",
    "    ],\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437319c-18eb-42ff-a5f0-4f80cbae2d34",
   "metadata": {},
   "source": [
    "### Section 2: Modifing the memory with tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b1abb-cdf6-4e5c-892e-f7f6956f6a84",
   "metadata": {},
   "source": [
    "#### Defining a memory editing tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad3b7e4d-e017-4c28-8b01-506b99563f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = {\"human\": \"\", \"agent\": \"\"}\n",
    "\n",
    "def core_memory_save(section: str, memory: str):\n",
    "    # Append the memory of specific section\n",
    "    agent_memory[section] += '\\n' \n",
    "    agent_memory[section] += memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e23aa3d-cc5a-40fa-947d-6de52f4a31d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': '', 'agent': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1256126-bd37-472b-a7c9-3d35cac1c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_memory_save(\"human\", \"The human's name is Charles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3f155f8-d7ad-45ca-875b-5b4d91e42c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': \"\\nThe human's name is Charles\", 'agent': ''}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e66af3-b80a-434c-a609-49241d146773",
   "metadata": {},
   "source": [
    "Let's define a tool schema for the `core_memory_save` function that GPT can call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b25e488-eb16-435f-bf02-71db08409ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Save important information about you,the agent or the human you are chatting with.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool description \n",
    "core_memory_save_description = \"Save important information about you,\" \\\n",
    "+ \"the agent or the human you are chatting with.\"\n",
    "\n",
    "core_memory_save_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cc3f84b-0904-40af-82a3-51b2a6f62d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments into the tool (generated by the LLM)\n",
    "# defines what the agent must generate to input into the tool \n",
    "core_memory_save_properties = \\\n",
    "{\n",
    "    # arg 1: section of memory to edit\n",
    "    \"section\": {\n",
    "        \"type\": \"string\",\n",
    "        \"enum\": [\"human\", \"agent\"],\n",
    "        \"description\": \"Must be either 'human' \" \\\n",
    "        + \"(to save information about the human) or 'agent'\" \\\n",
    "        + \"(to save information about yourself)\",            \n",
    "    },\n",
    "    # arg 2: memory to save\n",
    "    \"memory\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"Memory to save in the section\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbab9a88-44ba-408a-9504-4d5f5783ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool schema (passed to OpenAI)\n",
    "core_memory_save_metadata = \\\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"core_memory_save\",\n",
    "            \"description\": core_memory_save_description,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": core_memory_save_properties,\n",
    "                \"required\": [\"section\", \"memory\"],\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc2709-7bcb-4f2f-9707-4b40307693ef",
   "metadata": {},
   "source": [
    "#### Run first agent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73d747ec-a945-4aab-97cc-c32feb9e48b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ltdzf4L1kzuIkVjUvtNOXrQK', function=Function(arguments='{\"section\":\"human\",\"memory\":\"Name is Bob\"}', name='core_memory_save'), type='function')]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory = {\"human\": \"\"}\n",
    "system_prompt = \"You are a chatbot. \" \\\n",
    "+ \"You have a section of your context called [MEMORY] \" \\\n",
    "+ \"that contains information relevant to your conversation\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        # memory \n",
    "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        # chat history \n",
    "        {\"role\": \"user\", \"content\": \"My name is Bob\"},\n",
    "    ],\n",
    "    # tool schemas \n",
    "    tools=[core_memory_save_metadata]\n",
    ")\n",
    "response = chat_completion.choices[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "653d02f2-d6aa-450f-82bf-bbf35a443121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"finish_reason\": \"tool_calls\",\n",
      "    \"index\": 0,\n",
      "    \"logprobs\": null,\n",
      "    \"message\": {\n",
      "        \"audio\": null,\n",
      "        \"content\": null,\n",
      "        \"function_call\": null,\n",
      "        \"refusal\": null,\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": [\n",
      "            {\n",
      "                \"function\": {\n",
      "                    \"arguments\": \"{\\\"section\\\":\\\"human\\\",\\\"memory\\\":\\\"Name is Bob\\\"}\",\n",
      "                    \"name\": \"core_memory_save\"\n",
      "                },\n",
      "                \"id\": \"call_ltdzf4L1kzuIkVjUvtNOXrQK\",\n",
      "                \"type\": \"function\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print_pretty(response.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b803d-e92d-4cdb-b12d-e621511481c8",
   "metadata": {},
   "source": [
    "#### Executing the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e3b3e0-d534-44c8-baaa-ca27044365c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'human', 'memory': 'Name is Bob'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments = json.loads(response.message.tool_calls[0].function.arguments)\n",
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceca2291-feca-4f6e-bffe-abd27090d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the function with the specified arguments \n",
    "core_memory_save(**arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6d1028d-81ad-41e6-b676-aa8af7acb3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human': '\\nName is Bob'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bdd855-3262-44c9-acdf-ef9e5ea9fe78",
   "metadata": {},
   "source": [
    "#### Running the next agent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5725eb8-fb89-4483-b582-ede01143087f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Your name is Bob.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        # memory \n",
    "        {\"role\": \"system\", \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)},\n",
    "        # chat history \n",
    "        {\"role\": \"user\", \"content\": \"what is my name\"},\n",
    "    ],\n",
    "    tools=[core_memory_save_metadata]\n",
    ")\n",
    "response = chat_completion.choices[0]\n",
    "response.message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cff93f-adfd-4310-92ea-4c0091e0974d",
   "metadata": {},
   "source": [
    "#### Implementing an agentic loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0df4aeb0-0d23-4038-b9b9-30ffec58511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init agent memory\n",
    "agent_memory = {\"human\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82e93026-0ae4-4dbc-b200-20e720bb2d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_os = system_prompt \\\n",
    "+ \"\\n. You must either call a tool (core_memory_save) or\" \\\n",
    "+ \"write a response to the user. \" \\\n",
    "+ \"Do not take the same actions multiple times!\" \\\n",
    "+ \"When you learn new information, make sure to always\" \\\n",
    "+ \"call the core_memory_save tool.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af54acd9-8d87-42b1-89d3-33e142d0a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_step(user_message): \n",
    "    \n",
    "    # prefix messages with system prompt and memory\n",
    "    messages = [\n",
    "        # system prompt \n",
    "        {\"role\": \"system\", \"content\": system_prompt_os}, \n",
    "        # memory\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"[MEMORY]\\n\" + json.dumps(agent_memory)\n",
    "        },\n",
    "    ]    \n",
    "\n",
    "    # append the most recent message\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # agentic loop \n",
    "    while True:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=[core_memory_save_metadata]\n",
    "        )\n",
    "        response = chat_completion.choices[0]\n",
    "\n",
    "        # update the messages with the agent's response \n",
    "        messages.append(response.message)\n",
    "        \n",
    "        # if NOT calling a tool (responding to the user), return \n",
    "        if not response.message.tool_calls: \n",
    "            return response.message.content\n",
    "\n",
    "        # if calling a tool, execute the tool\n",
    "        else: \n",
    "            print(\"TOOL CALL:\", response.message.tool_calls[0].function)\n",
    "            \n",
    "            # parse the arguments from the LLM function call\n",
    "            arguments = json.loads(\n",
    "                response.message.tool_calls[0].function.arguments\n",
    "            )\n",
    "\n",
    "            # run the function with the specified arguments\n",
    "            core_memory_save(**arguments)\n",
    "\n",
    "            # add the tool call response to the message history \n",
    "            messages.append({\n",
    "                \"role\": \"tool\", \n",
    "                \"tool_call_id\": response.message.tool_calls[0].id, \n",
    "                \"name\": \"core_memory_save\", \n",
    "                \"content\": f\"Updated memory: {json.dumps(agent_memory)}\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06b0efb1-0935-4b16-91d6-76c3dba45188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOL CALL: Function(arguments='{\"section\":\"human\",\"memory\":\"The user\\'s name is Bob.\"}', name='core_memory_save')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Nice to meet you, Bob! How can I assist you today?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_step(\"my name is bob.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f71864ab-b57f-4fc8-af95-1b9cadf93e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_step(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c4009-92bd-4462-b1bc-a509e5d47026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
